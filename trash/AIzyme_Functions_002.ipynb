{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import re\n",
    "import subprocess\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "from Bio import SeqIO\n",
    "import warnings\n",
    "import time\n",
    "import logging\n",
    "from IPython.display import display, clear_output\n",
    "from Bio.PDB import PDBParser\n",
    "import statistics\n",
    "import math\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "from scipy.stats import pearsonr\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import json\n",
    "import random \n",
    "\n",
    "# Setting initial options\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None \n",
    "matplotlib_axes_logger.setLevel('INFO')\n",
    "\n",
    "DESIGN_COUNT = {}\n",
    "FOLDER_HOME = f'{os.getcwd()}/{DESIGN_FOLDER}'\n",
    "os.makedirs(FOLDER_HOME, exist_ok=True)\n",
    "FOLDER_INPUT = f'{os.getcwd()}/Input'\n",
    "if not os.path.isdir(FOLDER_INPUT): print(\"ERROR! Input folder missing!\")\n",
    "LOG_FILE = f'{FOLDER_HOME}.log'\n",
    "ALL_SCORES_CSV = f'{FOLDER_HOME}/all_scores.csv'\n",
    "BLOCKED_DAT    = f'{FOLDER_HOME}/blocked.dat'\n",
    "VARIABLES_JSON  = f'{FOLDER_HOME}/variables.json'\n",
    "\n",
    "# Configure logging file\n",
    "log_format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "# Remove all handlers associated with the root logger\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Basic configuration for logging to a file\n",
    "logging.basicConfig(filename=LOG_FILE, level=logging.DEBUG, format=log_format, datefmt=date_format)\n",
    "\n",
    "# Create a StreamHandler for console output\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_handler.setFormatter(logging.Formatter(log_format, datefmt=date_format))\n",
    "\n",
    "# Add the console handler to the root logger\n",
    "logging.getLogger().addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main functions - running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller(RESET=False, EXPLORE=EXPLORE, UNBLOCK_ALL=False, PRINT_VAR=True, PLOT_DATA=True, BLUEPEBBLE=False, GRID=True):\n",
    "    # Main AI.zymes functions. Controls the whole design process\n",
    "\n",
    "    # Startup, will only be executed once in the beginning\n",
    "    setup_aizymes(RESET) \n",
    "    # Check if Startup is done, if done, read in all_scores_df\n",
    "    all_scores_df, blocked_df = startup_controller(UNBLOCK_ALL, PRINT_VAR=PRINT_VAR, PLOT_DATA=PLOT_DATA)\n",
    "    \n",
    "    while not os.path.exists(os.path.join(FOLDER_HOME, str(MAX_DESIGNS))):\n",
    "\n",
    "        # Check how many jobs are currently running\n",
    "        num_running_jobs = check_running_jobs()\n",
    "        \n",
    "        if num_running_jobs >= MAX_JOBS: \n",
    "            \n",
    "            time.sleep(60)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Update scores\n",
    "            all_scores_df, blocked_df = update_scores(all_scores_df, blocked_df)\n",
    "            \n",
    "            # Boltzmann Selection\n",
    "            selected_index = boltzmann_selection(all_scores_df, blocked_df)\n",
    "            \n",
    "            # Decide Fate of selected index\n",
    "            all_scores_df, blocked_df = start_calculation(all_scores_df, blocked_df, selected_index)\n",
    "    \n",
    "    print(f\"Stopped because {os.path.join(FOLDER_HOME, str(MAX_DESIGNS))} exists.\")\n",
    "\n",
    "def check_running_jobs():\n",
    "    \n",
    "    if GRID:\n",
    "        jobs = subprocess.check_output([\"qstat\", \"-u\", USERNAME]).decode(\"utf-8\").split(\"\\n\")\n",
    "    if BLUEPEBBLE:\n",
    "        jobs = subprocess.check_output([\"sacct\"]).decode(\"utf-8\").split(\"\\n\")\n",
    "        jobs = [job for job in jobs if \"RUNNING\" in job]\n",
    "    jobs = [job for job in jobs if SUBMIT_PREFIX in job]\n",
    "    return len(jobs)\n",
    "\n",
    "def update_scores(all_scores_df, blocked_df):\n",
    "    # Update total_score, interface_score, and score\n",
    "    \n",
    "    for index, row in all_scores_df.iterrows():\n",
    "\n",
    "        index = row['index']\n",
    "        parent_index = row['parent_index']\n",
    "        \n",
    "        # do NOT update score if score was taken from a relax file\n",
    "        score_file_path = f\"{FOLDER_HOME}/{int(index)}/score_rosetta_relax.sc\"\n",
    "        if row['score_taken_from'] == 'Relax': continue\n",
    "\n",
    "        # change scorefile path if run is a RosettaDesign and if score_rosetta_relax.sc does not exist\n",
    "        if row['design_method'] == \"RosettaDesign\":\n",
    "            if not os.path.exists(score_file_path):\n",
    "                score_file_path = f\"{FOLDER_HOME}/{int(index)}/score_rosetta_design.sc\"\n",
    "                # do NOT update score if score was taken from a design file\n",
    "                if row['score_taken_from'] == 'Design': continue\n",
    "\n",
    "        if os.path.exists(score_file_path):\n",
    "\n",
    "            with open(score_file_path, \"r\") as f: scores = f.readlines()\n",
    "\n",
    "            if len(scores) > 2: # if the timing is bad, the score file is not fully written. Check if len(scores) > 2!\n",
    "\n",
    "                headers = scores[1].split()\n",
    "                scores  = scores[2].split()\n",
    "\n",
    "                catalytic_score = 0.0\n",
    "                for idx_headers, header in enumerate(headers):\n",
    "                    if header == 'total_score':\n",
    "                        all_scores_df.at[index, 'total_score'] = float(scores[idx_headers])\n",
    "                    if header == 'interface_delta_X':\n",
    "                        all_scores_df.at[index, 'interface_score'] = float(scores[idx_headers])\n",
    "                    if header in ['angle_constraint', 'atom_pair_constraint', 'dihedral_constraint']:\n",
    "                        catalytic_score += float(scores[idx_headers])\n",
    "                all_scores_df.at[index, 'catalytic_score'] = catalytic_score\n",
    "\n",
    "                if score_file_path == f\"{FOLDER_HOME}/{int(index)}/score_rosetta_relax.sc\":\n",
    "                    all_scores_df.at[index, 'score_taken_from'] = 'Relax'\n",
    "                if score_file_path == f\"{FOLDER_HOME}/{int(index)}/score_rosetta_design.sc\":\n",
    "                    all_scores_df.at[index, 'score_taken_from'] = 'Design'\n",
    "\n",
    "                logging.info(f\"Updated total_score, interface_delta_X, and catalytic_score of index {int(index)}.\")\n",
    "        \n",
    "        #unblock index if relaxed file exists\n",
    "        if index in blocked_df:\n",
    "            if f\"Rosetta_Relax_{int(index)}.pdb\" in os.listdir(os.path.join(FOLDER_HOME, str(int(index)))):\n",
    "                logging.debug(f\"Unblocked index {int(index)}.\")\n",
    "                blocked_df = [i for i in blocked_df if i != index]\n",
    "                if blocked_df == []:\n",
    "                    np.savetxt(BLOCKED_DAT, np.array([], dtype=int), fmt='%d')\n",
    "                else:\n",
    "                    np.savetxt(BLOCKED_DAT, blocked_df)\n",
    "                    \n",
    "    all_scores_df.to_csv(ALL_SCORES_CSV, index=False)\n",
    "    return all_scores_df, blocked_df \n",
    "\n",
    "def normalize_scores(all_scores_df):\n",
    "    \n",
    "    def neg_norm_array(array, array_np):\n",
    "        if len(array) > 1:\n",
    "            array    = -array\n",
    "            array_np = -array_np\n",
    "            array = (array-np.nanmin(array_np))/(np.nanmax(array_np)-np.nanmin(array_np))\n",
    "            array[array < 0] = 0.0\n",
    "            return array\n",
    "        else:\n",
    "            return array\n",
    "      \n",
    "    all_scores_df_np    = all_scores_df[all_scores_df['parent_index'] != \"None\"]\n",
    "    \n",
    "    catalytic_scores    = np.array(   all_scores_df[\"catalytic_score\"].tolist())\n",
    "    catalytic_scores_np = np.array(all_scores_df_np[\"catalytic_score\"].tolist())\n",
    "    catalytic_scores    = neg_norm_array(catalytic_scores, catalytic_scores_np)   \n",
    "    \n",
    "    total_scores        = np.array(   all_scores_df[\"total_score\"].tolist()) \n",
    "    total_scores_np     = np.array(all_scores_df_np[\"total_score\"].tolist()) \n",
    "    total_scores        = neg_norm_array(total_scores, total_scores_np)   \n",
    "    \n",
    "    interface_scores    = np.array(   all_scores_df[\"interface_score\"].tolist())\n",
    "    interface_scores_np = np.array(all_scores_df_np[\"interface_score\"].tolist())\n",
    "    interface_scores    = neg_norm_array(interface_scores, interface_scores_np)  \n",
    "    \n",
    "    combined_scores   = ( catalytic_scores + total_scores + interface_scores ) / 3  \n",
    "    \n",
    "    return catalytic_scores, total_scores, interface_scores, combined_scores\n",
    "        \n",
    "def boltzmann_selection(all_scores_df, blocked_df):\n",
    "\n",
    "    number_of_indices = len(all_scores_df)\n",
    "    \n",
    "    # Drop rows where 'total_score' is NaN\n",
    "    all_scores_df  = all_scores_df.dropna(subset=['total_score'])\n",
    "    all_scores_df  = all_scores_df[all_scores_df['parent_index'] != \"None\"]\n",
    "     \n",
    "    all_scores_df  = all_scores_df[~all_scores_df['index'].isin(blocked_df)]\n",
    "        \n",
    "    catalytic_scores, total_scores, interface_scores, combined_scores = normalize_scores(all_scores_df)\n",
    "        \n",
    "    original_index = np.array(all_scores_df[\"index\"].tolist())\n",
    "  \n",
    "    if isinstance(KBT_BOLTZMANN, (float, int)):\n",
    "        kbt_boltzmann = KBT_BOLTZMANN\n",
    "    else:\n",
    "        if len(KBT_BOLTZMANN) == 2:\n",
    "            kbt_boltzmann = KBT_BOLTZMANN[0] * 10**(-KBT_BOLTZMANN[1]*all_scores_df['index'].max())\n",
    "    \n",
    "    boltzmann_factors = np.exp(combined_scores / (kbt_boltzmann)) \n",
    "    probabilities = boltzmann_factors / sum(boltzmann_factors)\n",
    "    \n",
    "    if original_index != []:\n",
    "        selected_index = int(np.random.choice(original_index, p=probabilities))\n",
    "    else:\n",
    "        selected_index = 1\n",
    "        \n",
    "    if number_of_indices < N_PARENT_JOBS: selected_index = 0\n",
    "        \n",
    "    return selected_index\n",
    "         \n",
    "# Decides what to do with selected index\n",
    "def start_calculation(all_scores_df, blocked_df, selected_index):\n",
    "    logging.debug(f\"Starting new calculation for index {selected_index}.\")\n",
    "\n",
    "    blocked = False\n",
    "    if selected_index in blocked_df: blocked = True\n",
    "        \n",
    "    releaxed = False\n",
    "    if f\"Rosetta_Relax_{selected_index}.pdb\" in os.listdir(os.path.join(FOLDER_HOME, str(selected_index))): releaxed = True\n",
    "    \n",
    "    # Check if ESMfold_Rosetta_Relax is done\n",
    "    if releaxed:\n",
    "        \n",
    "        # ESMfold_Rosetta_Relax is done, create a new index\n",
    "        new_index, all_scores_df = create_new_index(parent_index=selected_index, all_scores_df=all_scores_df)\n",
    "        \n",
    "        #####\n",
    "        # Here, we can add an AI to decide on the next steps\n",
    "        #####\n",
    "        \n",
    "        # Run Rosetta_Design with new_index\n",
    "        if random.random() < ProteinMPNN_PROB:  \n",
    "            all_scores_df.at[new_index, 'design_method'] = \"ProteinMPNN\"\n",
    "            run_ProteinMPNN(parent_index=selected_index, new_index=new_index) \n",
    "        else:                    \n",
    "            all_scores_df.at[new_index, 'design_method'] = \"RosettaDesign\"\n",
    "            run_RosettaDesign(parent_index=selected_index, new_index=new_index) \n",
    "            \n",
    "        all_scores_df.to_csv(ALL_SCORES_CSV, index=False)   \n",
    "        \n",
    "    else:\n",
    "        # ESMfold_Rosetta_Relax is not done, check if Index is blocked\n",
    "        if blocked:\n",
    "            # Blocked --> ESMfold_Rosetta_Relax is still running, do not do antyting. This shouldn't happen!\n",
    "            logging.error(f\"Index {selected_index} is being worked on. Skipping index.\")\n",
    "            logging.error(f\"Note: This should not happen! Check blocking and Boltzman selection.\")\n",
    "        else:\n",
    "            # Not blocked --> submit ESMfold_Rosetta_Relax and block index\n",
    "            logging.info(f\"Index {selected_index} has no relaxed structure, starting ESMfold_Rosetta_Relax.\")\n",
    "            parent_index = int(float(all_scores_df['parent_index'][selected_index]))\n",
    "            run_ESMfold_RosettaRelax(index=selected_index, RosettaDesign=True)\n",
    "            # Block index\n",
    "            blocked_df += [selected_index]\n",
    "            if blocked_df == []:\n",
    "                np.savetxt(BLOCKED_DAT, np.array([], dtype=int), fmt='%d')\n",
    "            else:\n",
    "                np.savetxt(BLOCKED_DAT, blocked_df)\n",
    "              \n",
    "    return all_scores_df, blocked_df  \n",
    "\n",
    "def create_new_index(parent_index, all_scores_df):\n",
    "    \n",
    "    # Get the latest index\n",
    "    latest_index = all_scores_df['index'].max()\n",
    "\n",
    "    # Create a new line with the next index and parent_index\n",
    "    new_index = int(latest_index + 1)\n",
    "    \n",
    "    # Append the new line to the DataFrame and save to  all_scores_df.csv\n",
    "    if isinstance(KBT_BOLTZMANN, (float, int)):\n",
    "        kbt_boltzmann = KBT_BOLTZMANN\n",
    "    else:\n",
    "        if len(KBT_BOLTZMANN) == 2:\n",
    "            kbt_boltzmann = KBT_BOLTZMANN[0] * 10 ** (- KBT_BOLTZMANN[1] * new_index)\n",
    "    all_scores_df = all_scores_df.append({'index': new_index, \n",
    "                                          'parent_index': parent_index,\n",
    "                                          'kbt_boltzmann': kbt_boltzmann}, ignore_index=True)\n",
    "    all_scores_df.to_csv(ALL_SCORES_CSV, index=False)\n",
    "\n",
    "    # Create the folders for the new index\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{new_index}/scripts\", exist_ok=True)\n",
    "           \n",
    "    logging.debug(f\"Child index {new_index} created for {parent_index}.\")\n",
    "    return new_index, all_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main functions - design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ESMfold_RosettaRelax(index, RosettaDesign=False, ProteinMPNN=False, StartupRelax=False,\n",
    "                             ProteinMPNN_parent_index=0, cmd=\"\", bash=False):\n",
    "    \n",
    "    os.makedirs(f\"{FOLDER_HOME}/{index}/ESMfold\", exist_ok=True)\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{index}/scripts\", exist_ok=True)\n",
    "        \n",
    "    ex = \"-ex1 -ex2\"\n",
    "    if EXPLORE: ex = \"\"\n",
    "        \n",
    "    # Get Name of parent PDB\n",
    "    if StartupRelax:\n",
    "        RosettaDesign = True ### Run these options!\n",
    "    if RosettaDesign: \n",
    "        PDBFile = f\"{FOLDER_HOME}/{index}/Rosetta_Design_{index}.pdb\"\n",
    "    if ProteinMPNN:\n",
    "        PDBFile = f\"{FOLDER_HOME}/{ProteinMPNN_parent_index}/Rosetta_Relax_{ProteinMPNN_parent_index}.pdb\"\n",
    "    if not os.path.isfile(PDBFile):\n",
    "        logging.error(f\"{PDBFile} not present!\")\n",
    "        return\n",
    "    \n",
    "    #Get updated RemarkLine\n",
    "    with open(PDBFile, 'r') as f: PDB = f.readlines()\n",
    "    for line in PDB:\n",
    "        if line.startswith(\"ATOM\") or line.startswith(\"HETATM\"):\n",
    "            if int(line[22:26].strip()) == 99:\n",
    "                residue_99_code = line[17:20].strip()\n",
    "                break\n",
    "    amino_acids = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLU', 'GLN', 'GLY', 'HIS', 'ILE', \n",
    "                   'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL']\n",
    "    for RES in amino_acids:\n",
    "        if RES in REMARK: header = REMARK.replace(RES, residue_99_code)\n",
    "    \n",
    "    # Make sequence file\n",
    "    if RosettaDesign: \n",
    "        seq = extract_sequence_from_pdb(PDBFile)\n",
    "        with open(f\"{FOLDER_HOME}/{index}/ESMfold/{PARENT}_{index}.seq\",\"w\") as f: f.write(seq)\n",
    "                    \n",
    "    # Get the pdb file from the last step and strip away ligand and hydrogens \n",
    "    cpptraj = f'''parm    {PDBFile}\n",
    "trajin  {PDBFile}\n",
    "strip   :{LIGAND}\n",
    "strip   @H=\n",
    "trajout {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Apo_{index}.pdb\n",
    "'''\n",
    "    with open(f'{FOLDER_HOME}/{index}/ESMfold/CPPTraj_Apo_{index}.in','w') as f: f.write(cpptraj)\n",
    "\n",
    "    # Get the pdb file from the last step and strip away everything except the ligand\n",
    "    cpptraj = f'''parm    {PDBFile}\n",
    "trajin  {PDBFile}\n",
    "strip   !:{LIGAND}\n",
    "trajout {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Lig_{index}.pdb\n",
    "'''\n",
    "    with open(f'{FOLDER_HOME}/{index}/ESMfold/CPPTraj_Lig_{index}.in','w') as f: f.write(cpptraj)\n",
    "\n",
    "    # Get the ESMfold pdb file and strip away all hydrogens\n",
    "    cpptraj = f'''parm    {FOLDER_HOME}/{index}/ESMfold/ESMfold_output_{index}.pdb\n",
    "trajin  {FOLDER_HOME}/{index}/ESMfold/ESMfold_output_{index}.pdb\n",
    "strip   @H=\n",
    "trajout {FOLDER_HOME}/{index}/ESMfold/ESMfold_no_hydrogens_{index}.pdb\n",
    "'''\n",
    "    with open(f'{FOLDER_HOME}/{index}/ESMfold/CPPTraj_no_hydrogens_{index}.in','w') as f: f.write(cpptraj)\n",
    "\n",
    "    # Align substrate and ESM prediction of scaffold without hydrogens\n",
    "    cpptraj = f'''parm    {FOLDER_HOME}/{index}/ESMfold/ESMfold_no_hydrogens_{index}.pdb\n",
    "reference {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Apo_{index}.pdb [apo]\n",
    "trajin    {FOLDER_HOME}/{index}/ESMfold/ESMfold_no_hydrogens_{index}.pdb\n",
    "rmsd      @CA ref [apo]\n",
    "trajout   {FOLDER_HOME}/{index}/ESMfold/ESMfold_aligned_{index}.pdb noter\n",
    "'''\n",
    "    with open(f'{FOLDER_HOME}/{index}/ESMfold/CPPTraj_aligned_{index}.in','w') as f: f.write(cpptraj) \n",
    "    output_file = f'{FOLDER_HOME}/{index}/ESMfold/ESMfold_output_{index}.pdb'      \n",
    "    \n",
    "    # Giving the ESMfold algorihm the needed inputs\n",
    "    sequence_file = f'{FOLDER_HOME}/{index}/ESMfold/{PARENT}_{index}.seq'\n",
    "    cmd += f\"\"\"\n",
    "    \n",
    "python {FOLDER_HOME}/ESMfold.py {output_file} {sequence_file}\n",
    "\n",
    "sed -i '/PARENT N\\/A/d' {FOLDER_HOME}/{index}/ESMfold/ESMfold_output_{index}.pdb\n",
    "cpptraj -i {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Apo_{index}.in           &> \\\n",
    "           {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Apo_{index}.out\n",
    "cpptraj -i {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Lig_{index}.in           &> \\\n",
    "           {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Lig_{index}.out\n",
    "cpptraj -i {FOLDER_HOME}/{index}/ESMfold/CPPTraj_no_hydrogens_{index}.in  &> \\\n",
    "           {FOLDER_HOME}/{index}/ESMfold/CPPTraj_no_hydrogens_{index}.out\n",
    "cpptraj -i {FOLDER_HOME}/{index}/ESMfold/CPPTraj_aligned_{index}.in       &> \\\n",
    "           {FOLDER_HOME}/{index}/ESMfold/CPPTraj_aligned_{index}.out\n",
    "\n",
    "sed -i '/END/d' {FOLDER_HOME}/{index}/ESMfold/ESMfold_aligned_{index}.pdb\n",
    "grep '^REMARK' {PDBFile} > {FOLDER_HOME}/remark.txt\n",
    "\n",
    "cat {FOLDER_HOME}/remark.txt \\\n",
    "    {FOLDER_HOME}/{index}/ESMfold/ESMfold_aligned_{index}.pdb \\\n",
    "    {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Lig_{index}.pdb > {FOLDER_HOME}/{index}/ESMfold_{index}.pdb\n",
    "sed -i '/TER/d' {FOLDER_HOME}/{index}/ESMfold_{index}.pdb\n",
    "\n",
    "# Run Rosetta Relax\n",
    "{ROSETTA_PATH}/bin/rosetta_scripts.linuxgccrelease \\\n",
    "                -s                                        {FOLDER_HOME}/{index}/ESMfold_{index}.pdb \\\n",
    "                -extra_res_fa                             {FOLDER_INPUT}/{LIGAND}.params \\\n",
    "                -parser:protocol                          {FOLDER_HOME}/Rosetta_Relax.xml \\\n",
    "                -out:file:scorefile                       {FOLDER_HOME}/{index}/score_rosetta_relax.sc \\\n",
    "                -nstruct                                  1 \\\n",
    "                -ignore_zero_occupancy                    false \\\n",
    "                -corrections::beta_nov16                  true \\\n",
    "                -run:preserve_header  \\\n",
    "                -overwrite {ex}\n",
    "\n",
    "# Rename the output file\n",
    "mv ESMfold_{index}_0001.pdb Rosetta_Relax_{index}.pdb\n",
    "\n",
    "# Clean output file\n",
    "sed -i '/^\\(HET\\|ATO\\|TER\\|REM\\)/!d' Rosetta_Relax_{index}.pdb\n",
    "\"\"\"\n",
    "    \n",
    "    if RosettaDesign: \n",
    "        with open(f'{FOLDER_HOME}/{index}/scripts/ESMfold_Rosetta_Relax_{index}.sh', 'w') as file:\n",
    "            file.write(cmd)\n",
    "        logging.info(f\"Run ESMfold & Rosetta_Relax for index {index}.\")\n",
    "        submit_job(index=index, job=\"ESMfold_Rosetta_Relax\", bash=bash)\n",
    "        \n",
    "    if ProteinMPNN:\n",
    "        with open(f'{FOLDER_HOME}/{index}/scripts/ProteinMPNN_ESMfold_Rosetta_Relax_{index}.sh', 'w') as file:\n",
    "            file.write(cmd)\n",
    "        logging.info(f\"Run ProteinMPNN for index {index} based on index {ProteinMPNN_parent_index}.\")\n",
    "        submit_job(index=index, job=\"ProteinMPNN_ESMfold_Rosetta_Relax\", bash=bash)\n",
    "        \n",
    "def run_RosettaDesign(parent_index, new_index):\n",
    "        \n",
    "    ex = \"-ex1 -ex2\"\n",
    "    if EXPLORE: ex = \"\"\n",
    "\n",
    "    cmd = f\"\"\"{ROSETTA_PATH}/bin/rosetta_scripts.linuxgccrelease \\\n",
    "    -s                                        {FOLDER_HOME}/{parent_index}/Rosetta_Relax_{parent_index}.pdb \\\n",
    "    -in:file:native                           {FOLDER_HOME}/{parent_index}/Rosetta_Relax_{parent_index}.pdb \\\n",
    "    -run:preserve_header                      true \\\n",
    "    -extra_res_fa                             {FOLDER_INPUT}/{LIGAND}.params \\\n",
    "    -parser:protocol                          {FOLDER_HOME}/Rosetta_Design.xml \\\n",
    "    -out:file:scorefile                       {FOLDER_HOME}/{new_index}/score_rosetta_design.sc \\\n",
    "    -nstruct                                  1  \\\n",
    "    -ignore_zero_occupancy                    false  \\\n",
    "    -corrections::beta_nov16                  true \\\n",
    "    -run:preserve_header  \\\n",
    "    -overwrite {ex}\n",
    "            \n",
    "# Rename the output file\n",
    "mv Rosetta_Relax_{parent_index}_0001.pdb Rosetta_Design_{new_index}.pdb\n",
    "\"\"\"\n",
    "    # Write the shell command to a file\n",
    "    with open(f'{FOLDER_HOME}/{new_index}/scripts/Rosetta_Design_{new_index}.sh','w') as file: file.write(cmd)\n",
    "                \n",
    "    # Submit the job using the submit_job function\n",
    "    logging.info(f\"Run RosettaDesign for index {new_index} based on index {parent_index}.\")\n",
    "    submit_job(index=new_index, job=\"Rosetta_Design\")\n",
    "\n",
    "def run_ProteinMPNN(parent_index, new_index, bash=False):\n",
    "\n",
    "    #Throw error if ProteinMPNN not cloned\n",
    "    if not os.path.exists(f'{FOLDER_HOME}/../ProteinMPNN'):\n",
    "        logging.error(f\"{ProteinMPNN} not installed in {FOLDER_HOME}/../ProteinMPNN.\")\n",
    "        logging.error(f\"Install using: git clone https://github.com/dauparas/ProteinMPNN.git\")\n",
    "        return\n",
    "    \n",
    "    # Make the fasta file for the index variant \n",
    "    PDBFile = f\"{FOLDER_HOME}/{parent_index}/Rosetta_Relax_{parent_index}.pdb\"\n",
    "\n",
    "    #Throw error if design not present!\n",
    "    if not os.path.isfile(PDBFile):\n",
    "        logging.error(f\"{PDBFile} not present!\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{new_index}/ProteinMPNN\", exist_ok=True)\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{new_index}/ESMfold\", exist_ok=True)\n",
    "    shutil.copy(PDBFile, f\"{FOLDER_HOME}/{new_index}/ProteinMPNN/Rosetta_Relax_{parent_index}.pdb\")\n",
    "    seq = extract_sequence_from_pdb(PDBFile)\n",
    "    with open(f\"{FOLDER_HOME}/{new_index}/ProteinMPNN/Rosetta_Relax_{parent_index}.seq\",\"w\") as f: f.write(seq)\n",
    "          \n",
    "    cmd = f'''\n",
    "# Run ProteinMPNN\n",
    "\n",
    "python {FOLDER_HOME}/../ProteinMPNN/helper_scripts/parse_multiple_chains.py \\\n",
    "    --input_path={FOLDER_HOME}/{new_index}/ProteinMPNN/ \\\n",
    "    --output_path={FOLDER_HOME}/{new_index}/ProteinMPNN/parsed_chains.json1\n",
    "\n",
    "python {FOLDER_HOME}/../ProteinMPNN/helper_scripts/assign_fixed_chains.py \\\n",
    "    --input_path={FOLDER_HOME}/{new_index}/ProteinMPNN/parsed_chains.json1 \\\n",
    "    --output_path={FOLDER_HOME}/{new_index}/ProteinMPNN/assigned_chains.json1 \\\n",
    "    --chain_list 'A'\n",
    "\n",
    "python {FOLDER_HOME}/../ProteinMPNN/helper_scripts/make_fixed_positions_dict.py \\\n",
    "    --input_path={FOLDER_HOME}/{new_index}/ProteinMPNN/parsed_chains.json1 \\\n",
    "    --output_path={FOLDER_HOME}/{new_index}/ProteinMPNN/fixe_positions.json1 \\\n",
    "    --chain_list 'A' \\\n",
    "    --position_list '{\" \".join(DESIGN.split(\",\"))}'\n",
    "\n",
    "python {FOLDER_HOME}/../ProteinMPNN/protein_mpnn_run.py \\\n",
    "    --jsonl_path            {FOLDER_HOME}/{new_index}/ProteinMPNN/parsed_chains.json1 \\\n",
    "    --chain_id_jsonl        {FOLDER_HOME}/{new_index}/ProteinMPNN/assigned_chains.json1\\\n",
    "    --fixed_positions_jsonl {FOLDER_HOME}/{new_index}/ProteinMPNN/fixe_positions.json1 \\\n",
    "    --out_folder            {FOLDER_HOME}/{new_index}/ProteinMPNN/ \\\n",
    "    --num_seq_per_target    100 \\\n",
    "    --sampling_temp         \"{ProteinMPNN_T}\" \\\n",
    "    --seed                  37 \\\n",
    "    --batch_size            1\n",
    "       \n",
    "# Get highest scoreing sequence\n",
    "file_path='{FOLDER_HOME}/{new_index}/ProteinMPNN/seqs/Rosetta_Relax_{parent_index}.fa' \n",
    "parent_seq_file='{FOLDER_HOME}/{new_index}/ProteinMPNN/Rosetta_Relax_{parent_index}.seq'\n",
    "input_sequence='{FOLDER_HOME}/input_sequence_with_X_as_wildecard.seq'\n",
    "highest_score=0\n",
    "highest_scoring_sequence=''\n",
    "read -r parent_sequence < \"$parent_seq_file\"\n",
    "\n",
    "# loop through scores and find greatest score that is not the same as the parent sequence\n",
    "while read -r line; do\n",
    "    if [[ $line == \">\"* ]]; then\n",
    "        score=$(echo $line | grep -oP 'global_score=\\K[\\d.]+')\n",
    "        read -r sequence\n",
    "        \n",
    "        # Check if score is higher than the highest score\n",
    "        if (( $(echo \"$score > $highest_score\" | bc -l) )); then\n",
    "        \n",
    "            # Check if sequence is different from parent_sequence\n",
    "            if [ \"$sequence\" != \"$parent_sequence\" ]; then\n",
    "            \n",
    "                # Check if sequence does not match input_sequence pattern\n",
    "                pattern=$(echo \"$input_sequence\" | sed 's/X/./g')  # Replace 'X' with wildecard '.'\n",
    "                if [[ ! \"$sequence\" =~ $pattern ]]; then\n",
    "                \n",
    "                    highest_score=$score\n",
    "                    highest_scoring_sequence=$sequence\n",
    "                    \n",
    "                fi\n",
    "            fi\n",
    "        fi\n",
    "    fi\n",
    "done < \"$file_path\"\n",
    "\n",
    "# Save highest scoring sequence\n",
    "echo $highest_scoring_sequence > {FOLDER_HOME}/{new_index}/ProteinMPNN/{PARENT}_{new_index}.seq\n",
    "echo $highest_scoring_sequence > {FOLDER_HOME}/{new_index}/ESMfold/{PARENT}_{new_index}.seq\n",
    "''' \n",
    "    run_ESMfold_RosettaRelax(index=new_index, RosettaDesign=False, \\\n",
    "                             ProteinMPNN=True, ProteinMPNN_parent_index=parent_index, cmd=cmd, bash=bash)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main functions - startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startup_controller(UNBLOCK_ALL, PRINT_VAR=True, PLOT_DATA=True):\n",
    "\n",
    "    prepare_input_files()\n",
    "    \n",
    "    if PRINT_VAR:\n",
    "        if os.path.isfile(VARIABLES_JSON):\n",
    "            with open(VARIABLES_JSON, 'r') as f: globals_dict = json.load(f)\n",
    "            if globals_dict['DESIGN_FOLDER'] == DESIGN_FOLDER:\n",
    "                for k, v in globals_dict.items():\n",
    "                    globals()[k] = v\n",
    "                    if k == \"REMARK\": v = v[:-1]\n",
    "                    print(k.ljust(16), ':', v)\n",
    "            else:\n",
    "                print(\"WRONG DESIGN FOLDER!\")\n",
    "                sys.exit()\n",
    "            \n",
    "    if PLOT_DATA:\n",
    "        plot_scores()\n",
    "        \n",
    "    #Unblock all (use if all ESMfold_Relax jobs had to be killed.)\n",
    "    if UNBLOCK_ALL: np.savetxt(BLOCKED_DAT, np.array([], dtype=int), fmt='%d')\n",
    "    \n",
    "    #Check if Rosetta_Relax_0 is ready\n",
    "    while not f\"Rosetta_Relax_0.pdb\" in os.listdir(os.path.join(FOLDER_HOME, str(0))):\n",
    "        print(f'Initial relax running. Rosetta_Relax_0.pdb not in ./{FOLDER_HOME.split(\"/\")[-1]}/{0}')\n",
    "        time.sleep(60) \n",
    "\n",
    "    all_scores_df = pd.read_csv(ALL_SCORES_CSV)\n",
    "    all_scores_df['sequence'] = all_scores_df['sequence'].astype(str)\n",
    "    all_scores_df['design_method'] = all_scores_df['design_method'].astype(str)\n",
    "    all_scores_df['score_taken_from'] = all_scores_df['score_taken_from'].astype(str)\n",
    "\n",
    "    blocked_df = np.loadtxt(BLOCKED_DAT)\n",
    "    \n",
    "    all_scores_df, blocked_df = update_scores(all_scores_df, blocked_df)\n",
    "           \n",
    "    return all_scores_df, blocked_df\n",
    "\n",
    "def prepare_input_files():\n",
    "                \n",
    "    # Write the REEMARK to a textfile\n",
    "    with open(f\"{FOLDER_HOME}/remark.txt\", \"w\") as f: f.write(REMARK)\n",
    "        \n",
    "    # Create the ESMfold.py script\n",
    "    ESMfold_python_script = \"\"\"import sys\n",
    "from transformers import AutoTokenizer, EsmForProteinFolding, EsmConfig\n",
    "import torch\n",
    "from transformers.models.esm.openfold_utils.protein import to_pdb, Protein as OFProtein\n",
    "from transformers.models.esm.openfold_utils.feats import atom14_to_atom37\n",
    "\n",
    "output_file = sys.argv[1]\n",
    "sequence_file = sys.argv[2]\n",
    "\n",
    "with open(sequence_file) as f: sequence=f.read()\n",
    "\n",
    "def convert_outputs_to_pdb(outputs):\n",
    "    final_atom_positions = atom14_to_atom37(outputs[\"positions\"][-1], outputs)\n",
    "    outputs = {k: v.to(\"cpu\").numpy() for k, v in outputs.items()}\n",
    "    final_atom_positions = final_atom_positions.cpu().numpy()\n",
    "    final_atom_mask = outputs[\"atom37_atom_exists\"]\n",
    "    pdbs = []\n",
    "    for i in range(outputs[\"aatype\"].shape[0]):\n",
    "        aa = outputs[\"aatype\"][i]\n",
    "        pred_pos = final_atom_positions[i]\n",
    "        mask = final_atom_mask[i]\n",
    "        resid = outputs[\"residue_index\"][i] + 1\n",
    "        pred = OFProtein(\n",
    "            aatype=aa,\n",
    "            atom_positions=pred_pos,\n",
    "            atom_mask=mask,\n",
    "            residue_index=resid,\n",
    "            b_factors=outputs[\"plddt\"][i],\n",
    "            chain_index=outputs[\"chain_index\"][i] if \"chain_index\" in outputs else None,\n",
    "        )\n",
    "        pdbs.append(to_pdb(pred))\n",
    "    return pdbs\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esmfold_v1\")\n",
    "model = EsmForProteinFolding.from_pretrained(\"facebook/esmfold_v1\", low_cpu_mem_usage=True)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "tokenized_input = tokenizer([sequence], return_tensors=\"pt\", add_special_tokens=False)['input_ids']\n",
    "with torch.no_grad(): output = model(tokenized_input)\n",
    "pdb = convert_outputs_to_pdb(output)\n",
    "with open(output_file, \"w\") as f: f.write(\"\".join(pdb))\n",
    "\"\"\"\n",
    "\n",
    "    # Write the ESMfold.py to a file\n",
    "    with open(f\"{FOLDER_HOME}/ESMfold.py\", \"w\") as f: \n",
    "        f.write(ESMfold_python_script)\n",
    "\n",
    "    # Create the Rosetta_Relax.xml file\n",
    "    repeats = \"3\"\n",
    "    if EXPLORE: repeats = \"1\"\n",
    "    Rosetta_Relax_xml = f\"\"\"\n",
    "<ROSETTASCRIPTS>\n",
    "\n",
    "    <SCOREFXNS>\n",
    "    \n",
    "        <ScoreFunction name      = \"score\"                   weights = \"beta_nov16\" >\n",
    "            <Reweight scoretype  = \"atom_pair_constraint\"    weight  = \"1\" />\n",
    "            <Reweight scoretype  = \"dihedral_constraint\"     weight  = \"1\" />\n",
    "            <Reweight scoretype  = \"angle_constraint\"        weight  = \"1\" />\n",
    "        </ScoreFunction> \n",
    "        \n",
    "        <ScoreFunction name      = \"score_final\"             weights = \"beta_nov16\" >\n",
    "            <Reweight scoretype  = \"atom_pair_constraint\"    weight  = \"1\" />\n",
    "            <Reweight scoretype  = \"dihedral_constraint\"     weight  = \"1\" />\n",
    "            <Reweight scoretype  = \"angle_constraint\"        weight  = \"1\" />\n",
    "        </ScoreFunction>\n",
    "        \n",
    "    </SCOREFXNS>\n",
    "       \n",
    "    <MOVERS>\n",
    "\n",
    "        <AddOrRemoveMatchCsts     name=\"mv_add_cst\" \n",
    "                                  cst_instruction=\"add_new\" \n",
    "                                  cstfile=\"{FOLDER_INPUT}/{LIGAND}_enzdes.cst\" />\n",
    "                                  \n",
    "        <FastRelax  name=\"mv_relax\" disable_design=\"false\" repeats=\"{repeats}\" \n",
    "                    ramp_down_constraints=\"false\" scorefxn=\"score\" >\n",
    "        </FastRelax>\n",
    "        \n",
    "        <InterfaceScoreCalculator   name                   = \"mv_inter\" \n",
    "                                    chains                 = \"X\" \n",
    "                                    scorefxn               = \"score_final\" />\n",
    "    </MOVERS>\n",
    "    \n",
    "    <PROTOCOLS>\n",
    "        <Add mover_name=\"mv_add_cst\" />\n",
    "        <Add mover_name=\"mv_relax\" />\n",
    "        <Add mover_name=\"mv_inter\" />\n",
    "    </PROTOCOLS>\n",
    "    \n",
    "</ROSETTASCRIPTS>\n",
    "\"\"\"\n",
    "    # Write the Rosetta_Relax.xml to a file\n",
    "    with open(f'{FOLDER_HOME}/Rosetta_Relax.xml', 'w') as f:\n",
    "        f.writelines(Rosetta_Relax_xml)      \n",
    "\n",
    "    # Create XML script for Rosetta Design  \n",
    "    repeats = \"2\"\n",
    "    if EXPLORE: repeats = \"1\"\n",
    "    Rosetta_Design_xml = f\"\"\"\n",
    "<ROSETTASCRIPTS>\n",
    "\n",
    "    <SCOREFXNS>\n",
    "    \n",
    "        <ScoreFunction            name=\"score_hbnet\"                     weights=\"beta_nov16\" >        \n",
    "            <Reweight             scoretype=\"hbnet\"                      weight=\"1.0\" />\n",
    "            <Reweight             scoretype=\"buried_unsatisfied_penalty\" weight=\"1\" />\n",
    "            <Reweight             scoretype=\"atom_pair_constraint\"       weight=\"1\" />\n",
    "            <Reweight             scoretype=\"dihedral_constraint\"        weight=\"1\" />\n",
    "            <Reweight             scoretype=\"angle_constraint\"           weight=\"1\" />      \n",
    "            <Reweight             scoretype=\"res_type_constraint\"        weight=\"1\" />         \n",
    "        </ScoreFunction>\n",
    "\n",
    "        <ScoreFunction            name=\"score\"                           weights=\"beta_nov16\" >        \n",
    "            <Reweight             scoretype=\"atom_pair_constraint\"       weight=\"1\" />\n",
    "            <Reweight             scoretype=\"dihedral_constraint\"        weight=\"1\" />\n",
    "            <Reweight             scoretype=\"angle_constraint\"           weight=\"1\" />      \n",
    "            <Reweight             scoretype=\"res_type_constraint\"        weight=\"1\" />               \n",
    "        </ScoreFunction>\n",
    "\n",
    "        <ScoreFunction            name=\"score_final\"                     weights=\"beta_nov16\" >    \n",
    "            <Reweight             scoretype=\"atom_pair_constraint\"       weight=\"1\" />\n",
    "            <Reweight             scoretype=\"dihedral_constraint\"        weight=\"1\" />\n",
    "            <Reweight             scoretype=\"angle_constraint\"           weight=\"1\" />                \n",
    "        </ScoreFunction>\n",
    "   \n",
    "   </SCOREFXNS>\n",
    "    \n",
    "    <RESIDUE_SELECTORS>\n",
    "    \n",
    "        <Index                    name=\"sel_design\" \n",
    "                                  resnums=\"{DESIGN}\" />\n",
    "\n",
    "        <Index                    name=\"sel_repack\" \n",
    "                                  resnums=\"{REPACK}\" />\n",
    "\n",
    "        <Index                    name=\"sel_cat\" \n",
    "                                  resnums=\"{RESTRICT.split(\",\")[0]}\" />\n",
    "\n",
    "        <Or                       name=\"sel_desrep\" \n",
    "                                  selectors=\"sel_design,sel_repack\" />\n",
    "\n",
    "        <Not                      name=\"sel_nothing\"\n",
    "                                  selector=\"sel_desrep\" />\n",
    "    </RESIDUE_SELECTORS>\n",
    "    \n",
    "    <TASKOPERATIONS>\n",
    "    \n",
    "        <OperateOnResidueSubset   name=\"tsk_design\"                      selector=\"sel_design\" >\n",
    "                                  <RestrictAbsentCanonicalAASRLT         aas=\"GPAVLIMFYWHKRQNEDST\" />\n",
    "        </OperateOnResidueSubset>\n",
    "        \n",
    "        <OperateOnResidueSubset   name=\"tsk_cat\"                         selector=\"sel_cat\" >\n",
    "                                  <RestrictAbsentCanonicalAASRLT         aas=\"{RESTRICT.split(\",\")[1]}\" />\n",
    "        </OperateOnResidueSubset>\n",
    "        \n",
    "        <OperateOnResidueSubset   name=\"tsk_repack\"                      selector=\"sel_repack\" >\n",
    "                                  <RestrictToRepackingRLT />\n",
    "        </OperateOnResidueSubset>\n",
    "        \n",
    "        <OperateOnResidueSubset   name=\"tsk_nothing\"                     selector=\"sel_nothing\" >\n",
    "                                  <PreventRepackingRLT />\n",
    "        </OperateOnResidueSubset>\n",
    "        \n",
    "    </TASKOPERATIONS>\n",
    "\n",
    "    <FILTERS>\n",
    "    \n",
    "        <HbondsToResidue          name=\"flt_hbonds\" \n",
    "                                  scorefxn=\"score\" \n",
    "                                  partners=\"1\"\n",
    "                                  residue=\"1X\"\n",
    "                                  backbone=\"true\" \n",
    "                                  sidechain=\"true\" \n",
    "                                  from_other_chains=\"true\" \n",
    "                                  from_same_chain=\"false\"\n",
    "                                  confidence=\"0\" />\n",
    "    </FILTERS>\n",
    "    \n",
    "    <MOVERS>\n",
    "        \n",
    "        <FavorSequenceProfile     name=\"mv_native\" \n",
    "                                  weight=\"{CST_WEIGHT}\" \n",
    "                                  use_native=\"true\" \n",
    "                                  matrix=\"IDENTITY\" \n",
    "                                  scorefxns=\"score,score_hbnet\" />  \n",
    "                                \n",
    "        <AddOrRemoveMatchCsts     name=\"mv_add_cst\" \n",
    "                                  cst_instruction=\"add_new\" \n",
    "                                  cstfile=\"{FOLDER_INPUT}/{LIGAND}_enzdes.cst\" />\n",
    "\n",
    "        <FastDesign               name=\"mv_design_hbnet\" \n",
    "                                  disable_design=\"false\" \n",
    "                                  task_operations=\"tsk_design,tsk_repack,tsk_nothing,tsk_cat\" \n",
    "                                  repeats=\"{repeats}\" \n",
    "                                  ramp_down_constraints=\"false\" \n",
    "                                  scorefxn=\"score_hbnet\" />\n",
    "        \n",
    "        <AddOrRemoveMatchCsts     name=\"mv_remove_cst\" \n",
    "                                  cst_instruction=\"remove\" \n",
    "                                  cstfile=\"{FOLDER_INPUT}/{LIGAND}_enzdes.cst\" />\n",
    "                              \n",
    "        <FastDesign               name                   =\"mv_design\" \n",
    "                                  disable_design         =\"false\" \n",
    "                                  task_operations        =\"tsk_design,tsk_repack,tsk_nothing,tsk_cat\" \n",
    "                                  repeats                =\"1\" \n",
    "                                  ramp_down_constraints  = \"false\" \n",
    "                                  scorefxn               = \"score\" />                                 \n",
    "            \n",
    "        <InterfaceScoreCalculator name                   = \"mv_inter\" \n",
    "                                  chains                 = \"X\" \n",
    "                                  scorefxn               = \"score_final\" />\n",
    "                                  \n",
    "    </MOVERS>\n",
    "\n",
    "    <PROTOCOLS>\n",
    "        <Add mover_name=\"mv_native\" />\n",
    "        <Add mover_name=\"mv_add_cst\" />\n",
    "        <Add mover_name=\"mv_design_hbnet\" />\n",
    "        <Add mover_name=\"mv_remove_cst\" />\n",
    "        <Add mover_name=\"mv_design\" />\n",
    "        <Add mover_name=\"mv_add_cst\" />\n",
    "        <Add mover_name=\"mv_inter\" />\n",
    "    </PROTOCOLS>\n",
    "    \n",
    "</ROSETTASCRIPTS>\n",
    "\n",
    "\"\"\"\n",
    "    # Write the XML script to a file\n",
    "    with open(f'{FOLDER_HOME}/Rosetta_Design.xml', 'w') as f:\n",
    "        f.writelines(Rosetta_Design_xml)    \n",
    "        \n",
    "    # Save input sequence with X as wildcard\n",
    "    seq = extract_sequence_from_pdb(f\"{FOLDER_INPUT}/{PARENT}.pdb\")\n",
    "    design_positions = [int(x) for x in DESIGN.split(',')]\n",
    "    # Replace seq with X at design positions. Note: Subtract 1 from each position to convert to Python's 0-based indexing\n",
    "    seq = ''.join('X' if (i+1) in design_positions else amino_acid for i, amino_acid in enumerate(seq))\n",
    "    with open(f'{FOLDER_HOME}/input_sequence_with_X_as_wildecard.seq', 'w') as f:\n",
    "        f.writelines(seq)    \n",
    "    \n",
    "def setup_aizymes(RESET):\n",
    "    # Check if setup needs to run\n",
    "    if not os.path.isdir(FOLDER_HOME):\n",
    "        if not input(f'''{FOLDER_HOME} not present.\n",
    "Do you want to start AIzymes? [y/n]\n",
    "\n",
    "''') == 'y':\n",
    "            return #stops the start up. Although FOLDER_HOME is missing, user elected not to start AIzymes\n",
    "    else:\n",
    "        if RESET:\n",
    "            if not input(f'''Do you really want to restart AIzymes from scratch? \n",
    "This will delete all existing files in {FOLDER_HOME} [y/n]\n",
    "\n",
    "''') == 'y':\n",
    "                return #stops the start up. Although folder exists and RESET set, user canceled\n",
    "        else:\n",
    "            return #stop startup. FOLDER_HOME exists and RESET not set by user\n",
    "\n",
    "    with open(LOG_FILE, 'w'): pass  #resets logfile\n",
    "    logging.info(f\"Running AI.zymes setup.\")\n",
    "    logging.info(f\"Content of {FOLDER_HOME} deleted.\")\n",
    "    logging.info(f\"Happy AI.zymeing! :)\")\n",
    "   \n",
    "    if os.path.exists(FOLDER_HOME):\n",
    "        shutil.rmtree(FOLDER_HOME)\n",
    "    os.makedirs(FOLDER_HOME, exist_ok=True)\n",
    "\n",
    "    prepare_input_files()\n",
    "        \n",
    "    # If the file doesn't exist, we start with index 0\n",
    "    all_scores_df = pd.DataFrame(columns=['index', 'sequence', 'parent_index', \\\n",
    "                                          'interface_score', 'total_score', 'catalytic_score', \\\n",
    "                                          'generation', 'mutations', 'design_method', 'score_taken_from'])\n",
    "    \n",
    "    # Append the new line to the DataFrame\n",
    "    all_scores_df = all_scores_df.append({'index': 0, \\\n",
    "                                          'parent_index': \"None\", \\\n",
    "                                          'interface_score' : 0.0,\\\n",
    "                                          'total_score' : 0.0,\\\n",
    "                                          'catalytic_score' : 0.0,\\\n",
    "                                          'generation' : 0,\\\n",
    "                                          'mutations' : 0,\\\n",
    "                                          'sequence' : '',\\\n",
    "                                          'design_method' : \"parent\", \\\n",
    "                                          'score_taken_from' : ''}, ignore_index=True)\n",
    "    all_scores_df['sequence'] = all_scores_df['sequence'].astype(str)\n",
    "    all_scores_df['design_method'] = all_scores_df['design_method'].astype(str)\n",
    "    all_scores_df['score_taken_from'] = all_scores_df['score_taken_from'].astype(str)\n",
    "    all_scores_df.to_csv(ALL_SCORES_CSV, index=False)\n",
    "    \n",
    "    # create empty blocked.dat\n",
    "    np.savetxt(BLOCKED_DAT, np.array([], dtype=int), fmt='%d')\n",
    "\n",
    "    # Create the folders for the new index\n",
    "    os.makedirs(f\"{FOLDER_HOME}/0/ESMfold\", exist_ok=True)\n",
    "    os.makedirs(f\"{FOLDER_HOME}/0/scripts\", exist_ok=True)\n",
    "\n",
    "    # Save important varliables\n",
    "    variables_to_save = [\n",
    "        'DESIGN_FOLDER', 'MAX_JOBS', 'N_PARENT_JOBS', 'MAX_DESIGNS', 'KBT_BOLTZMANN', 'CST_WEIGHT',\n",
    "        'ProteinMPNN_PROB', 'PARENT', 'LIGAND', 'ROSETTA_PATH', 'REPACK', 'DESIGN', \n",
    "        'RESTRICT', 'SCORE_NAMES', 'REMARK', 'EXPLORE', 'ProteinMPNN_T', 'SUBMIT_PREFIX', 'BLUEPEBBLE', 'GRID'\n",
    "    ]\n",
    "    \n",
    "    # Creating a dictionary of specific global variables\n",
    "    globals_to_save = {k: globals()[k] for k in variables_to_save}\n",
    "    with open(VARIABLES_JSON, 'w') as f: json.dump(globals_to_save, f, indent=4)\n",
    "        \n",
    "    # Copy PDB from INPUT, add REMARK header, and rename it to fit the algorithms logic\n",
    "    pdb_file_path = f\"{FOLDER_HOME}/0/Rosetta_Design_0.pdb\" \n",
    "    shutil.copy(f\"{FOLDER_INPUT}/{PARENT}.pdb\", f\"{FOLDER_HOME}/0/Rosetta_Design_0.pdb\")\n",
    "    with open(pdb_file_path, 'r') as file: original_content = file.readlines()\n",
    "    modified_content = [REMARK] + original_content\n",
    "    with open(pdb_file_path, 'w') as file: file.writelines(modified_content)\n",
    "    run_ESMfold_RosettaRelax(0,StartupRelax=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_job(index, job, bash=False):        \n",
    "      \n",
    "    if GRID:\n",
    "        submission_script = f\"\"\"#!/bin/bash\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -N {SUBMIT_PREFIX}_{job}_{index}\n",
    "#$ -hard -l mf=16G\n",
    "#$ -o {FOLDER_HOME}/{index}/scripts/AI_{job}_{index}.out\n",
    "#$ -e {FOLDER_HOME}/{index}/scripts/AI_{job}_{index}.err\n",
    "\"\"\"\n",
    "    if BLUEPEBBLE:\n",
    "        submission_script = f\"\"\"#!/bin/bash\n",
    "#SBATCH --account=ptch000361\n",
    "#SBATCH --partition=short\n",
    "#SBATCH --mem=40GB\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --time=2:00:00    \n",
    "#SBATCH --nodes=1          \n",
    "#SBATCH --job-name={SUBMIT_PREFIX}_{job}_{index}\n",
    "#SBATCH --output=AI_{job}_{index}.out\n",
    "#SBATCH --error=AI_{job}_{index}.err\n",
    "\"\"\"\n",
    "    submission_script += f\"\"\"\n",
    "# Output folder\n",
    "cd {FOLDER_HOME}/{index}\n",
    "pwd\n",
    "\n",
    "# Count the number of .pdb files in the current directory\n",
    "file_count=$(find . -maxdepth 1 -type f -name \"{job}_{index}.pdb\" | wc -l)\n",
    "\n",
    "# Check whether the number of .pdb files is equal to the input structure number and if so write step done in log\n",
    "if [ \"$file_count\" = 0 ]; then\n",
    "# Run the bash script\n",
    "bash {FOLDER_HOME}/{index}/scripts/{job}_{index}.sh\n",
    "fi\n",
    "\"\"\" \n",
    "    \n",
    "    # Create the submission_script\n",
    "    with open(f'{FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh', 'w') as file: file.write(submission_script)\n",
    "    \n",
    "    if bash:\n",
    "        #Bash the submission_script for testing\n",
    "        subprocess.run(f'bash {FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh', shell=True, text=True)\n",
    "    else:\n",
    "        #Submit the submission_script\n",
    "        if GRID:\n",
    "            output = subprocess.check_output(f'qsub -l h=\"!bs-dsvr64&!bs-dsvr58\" -q regular.q \\\n",
    "                                             {FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh', \\\n",
    "                                             shell=True, text=True)\n",
    "            logging.debug(output[:-1]) #remove newline at end of output\n",
    "            \n",
    "        if BLUEPEBBLE:\n",
    "            output = subprocess.check_output(f'sbatch {FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh', \\\n",
    "                                             shell=True, text=True)\n",
    "            logging.debug(output[:-1]) #remove newline at end of output\n",
    "        \n",
    "def extract_sequence_from_pdb(pdb_path):\n",
    "    with open(pdb_path, \"r\") as pdb_file:\n",
    "        for record in SeqIO.parse(pdb_file, \"pdb-atom\"):\n",
    "            seq = str(record.seq)\n",
    "    return seq\n",
    "    \n",
    "def count_descendants(G, node, counts):\n",
    "    neighbors = list(G.successors(node))\n",
    "    count = 1\n",
    "    for neighbor in neighbors:\n",
    "        count += count_descendants(G, neighbor, counts)\n",
    "    counts[node] = count\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(combined_score_min=0, combined_score_max=1, combined_score_bin=0.01,\n",
    "                interface_score_min=0, interface_score_max=1, interface_score_bin=0.01,\n",
    "                total_score_min=0, total_score_max=1, total_score_bin=0.01,\n",
    "                catalytic_score_min=0, catalytic_score_max=1, catalytic_score_bin=0.01,\n",
    "                mut_min=0,mut_max=len(DESIGN.split(\",\"))+1):\n",
    "        \n",
    "    # Break because file does not exist\n",
    "    if not os.path.isfile(ALL_SCORES_CSV): return\n",
    "    \n",
    "    all_scores_df = pd.read_csv(ALL_SCORES_CSV)\n",
    "    all_scores_df['sequence'] = all_scores_df['sequence'].astype(str)\n",
    "    all_scores_df['design_method'] = all_scores_df['design_method'].astype(str)\n",
    "    all_scores_df['score_taken_from'] = all_scores_df['score_taken_from'].astype(str)\n",
    "            \n",
    "    ### Calculate Generations and Scores    \n",
    "    G = nx.DiGraph()\n",
    "    generations = {} \n",
    "    for idx, row in all_scores_df.iterrows():\n",
    "        \n",
    "        # Get generation\n",
    "        G.add_node(idx)\n",
    "        if row['parent_index'] != \"None\":\n",
    "            G.add_edge(int(float(row['parent_index'])), idx)\n",
    "            parent_gen = generations.get(int(float(row['parent_index'])), 0)\n",
    "            generations[idx] = parent_gen + 1\n",
    "        else:\n",
    "            generations[idx] = 0  # Set generation to 0 if parent_index is \"None\"\n",
    "        all_scores_df.at[idx, 'generation'] = generations[idx]\n",
    "\n",
    "        # Get mutations\n",
    "        if pd.isna(all_scores_df.at[idx, 'mutations']):\n",
    "            reference_sequence = extract_sequence_from_pdb(f\"{FOLDER_HOME}/0/Rosetta_Relax_0.pdb\")\n",
    "            pdb_path = f\"{FOLDER_HOME}/{idx}/Rosetta_Design_{idx}.pdb\"\n",
    "            if os.path.exists(pdb_path): \n",
    "                current_sequence = extract_sequence_from_pdb(pdb_path)\n",
    "                mutations = sum(1 for a, b in zip(current_sequence, reference_sequence) if a != b)\n",
    "                all_scores_df.at[idx, 'sequence'] = current_sequence\n",
    "                all_scores_df.at[idx, 'mutations'] = mutations\n",
    "  \n",
    "    all_scores_df.to_csv(ALL_SCORES_CSV, index=False)\n",
    "\n",
    "    # Plot data\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(15, 6))\n",
    "    \n",
    "    all_scores_df = all_scores_df.dropna(subset=['total_score'])\n",
    "    all_scores_df = all_scores_df[all_scores_df['parent_index'] != \"None\"]\n",
    "    catalytic_scores, total_scores, interface_scores, combined_scores = normalize_scores(all_scores_df)\n",
    "            \n",
    "    # Break because not enough data\n",
    "    if len(all_scores_df) < 3: return\n",
    "    \n",
    "    plot_combined_score(axs[0,0], combined_scores, \\\n",
    "                        combined_score_min, combined_score_max, combined_score_bin)\n",
    "    plot_interface_score(axs[0,1], interface_scores, \\\n",
    "                         interface_score_min, interface_score_max, interface_score_bin)\n",
    "    plot_total_score(axs[0,2], total_scores, \\\n",
    "                     total_score_min, total_score_max, total_score_bin)\n",
    "    plot_catalytic_score(axs[0,3], catalytic_scores, \\\n",
    "                         catalytic_score_min, catalytic_score_max, catalytic_score_bin)\n",
    "    \n",
    "    plot_boltzmann_histogram(axs[1,0], combined_scores, all_scores_df, \\\n",
    "                             combined_score_min, combined_score_max, combined_score_bin)\n",
    "    plot_combined_score_v_generation_scatter(axs[1,1], combined_scores, all_scores_df, \\\n",
    "                                             combined_score_min, combined_score_max)\n",
    "    plot_combined_score_v_generation(axs[1,2], combined_scores, all_scores_df, \\\n",
    "                                     combined_score_min, combined_score_max)\n",
    "    plot_mutations_v_generation(axs[1,3], all_scores_df, mut_min, mut_max)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 2.5))\n",
    "    plot_tree(ax, combined_scores, all_scores_df, G)\n",
    "    plt.show()\n",
    "\n",
    "def plot_combined_score(ax, combined_scores, score_min, score_max, score_bin):\n",
    "    \n",
    "    ax.hist(combined_scores, bins=np.arange(score_min,score_max+score_bin,score_bin))\n",
    "    ax.axvline(HIGHSCORE, color='r')\n",
    "    ax.set_xlim(score_min,score_max)\n",
    "    ax.set_title('Histogram of Score')\n",
    "    ax.set_xlabel('Combined Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "def plot_interface_score(ax, interface_scores, interface_score_min, interface_score_max, interface_score_bin):\n",
    "        \n",
    "    ax.hist(interface_scores, density=True,\n",
    "            bins=np.arange(interface_score_min,interface_score_max+interface_score_bin,interface_score_bin))\n",
    "    ax.set_xlim(interface_score_min,interface_score_max)\n",
    "    ax.set_title('Histogram of Interface Score')\n",
    "    ax.set_xlabel('Interface Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "def plot_total_score(ax, total_scores, total_score_min, total_score_max, total_score_bin):\n",
    "\n",
    "    ax.hist(total_scores, density=True,\n",
    "            bins=np.arange(total_score_min,total_score_max+total_score_bin,total_score_bin))\n",
    "    ax.set_xlim(total_score_min,total_score_max)\n",
    "    ax.set_title('Histogram of Total Score')\n",
    "    ax.set_xlabel('Total Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "def plot_catalytic_score(ax, catalytic_scores, total_score_min, total_score_max, total_score_bin):\n",
    "\n",
    "    ax.hist(catalytic_scores, density=True,\n",
    "            bins=np.arange(total_score_min,total_score_max+total_score_bin,total_score_bin))\n",
    "    ax.set_xlim(total_score_min,total_score_max)\n",
    "    ax.set_title('Histogram of Catalytic Score')\n",
    "    ax.set_xlabel('Catalytic Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "def plot_combined_score_v_generation_scatter(ax, combined_scores, all_scores_df, combined_score_min, combined_score_max):\n",
    "    \n",
    "    combined_scores = pd.Series(combined_scores)\n",
    "    moving_avg = combined_scores.rolling(window=20).mean()\n",
    "    ax.scatter(all_scores_df['index'], combined_scores, c='lightgrey', s=5) \n",
    "    ax.axhline(HIGHSCORE, color='r')\n",
    "    ax.plot(range(len(moving_avg)),moving_avg,c=\"k\")\n",
    "    ax.set_ylim(combined_score_min,combined_score_max)\n",
    "    ax.set_title('Score vs Index')\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Combined Score')    \n",
    "\n",
    "def plot_boltzmann_histogram(ax, combined_scores, all_scores_df, score_min, score_max, score_bin):\n",
    "    \n",
    "    if isinstance(KBT_BOLTZMANN, (float, int)):\n",
    "        kbt_boltzmann = KBT_BOLTZMANN\n",
    "    else:\n",
    "        if len(KBT_BOLTZMANN) == 2:\n",
    "            kbt_boltzmann = KBT_BOLTZMANN[0] * 10 ** (- KBT_BOLTZMANN[1] * len(all_scores_df))\n",
    "    \n",
    "    boltzmann_factors = np.exp(combined_scores / (kbt_boltzmann)) \n",
    "    probabilities     = boltzmann_factors / sum(boltzmann_factors) \n",
    "    \n",
    "    random_scores     = np.random.choice(combined_scores, size=1000, replace=True)\n",
    "    boltzmann_scores  = np.random.choice(combined_scores, size=1000, replace=True, p=probabilities)\n",
    "\n",
    "    # Plot the first histogram\n",
    "    ax.hist(random_scores, density=True, alpha=0.7, label='Random Sampling', \\\n",
    "            bins=np.arange(score_min,score_max+score_bin,score_bin))\n",
    "    ax.axvline(HIGHSCORE, color='r')\n",
    "    ax.set_xlabel('Combined Score')\n",
    "    ax.set_ylabel('Density (Normal)')\n",
    "    ax.set_title(f'kbT = {kbt_boltzmann:.1e}')\n",
    "    # Create a twin y-axis for the second histogram\n",
    "    ax_dup = ax.twinx()\n",
    "    ax_dup.hist(boltzmann_scores, density=True, alpha=0.7, color='orange', label='Boltzmann Sampling', \\\n",
    "                bins=np.arange(score_min,score_max+score_bin,score_bin))\n",
    "    ax.set_xlim(score_min,score_max)\n",
    "    ax_dup.set_ylabel('Density (Boltzmann)')\n",
    "    ax_dup.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "\n",
    "\n",
    "def plot_interface_score_v_total_score(ax, all_scores_df, \n",
    "                                       total_score_min, total_score_max, interface_score_min, interface_score_max):\n",
    "\n",
    "    ax.scatter(all_scores_df['total_score'], all_scores_df['interface_score'],\n",
    "            c=all_scores_df['index'], cmap='coolwarm_r', s=5)\n",
    "    correlation,_ = pearsonr(all_scores_df['total_score'], all_scores_df['interface_score'])\n",
    "    xmin = all_scores_df['total_score'].min()\n",
    "    xmax = all_scores_df['total_score'].max()\n",
    "    z = np.polyfit(all_scores_df['total_score'], all_scores_df['interface_score'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_trendline = np.linspace(xmin, xmax, 100) \n",
    "    ax.plot(x_trendline, p(x_trendline), \"k\")\n",
    "    ax.set_title(f'Pearson r: {correlation:.2f}')\n",
    "    ax.set_xlim(total_score_min,total_score_max)\n",
    "    ax.set_ylim(interface_score_min,interface_score_max)\n",
    "    ax.set_xlabel('Total Score')\n",
    "    ax.set_ylabel('Interface Score')\n",
    "        \n",
    "def plot_mutations_v_generation(ax, all_scores_df,  mut_min, mut_max):\n",
    "    \n",
    "    all_scores_df = all_scores_df.dropna(subset=['mutations'])\n",
    "    \n",
    "    max_gen = int(all_scores_df['generation'].max())\n",
    "    boxplot_data = [all_scores_df[all_scores_df['generation'] == gen]['mutations'] for gen in range(1,max_gen+1,1)]\n",
    "    ax.boxplot(boxplot_data, positions=range(len(boxplot_data)))\n",
    "    ax.axhline(len(DESIGN.split(\",\")), color='r')\n",
    "    ax.set_xticks(range(len(boxplot_data)))\n",
    "    ax.set_xticklabels(range(1,len(boxplot_data)+1,1))\n",
    "    ax.set_ylim(mut_min,mut_max)\n",
    "    ax.set_title('Mutations vs Generations')\n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Number of Mutations')\n",
    "    ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.7)\n",
    "\n",
    "def plot_combined_score_v_generation(ax, combined_scores, all_scores_df, score_min, score_max):\n",
    "\n",
    "    max_gen = int(all_scores_df['generation'].max())\n",
    "    boxplot_data = [combined_scores[all_scores_df['generation'] == gen] for gen in range(1, max_gen+1)]    \n",
    "    ax.boxplot(boxplot_data, positions=range(len(boxplot_data)))\n",
    "    ax.axhline(HIGHSCORE, color='r')\n",
    "    ax.set_xticks(range(len(boxplot_data)))\n",
    "    ax.set_xticklabels(range(1,len(boxplot_data)+1,1))\n",
    "    ax.set_ylim(score_min,score_max)\n",
    "    ax.set_title('Combined Score vs Generations')\n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Combined Score')\n",
    "    ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.7)\n",
    "    \n",
    "def plot_tree(ax, combined_scores, all_scores_df, G):\n",
    "    \n",
    "    all_scores_df = pd.read_csv(ALL_SCORES_CSV)\n",
    "    catalytic_scores, total_scores, interface_scores, combined_scores = normalize_scores(all_scores_df)\n",
    "\n",
    "    max_gen = int(all_scores_df['generation'].max())\n",
    "    \n",
    "    def set_node_positions(G, node, pos, x, y, counts):\n",
    "        pos[node] = (x, y)\n",
    "        neighbors = list(G.successors(node))\n",
    "        next_y = y - counts[node] / 2\n",
    "        for neighbor in neighbors:\n",
    "            set_node_positions(G, neighbor, pos, x + 1, next_y + counts[neighbor] / 2, counts)\n",
    "            next_y += counts[neighbor]\n",
    "\n",
    "    counts = {}\n",
    "    count_descendants(G, 0, counts)\n",
    "\n",
    "    pos = {}\n",
    "    set_node_positions(G, 0, pos, 0, 0, counts)\n",
    "    y_values = [y for x, y in pos.values()]\n",
    "    y_span = max(y_values) - min(y_values)  \n",
    "    \n",
    "    colors = combined_scores\n",
    "    colors[0] = np.nan\n",
    "    normed_colors = [(x - np.nanmin(colors[1:])) / (np.nanmax(colors[1:]) - np.nanmin(colors[1:])) for x in colors]\n",
    "    normed_colors = np.nan_to_num(normed_colors, nan=0)\n",
    "\n",
    "    # Draw the graph with the positions set\n",
    "    #nx.draw(G, pos, ax=ax, sld', arrows=False, cmap=plt.cm.coolwarm_r)\n",
    "    for start, end in G.edges():\n",
    "        color = plt.cm.coolwarm_r(normed_colors[end])\n",
    "        if float(normed_colors[end]) == 0.0: color = [0., 0., 0., 1.]\n",
    "        linewidth = 0.1+2*normed_colors[end]\n",
    "        \n",
    "        x0, y0 = pos[start]\n",
    "        x1, y1 = pos[end]\n",
    "        ax.plot([y0, y1], [x0, x1], color=color, linewidth=linewidth)\n",
    "\n",
    "    # Adjust axis labels and ticks for the swapped axes\n",
    "    ax.axis('on')\n",
    "    ax.set_xlabel(\"Variants\")\n",
    "    ax.set_ylabel(\"Generations\")\n",
    "    ax.set_yticks(range(max_gen+1))\n",
    "    ax.set_ylim(0,max_gen+0.25)\n",
    "    ax.set_yticklabels(range(max_gen+1))\n",
    "\n",
    "    ax.tick_params(axis='y', which='both', bottom=True, top=False, left=True, right=False,\n",
    "                   labelbottom=True, labelleft=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed to run AIzyme algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AIzyme Functions loaded!\")\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
