{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness Landscape Tools loaded.\n",
      "Data loaded from: ./data/all_scores_pooled_cut.csv\n",
      "Data normalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "%run src/fitness_landscape_tools.py\n",
    "%run src/train_model.py\n",
    "\n",
    "dataset = fitness_landscape(output_folder = '../../AIzymes_resi14')\n",
    "\n",
    "#    df_path         = './data/all_scores_pooled_cut.csv',\n",
    "#    df_path         = './data/all_scores_pooled.csv',\n",
    "\n",
    "df = fitness_landscape.load_dataset(    \n",
    "    dataset,            \n",
    "    df_path         = './data/all_scores_pooled_cut.csv',\n",
    "    scores          = ['interface_score', 'total_score', 'interface_potential', 'total_potential'],\n",
    "    labels          = ['score_taken_from', 'design_method', 'cat_resn', 'cat_resi', 'parent_index', 'generation', 'mutations'],\n",
    "    cat_resi        = 14,\n",
    "    select_unique   = True\n",
    "    )\n",
    "\n",
    "df = fitness_landscape.make_embeddings( \n",
    "    dataset,\n",
    "    embeddings      = ['onehot','plm','plm_pca'],\n",
    "    pooling_method  = 'concatenate',\n",
    "    pca_dim         = 5,\n",
    "    load_self       = False\n",
    "    )\n",
    "\n",
    "#dataset = fitness_landscape(output_folder = '../../AIzymes_resi14')\n",
    "#df = fitness_landscape.load_self_from_file(dataset, '../../AIzymes_resi14')\n",
    "\n",
    "train_model(\n",
    "    dataset,\n",
    "    load_self       = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#'''\n",
    "#Q for Tudor:\n",
    "#\n",
    "#- Why onehot 2d list, defined as tensors?\n",
    "#    plm and plm-pca are 1d lists now.\n",
    "#    What makes most sense?\n",
    "#\n",
    "#- What are the different options in pool_output?\n",
    "#\n",
    "#- Where do I find the training scripts?\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein_sequence': 'MNTPEHITAVVQRDVAALNAGDLDGLVALFADDATVEIPVGSEPRSGTAAIRELIANTLKLPLAVELTQEIRVVANEAAAAMIVSFEYQGRKIVVAPILHFRFNGAGKIVSLRQLFGEKNIHAGA',\n",
       " 'interface_score': tensor([-20.3530], dtype=torch.float64),\n",
       " 'total_score': tensor([-371.7990], dtype=torch.float64),\n",
       " 'interface_potential': tensor([-20.3530], dtype=torch.float64),\n",
       " 'total_potential': tensor([-371.7990], dtype=torch.float64),\n",
       " 'score_taken_from': 'Design',\n",
       " 'design_method': 'RosettaDesign',\n",
       " 'cat_resn': 'ASP',\n",
       " 'cat_resi': 14.0,\n",
       " 'parent_index': 'Parent',\n",
       " 'generation': 0.0,\n",
       " 'mutations': 16.0,\n",
       " 'onehot': [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]],\n",
       " 'plm': array([ 0.0653702 ,  0.13335297, -0.11276045, ..., -0.260164  ,\n",
       "        -0.06797425,  0.02364336], dtype=float32),\n",
       " 'plm_pca': array([11.184066  ,  0.23751418, -5.602404  ,  9.606658  , -0.32020757],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df.columns)\n",
    "fitness_landscape.__getitem__(dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence                    MNTPEHITAVVQRDVAALNAGDLDGLVALFADDATVEIPVGSEPRS...\n",
      "interface_score                                                       -20.353\n",
      "total_score                                                          -371.799\n",
      "interface_potential                                                   -20.353\n",
      "total_potential                                                      -371.799\n",
      "score_taken_from                                                       Design\n",
      "design_method                                                   RosettaDesign\n",
      "cat_resn                                                                  ASP\n",
      "cat_resi                                                                 14.0\n",
      "parent_index                                                           Parent\n",
      "generation                                                                0.0\n",
      "mutations                                                                16.0\n",
      "norm_interface_score                                                 0.431328\n",
      "norm_total_score                                                    -0.061612\n",
      "norm_interface_potential                                             0.431328\n",
      "norm_total_potential                                                -0.061612\n",
      "onehot                      [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
      "plm                         [0.0653702, 0.13335297, -0.11276045, 0.0224858...\n",
      "plm-pca                     [11.184058, 0.23754673, -5.60239, 9.606666, -0...\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(df.iloc[0])\n",
    "print(dataset.df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.1+cu121\n",
      "CUDA version: 12.1\n",
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df_path = './data/all_scores_pooled.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# Defining the scores (regression values) and labels from the AIzymes run to be used in the torch Dataset\n",
    "scores = ['interface_score', 'total_score', 'catalytic_score', 'interface_potential', 'total_potential', 'catalytic_potential', 'generation', 'mutations']\n",
    "labels = ['score_taken_from', 'design_method', 'cat_resn', 'cat_resi', 'parent_index']\n",
    "    \n",
    "# Filtering out duplicate sequences and averaging scores\n",
    "def select_unique(df, scores, labels):\n",
    "    score_df = df.groupby('sequence')[scores].mean().reset_index()\n",
    "    label_df = df.drop_duplicates('sequence')[labels + ['sequence']]\n",
    "    df = pd.merge(score_df, label_df, on='sequence')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = select_unique(df, scores, labels)\n",
    "\n",
    "df = df[df['cat_resi'] == 14]\n",
    "gp_ds_train = AIzymesDataset(train_df, scores, labels)\n",
    "gp_ds_test = AIzymesDataset(test_df, scores, labels)\n",
    "\n",
    "gp_ds_train.onehot_sequences()\n",
    "gp_ds_test.onehot_sequences()\n",
    "\n",
    "plm = EnzymePLM(device = device, pca_dim = 50) #Also make that PCA explained variance plot...\n",
    "pooling_methods = ['class', 'average', 'concatenate'] #will not test 'concatenate' due to high dimensionality\n",
    "\n",
    "gp_ds_train.embed_sequences(plm, pooling_methods)\n",
    "gp_ds_test.embed_sequences(plm, pooling_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encodings\n",
    "embedding_dataset.onehot_sequences()\n",
    "\n",
    "train_ds_1.onehot_sequences()\n",
    "test_ds_1.onehot_sequences()\n",
    "\n",
    "train_ds_2.onehot_sequences()\n",
    "test_ds_2.onehot_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plm = EnzymePLM(device = device, pca_dim = 50) #Also make that PCA explained variance plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ESM embeddings\n",
    "pooling_methods = ['class', 'average', 'pca_concatenate'] #will not test 'concatenate' due to high dimensionality\n",
    "\n",
    "train_ds_1.embed_sequences(plm, pooling_methods)\n",
    "test_ds_1.embed_sequences(plm, pooling_methods)\n",
    "\n",
    "train_ds_2.embed_sequences(plm, pooling_methods)\n",
    "test_ds_2.embed_sequences(plm, pooling_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements for VAE training (//Clean up and integrate into the existing dataset class//)\n",
    "\n",
    "df = pd.read_csv('/cluster/home/tcotet/fitness_landscapes/data/all_scores_pooled.csv')\n",
    "scores = ['interface_score', 'total_score', 'catalytic_score', 'interface_potential', 'total_potential', 'catalytic_potential', 'generation', 'mutations']\n",
    "labels = ['score_taken_from', 'design_method', 'cat_resn', 'cat_resi', 'parent_index']\n",
    "df = df[df['sequence'].notnull()]\n",
    "df = select_unique(df, scores, labels)\n",
    "seq = df['sequence'].tolist()\n",
    "label = df['cat_resi'].tolist()\n",
    "\n",
    "dataset = VDJ_dataset(seq, label, task = 'multiclass.classification')\n",
    "scores = df['total_score'].tolist()\n",
    "score_dataset = VDJ_dataset(seq, scores, task = 'regression')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training VAE for feature extraction\n",
    "args = Args()\n",
    "args.input_size = dataset.max_len * 19\n",
    "args.epochs = 100\n",
    "args.w_categ = 1\n",
    "args.w_recon = 1\n",
    "\n",
    "gmvae = GMVAE(args)\n",
    "\n",
    "history_loss = gmvae.train(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp1 = VDJ_dataset(train_ds_1.sequences, train_ds_1.labels['cat_resi'], task = 'multiclass.classification')\n",
    "temp1_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "embedding_dataset.embeddings['vae'] \n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "tsne = TSNE(n_components = 2)\n",
    "umap = UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = train_ds_1\n",
    "\n",
    "temp = VDJ_dataset(ds.sequences, ds.labels['cat_resi'], task = 'multiclass.classification')\n",
    "temp_loader = torch.utils.data.DataLoader(temp, batch_size=64, shuffle=False)\n",
    "features, labs = gmvae.latent_features(temp_loader, return_labels = True)\n",
    "ds.embeddings['vae'] = [features[i] for i in range(features.shape[0])]\n",
    "\n",
    "t1 = ds\n",
    "\n",
    "\n",
    "ds = test_ds_1\n",
    "\n",
    "temp = VDJ_dataset(ds.sequences, ds.labels['cat_resi'], task = 'multiclass.classification')\n",
    "temp_loader = torch.utils.data.DataLoader(temp, batch_size=64, shuffle=False)\n",
    "features, labs = gmvae.latent_features(temp_loader, return_labels = True)\n",
    "ds.embeddings['vae'] = [features[i] for i in range(features.shape[0])]\n",
    "\n",
    "tt1 = ds\n",
    "\n",
    "\n",
    "ds = train_ds_2\n",
    "\n",
    "temp = VDJ_dataset(ds.sequences, ds.labels['cat_resi'], task = 'multiclass.classification')\n",
    "temp_loader = torch.utils.data.DataLoader(temp, batch_size=64, shuffle=False)\n",
    "features, labs = gmvae.latent_features(temp_loader, return_labels = True)\n",
    "ds.embeddings['vae'] = [features[i] for i in range(features.shape[0])]\n",
    "\n",
    "t2 = ds\n",
    "\n",
    "\n",
    "ds = test_ds_2\n",
    "\n",
    "temp = VDJ_dataset(ds.sequences, ds.labels['cat_resi'], task = 'multiclass.classification')\n",
    "temp_loader = torch.utils.data.DataLoader(temp, batch_size=64, shuffle=False)\n",
    "features, labs = gmvae.latent_features(temp_loader, return_labels = True)\n",
    "ds.embeddings['vae'] = [features[i] for i in range(features.shape[0])]\n",
    "\n",
    "tt2 = ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from fitness.losses import bt_loss\n",
    "\n",
    "class FitnessTrainer:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.optimizers = {}\n",
    "        self.history = {}\n",
    "        self.scores = []\n",
    "        self.device = None\n",
    "        self.loss_fn = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def plot_training_metrics(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_history(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_history(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def save_model_checkpoint(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model_checkpoint(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def encode_inputs(self, input):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class TrainerGeneral(FitnessTrainer):\n",
    "    def __init__(self, model, optim,\n",
    "                       device,\n",
    "                       lr = 0.001,\n",
    "                       epochs = 20,\n",
    "                       loss = 'bt',\n",
    "                       encoding = 'onehot',\n",
    "                       scores = ['norm_interface_score', 'norm_total_score'],\n",
    "                       features = None,\n",
    "                       verbose = True,\n",
    "                       checkpoint_path = './checkpoint',\n",
    "                       checkpoint_epoch = 10,\n",
    "                       validate_epoch = 1):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.scores = scores\n",
    "        self.device = device\n",
    "        self.features = features\n",
    "        self.encoding = encoding\n",
    "        self.verbose = verbose\n",
    "\n",
    "        for score in self.scores:\n",
    "            self.models[score] = model.to(device)\n",
    "            self.optimizers[score] = optim(self.models[score].parameters(), lr = lr)\n",
    "\n",
    "        if loss == 'bt':\n",
    "            self.loss_fn = bt_loss\n",
    "        else:\n",
    "            self.loss_fn = F.mse_loss\n",
    "\n",
    "\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        if self.checkpoint_path is not None and os.path.isdir(self.checkpoint_path) is False:\n",
    "            os.mkdir(self.checkpoint_path)\n",
    "        self.checkpoint_epoch = checkpoint_epoch\n",
    "        self.validate_epoch = validate_epoch\n",
    "        \n",
    "        self.history = dict(zip(scores, [None] * len(scores)))\n",
    "\n",
    "    def train(self, train_dl, valid_dl):\n",
    "        for score in self.scores:\n",
    "            self.history[score] = {'train_epoch': [], 'train_loss_per_epoch': [], 'validation_epoch': [], 'validation_loss_per_epoch': []}\n",
    "            if self.verbose:\n",
    "                print(f'### Training regression model to predict: {score} ###')\n",
    "\n",
    "            for epoch in range(1, self.epochs + 1):\n",
    "                self.models[score].train()\n",
    "\n",
    "                losses_per_epoch = []\n",
    "                for iter, batch in enumerate(train_dl):\n",
    "\n",
    "                    y = batch[score].to(device)\n",
    "\n",
    "                    self.optimizers[score].zero_grad()\n",
    "                    y_hat = self.predict(batch, score)\n",
    "\n",
    "                    loss = self.loss_fn(y_hat, y)\n",
    "                    loss.backward()\n",
    "\n",
    "                    self.optimizers[score].step()\n",
    "\n",
    "                    losses_per_epoch.append(loss.item())\n",
    "\n",
    "                self.history[score]['train_epoch'].append(epoch)\n",
    "                self.history[score]['train_loss_per_epoch'].append(np.mean(losses_per_epoch))\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(f\"[Train] epoch:{epoch} \\t loss:{np.mean(losses_per_epoch):.4f}\")\n",
    "\n",
    "                if epoch % self.validate_epoch == 0:\n",
    "                    valid_loss = self.validate(valid_dl, score)\n",
    "                    self.history[score]['validation_epoch'].append(epoch)\n",
    "                    self.history[score]['validation_loss_per_epoch'].append(valid_loss)\n",
    "\n",
    "                    if self.verbose:\n",
    "                        print(f\"[Validation] epoch:{epoch} \\t loss:{valid_loss:.4f}\")\n",
    "\n",
    "\n",
    "                if self.checkpoint_path is not None:\n",
    "                    if epoch % self.checkpoint_epoch == 0:\n",
    "                        torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': self.models[score].state_dict(),\n",
    "                            'optimizer_state_dict': self.optimizers[score].state_dict(),\n",
    "                            'loss': np.mean(losses_per_epoch),\n",
    "                        }, os.path.join(self.checkpoint_path, f'model_{score}_checkpoint_{epoch}.pt'))\n",
    "\n",
    "        return self.models\n",
    "\n",
    "    def encode_inputs(self, input):\n",
    "        if self.encoding == 'onehot_flatten':\n",
    "            enc = input['onehot'].reshape(input['onehot'].shape[0], -1) #Flattens one-hot\n",
    "\n",
    "        elif self.encoding == 'onehot':\n",
    "            enc = input['onehot']\n",
    "\n",
    "        elif self.encoding == 'onehot_aizymes_features':\n",
    "            enc = input['onehot'].reshape(input['onehot'].shape[0], -1)\n",
    "            feat_list = [input[feat] for feat in self.features] + [enc]\n",
    "            enc = torch.cat(feat_list, axis = -1)\n",
    "\n",
    "        elif self.encoding == 'esm2':\n",
    "            enc = input['esm2']\n",
    "\n",
    "        elif self.encoding == 'vae':\n",
    "            enc = input['vae']\n",
    "\n",
    "        elif self.encoding == 'aizymes_features':\n",
    "            feat_list = [input[feat] for feat in self.features]\n",
    "            enc = torch.cat(feat_list, axis = -1)\n",
    "        else:\n",
    "            raise ValueError(f'Unrecognized encoding argument {self.encoding}!')\n",
    "\n",
    "        enc = enc.to(self.device)\n",
    "\n",
    "        return enc.float()\n",
    "\n",
    "    def predict(self, input, score):\n",
    "        enc = self.encode_inputs(input)\n",
    "\n",
    "        return self.models[score](enc)\n",
    "\n",
    "    def predict_mc_dropout(self, input, score, forward_passes = 50):\n",
    "        enc = self.encode_inputs(input)\n",
    "\n",
    "        dropout_predictions = np.empty((0, enc.shape[0], 1))\n",
    "\n",
    "        for i in range(forward_passes):\n",
    "            self.models[score].eval()\n",
    "            self.enable_dropout(self.models[score])\n",
    "            predictions = self.models[score](enc).cpu().detach().numpy()\n",
    "            dropout_predictions = np.vstack((dropout_predictions,\n",
    "                                             predictions[np.newaxis, :, :]))\n",
    "\n",
    "\n",
    "        mean = np.mean(dropout_predictions, axis=0)\n",
    "        std = np.std(dropout_predictions, axis=0)\n",
    "        y = input[score].cpu().detach().numpy()\n",
    "\n",
    "        return {'y_hat': np.squeeze(dropout_predictions, axis = -1),\n",
    "                'mean': np.squeeze(mean, axis = -1),\n",
    "                'std': np.squeeze(std, axis = -1),\n",
    "                'y': np.squeeze(y, axis = -1)}\n",
    "\n",
    "    def predict_numpy(self, input, score):\n",
    "        enc = self.encode_inputs(input)\n",
    "        self.models[score].eval()\n",
    "        predictions = self.models[score](enc).cpu().detach().numpy()\n",
    "        y = input[score].cpu().detach().numpy()\n",
    "\n",
    "        return {'y_hat': np.squeeze(predictions, axis = -1),\n",
    "                'mean': None,\n",
    "                'std': None,\n",
    "                'y': np.squeeze(y, axis = -1)}\n",
    "\n",
    "    def validate(self, valid_dl, score):\n",
    "\n",
    "        self.models[score].eval()\n",
    "        valid_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iter, batch in enumerate(valid_dl):\n",
    "                y = batch[score].to(device)\n",
    "                y_hat = self.predict(batch, score)\n",
    "\n",
    "                valid_losses.append(self.loss_fn(y_hat, y).item())\n",
    "\n",
    "        return np.mean(valid_losses)\n",
    "\n",
    "\n",
    "    def enable_dropout(self, model):\n",
    "        \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
    "        for m in model.modules():\n",
    "            if m.__class__.__name__.startswith('Dropout'):\n",
    "                m.train()\n",
    "\n",
    "    \n",
    "def train_mimo(train_ds, \n",
    "               test_ds, \n",
    "               device,\n",
    "               model,\n",
    "               scores = ['total_score', 'interface_score', 'catalytic_score'], \n",
    "               training_iter = 50, \n",
    "               lr = 1.0,\n",
    "               n_ensemble = 5,\n",
    "               batch_size = 128):\n",
    "    \n",
    "    input_dim = train_ds.embeddings['esm2'][0].shape[-1]\n",
    "    train_dataloaders = [torch.utils.data.DataLoader(train_ds, batch_size = batch_size, shuffle = True) for _ in range(n_ensemble)]\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size = batch_size, shuffle = True)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=len(train_ds.sequences), gamma=0.7)\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(1, training_iter + 1):\n",
    "        for datum in zip(*train_dataloaders):\n",
    "            train_x = torch.stack([data['esm2'] for data in datum]).to(device)\n",
    "            train_y = torch.stack([data['norm_interface_score'] for data in datum]).float().to(device)\n",
    "            #train_y = torch.cat(train_y, axis = -1)\n",
    "            n_ensemble, batch_size = list(train_y.size())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(train_x)\n",
    "            #print(outputs.reshape(n_ensemble * batch_size, -1).shape)\n",
    "            #print(train_y.reshape(n_ensemble * batch_size, -1).shape)\n",
    "            loss = F.mse_loss(\n",
    "                    outputs.reshape(n_ensemble * batch_size, -1), train_y.reshape(n_ensemble * batch_size, -1)\n",
    "            )\n",
    "                     \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            global_step += 1\n",
    "            if global_step != 0 and global_step % 10 == 0:\n",
    "                print(f\"[Train] epoch:{epoch} \\t global step:{global_step} \\t loss:{loss:.4f}\")\n",
    "            \n",
    "            \n",
    "                model.eval()\n",
    "                test_loss = 0\n",
    "                correct = 0\n",
    "                with torch.no_grad():\n",
    "                    for data in test_dataloader:\n",
    "                        model_inputs = torch.stack([data['esm2']] * 5).to(device)\n",
    "                        target = data['norm_interface_score'].to(device)\n",
    "\n",
    "                        outputs = model(model_inputs)\n",
    "                        output = torch.mean(outputs, axis=1)\n",
    "\n",
    "                        test_loss += F.mse_loss(output, target, reduction=\"sum\").item()\n",
    "                       \n",
    "        test_loss /= len(test_dataloader.dataset)\n",
    "        print(f\"[Valid] Average loss: {test_loss:.4f}\")\n",
    "        model.train()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_gps_simple(model_name, model, likelihood, train_ds, test_ds, scores, training_iter, device, lr = 0.1,\n",
    "                     encoding = 'esm2'):\n",
    "    observed_preds = []\n",
    "    val_per_iter = []\n",
    "    test_ys = []\n",
    "    #ids = np.random.choice(np.arange(len(train_ds.sequences)), size = 10000)\n",
    "    trained_models = []\n",
    "    for score in scores:\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()  \n",
    "        \n",
    "        if encoding == 'esm2':\n",
    "            train_x = torch.tensor(train_ds.embeddings['esm2']).to(device)\n",
    "            train_x = F.normalize(train_x)\n",
    "            train_y = torch.tensor(train_ds.scores['norm_' + score]).to(device)\n",
    "            test_x = torch.tensor(test_ds.embeddings['esm2']).to(device)\n",
    "            test_x = F.normalize(test_x)\n",
    "            test_y = torch.tensor(test_ds.scores['norm_' + score]).to(device)\n",
    "        else:\n",
    "            train_x = torch.stack(train_ds.embeddings['onehot']).to(device)\n",
    "            train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "            train_x = F.normalize(train_x)\n",
    "\n",
    "            train_y = torch.tensor(train_ds.scores['norm_' + score]).to(device)\n",
    "            \n",
    "            test_x =  torch.stack(test_ds.embeddings['onehot']).to(device)\n",
    "            test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "            test_x = F.normalize(test_x)\n",
    "\n",
    "            test_y = torch.tensor(test_ds.scores['norm_' + score]).to(device)\n",
    "\n",
    "\n",
    "        \n",
    "        likelihood = likelihood.to(device)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Includes GaussianLikelihood parameters\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        loss_dict = {'loss':[], 'noise': [], 'train_iter': [], \n",
    "                     'mae':[], 'nlpd':[], 'msll':[], 'mse':[]}\n",
    "        for i in range(training_iter):\n",
    "            model.train()\n",
    "            likelihood.train() \n",
    "            \n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = model(train_x)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "            #    i + 1, training_iter, loss.item(),\n",
    "            #    model.covar_module.base_kernel.lengthscale.item(),\n",
    "            #    model.likelihood.noise.item()\n",
    "            #))\n",
    "            if model_name != 'FixedNoiseGP':\n",
    "                print('Iter %d/%d - Loss: %.3f     noise: %.3f' % (\n",
    "                    i + 1, training_iter, loss.item(),\n",
    "                    #model.covar_module.base_kernel.lengthscale.item(),\n",
    "                    model.likelihood.noise.item()\n",
    "                ))\n",
    "                loss_dict['loss'].append(loss.item())\n",
    "                loss_dict['noise'].append(model.likelihood.noise.item())\n",
    "                loss_dict['train_iter'].append(i)\n",
    "            else:\n",
    "                print('Iter %d/%d - Loss: %.3f     noise: %.3f' % (\n",
    "                    i + 1, training_iter, loss.item(),\n",
    "                    #model.covar_module.base_kernel.lengthscale.item(),\n",
    "                    model.likelihood.noise[0].item()\n",
    "                ))\n",
    "                loss_dict['loss'].append(loss.item())\n",
    "                loss_dict['noise'].append(model.likelihood.noise[0].item())\n",
    "                loss_dict['train_iter'].append(i)\n",
    "                \n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            likelihood.eval()\n",
    "            \n",
    "            if model_name != 'FixedNoiseGP':\n",
    "                with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "                    observed_pred = likelihood(model(test_x))\n",
    "                    loss_dict['mae'].append(gpytorch.metrics.mean_absolute_error(observed_pred, test_y).item())\n",
    "                    #loss_dict['mse'].append(gpytorch.metrics.mean_squared_error(observed_pred, test_y).item())\n",
    "                    #loss_dict['nlpd'].append(gpytorch.metrics.negative_log_predictive_density(observed_pred, test_y).item())\n",
    "                    #loss_dict['msll'].append(gpytorch.metrics.mean_standardized_log_loss(observed_pred, test_y).item())\n",
    "            else:\n",
    "                with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "                    test_noises = torch.ones(test_y.shape) * 0.01\n",
    "                    observed_pred = likelihood(model(test_x), noise = test_noises)\n",
    "                    loss_dict['mae'].append(gpytorch.metrics.mean_absolute_error(observed_pred, test_y).item())\n",
    "                \n",
    "        val_per_iter.append(loss_dict)\n",
    "        \n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        # Test points are regularly spaced along [0,1]\n",
    "        # Make predictions by feeding model through likelihood\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            observed_pred = likelihood(model(test_x))\n",
    "            \n",
    "        observed_preds.append(observed_pred)\n",
    "        test_ys.append(test_y)\n",
    "        \n",
    "        trained_models.append(model)\n",
    "    \n",
    "    plot_pearson(observed_preds, test_ys, scores, model_name)\n",
    "    plot_metrics_per_iter(val_per_iter, scores, model_name)\n",
    "    \n",
    "    return (trained_models, observed_preds, test_ys, val_per_iter)\n",
    "\n",
    "\n",
    "def train_multitask_gps_simple(model_name, model, likelihood, train_ds, test_ds, scores, training_iter, device, lr = 0.1):\n",
    "    observed_preds = []\n",
    "    val_per_iter = []\n",
    "    train_ys = []\n",
    "    test_ys = []\n",
    "    n_tasks = len(scores)\n",
    "    \n",
    "    trained_models = []\n",
    "    \n",
    "    train_x = torch.tensor(train_ds.embeddings['esm2']).to(device)\n",
    "    train_x = F.normalize(train_x)\n",
    "    \n",
    "    test_x = torch.tensor(test_ds.embeddings['esm2']).to(device)\n",
    "    test_x = F.normalize(test_x)\n",
    "    \n",
    "    for score in scores:\n",
    "        train_ys.append(torch.tensor(train_ds.scores['norm_' + score]).to(device).unsqueeze(-1))\n",
    "        test_ys.append(torch.tensor(test_ds.scores['norm_' + score]).to(device).unsqueeze(-1))\n",
    "    \n",
    "    train_y = torch.cat(train_ys, axis = -1)\n",
    "    test_y = torch.cat(test_ys, axis = -1)\n",
    "    \n",
    "    likelihood = likelihood.to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Includes GaussianLikelihood parameters\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    \n",
    "    loss_dict = {'loss':[], 'noise': [], 'train_iter': [], \n",
    "                     'mae':[], 'nlpd':[], 'msll':[], 'mse':[]}\n",
    "    \n",
    "    for i in range(training_iter):\n",
    "        model.train()\n",
    "        likelihood.train() \n",
    "\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        loss.backward()\n",
    "     \n",
    "        print('Iter %d/%d - Loss: %.3f     noise: %.3f' % (\n",
    "            i + 1, training_iter, loss.item(),\n",
    "            #model.covar_module.base_kernel.lengthscale.item(),\n",
    "            model.likelihood.noise.item()\n",
    "        ))\n",
    "        loss_dict['loss'].append(loss.item())\n",
    "        loss_dict['noise'].append(model.likelihood.noise.item())\n",
    "        loss_dict['train_iter'].append(i)\n",
    "            \n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "        \n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            observed_pred = likelihood(model(test_x))\n",
    "            loss_dict['mae'].append(gpytorch.metrics.mean_absolute_error(observed_pred, test_y).unsqueeze(1))\n",
    "            #loss_dict['mse'].append(gpytorch.metrics.mean_squared_error(observed_pred, test_y).item())\n",
    "            #loss_dict['nlpd'].append(gpytorch.metrics.negative_log_predictive_density(observed_pred, test_y).item())\n",
    "            #loss_dict['msll'].append(gpytorch.metrics.mean_standardized_log_loss(observed_pred, test_y).item())\n",
    "    \n",
    "    loss_dict['mae'] = torch.cat(loss_dict['mae'], axis = 1).transpose(1,0)\n",
    "    val_per_iter.append(loss_dict)\n",
    "   \n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Test points are regularly spaced along [0,1]\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_preds = likelihood(model(test_x))\n",
    "\n",
    "    trained_models.append(model)\n",
    "    #plot_pearson(observed_preds, test_ys, scores, model_name)\n",
    "    #plot_metrics_per_iter(val_per_iter, scores, model_name)\n",
    "\n",
    "    return (observed_preds, test_y, val_per_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(t1, batch_size = 128)\n",
    "test_dl = torch.utils.data.DataLoader(tt1, batch_size = len(test_ds_1.sequences))\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "n_layers = 2\n",
    "n_features = [128,32,1]\n",
    "dropout_prob = 0.3\n",
    "\n",
    "input_size = 19 * 125\n",
    "model = MLP(input_size, n_layers, n_features, dropout_prob)\n",
    "\n",
    "trainer = TrainerGeneral(model, optimizer, device, encoding = 'onehot_flatten', loss = 'bt', features = ['norm_mutations', 'norm_interface_potential', 'norm_catalytic_potential'], scores = ['norm_total_score'], epochs = 10)\n",
    "models = trainer.train(train_dl, test_dl)\n",
    "mc = trainer.predict_mc_dropout(next(iter(test_dl)), 'norm_total_score', forward_passes = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "plt.errorbar(mc['y'], mc['mean'], mc['std'], linestyle='None', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(mc['y'], mc['mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(t1, batch_size = 64)\n",
    "test_dl = torch.utils.data.DataLoader(tt1, batch_size = len(tt1.sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv('./data/all_metrics_esm8M_concat_embs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = t1.sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = [dff[dff['sequences'] == s].pppl.values[0] for s in t1.sequences]\n",
    "b1 = [dff[dff['sequences'] == s].pppl.values[0] for s in tt1.sequences]\n",
    "a2 = [dff[dff['sequences'] == s].pppl.values[0] for s in t2.sequences]\n",
    "b2 = [dff[dff['sequences'] == s].pppl.values[0] for s in tt2.sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.scores['pppl'] = a1\n",
    "tt1.scores['pppl'] = b1\n",
    "t2.scores['pppl'] = a2\n",
    "tt2.scores['pppl'] = b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "def plot_pearson(observed_preds, test_ys, scores, model_name):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, len(scores), figsize=(12, 4))\n",
    "    p = ['#9C6987', '#A690CC', '#8FBFE0', '#00F6FF', '#390099', '#FF5400', '#FFBD00', '#ADA59E']\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "    plt.suptitle(f'{model_name}', fontsize = 14, weight = 'bold')\n",
    "    for i in range(len(scores)):\n",
    "        corr_res =  pearsonr(test_ys[i].cpu().numpy(), observed_preds[i].mean.cpu().numpy())\n",
    "        axs[i].errorbar(test_ys[i].cpu().numpy(), observed_preds[i].mean.cpu().numpy(), \n",
    "                              yerr=observed_preds[i].stddev.cpu().numpy(), fmt='o', \n",
    "                              ecolor = p[i],\n",
    "                              elinewidth = 0.85,\n",
    "                              markersize = 3.5,\n",
    "                              c = 'black'\n",
    "                             )\n",
    "        axs[i].title.set_text(f'{scores[i]}, Corr=%.2f, p-val.=%.3f' % (corr_res.statistic, corr_res.pvalue))\n",
    "        axs[i].set_xlabel('Actual')\n",
    "        axs[i].set_ylabel('Predicted')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./out/{model_name}_r2.pdf\", bbox_inches='tight')\n",
    "    plt.savefig(f\"./out/{model_name}_r2.png\", bbox_inches='tight')\n",
    "    \n",
    "\n",
    "def plot_metrics_per_iter(val_per_iter, scores, model_name):\n",
    "    fig, axs = plt.subplots(3, len(scores), figsize=(12, 9), sharex=True)\n",
    "    p = ['#9C6987', '#A690CC', '#8FBFE0', '#00F6FF', '#390099', '#FF5400', '#FFBD00', '#ADA59E']\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "    plt.suptitle(f'{model_name}', fontsize = 14, weight = 'bold')\n",
    "    \n",
    "    for i in range(len(scores)):\n",
    "\n",
    "        axs[i][0].plot(val_per_iter[i]['train_iter'], val_per_iter[i]['loss'], \n",
    "                       c = p[i],\n",
    "                       linewidth=2.5)\n",
    "        axs[i][1].plot(val_per_iter[i]['train_iter'], val_per_iter[i]['noise'], '--',\n",
    "                       c = p[i],\n",
    "                       linewidth=2.5)\n",
    "        axs[i][2].plot(val_per_iter[i]['train_iter'], val_per_iter[i]['mse'], '-.r',\n",
    "                       c = p[i],\n",
    "                       linewidth=2.5)\n",
    "\n",
    "        axs[i][0].title.set_text(f'{scores[i]} - loss per train_iter')\n",
    "        axs[i][1].title.set_text(f'{scores[i]} - noise per train_iter')\n",
    "        axs[i][2].title.set_text(f'{scores[i]} - MSE per train_iter')\n",
    "\n",
    "        axs[i][0].set_xlabel('train_iter')\n",
    "        axs[i][0].set_ylabel('Loss')\n",
    "            \n",
    "        axs[i][1].set_xlabel('train_iter')\n",
    "        axs[i][1].set_ylabel('Noise')\n",
    "            \n",
    "        axs[i][2].set_xlabel('train_iter')\n",
    "        axs[i][2].set_ylabel('MSE')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./out/{model_name}_metrics.pdf\", bbox_inches='tight')\n",
    "    plt.savefig(f\"./out/{model_name}_metrics.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitness.gp import ExactGP\n",
    "\n",
    "def train_gps_simple(model_name, train_ds, test_ds, scores, training_iter, device, lr = 0.1,\n",
    "                     encoding = 'esm2'):\n",
    "    observed_preds = []\n",
    "    val_per_iter = []\n",
    "    test_ys = []\n",
    "    #ids = np.random.choice(np.arange(len(train_ds.sequences)), size = 10000)\n",
    "    trained_models = []\n",
    "    for score in scores:\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()  \n",
    "        \n",
    "        if encoding != 'onehot':\n",
    "            train_x = torch.tensor(train_ds.embeddings[encoding]).to(device)\n",
    "            train_x = F.normalize(train_x)\n",
    "            train_y = torch.tensor(train_ds.scores['norm_' + score]).to(device)\n",
    "            test_x = torch.tensor(test_ds.embeddings[encoding]).to(device)\n",
    "            test_x = F.normalize(test_x)\n",
    "            test_y = torch.tensor(test_ds.scores['norm_' + score]).to(device)\n",
    "        else:\n",
    "            train_x = torch.stack(train_ds.embeddings[encoding]).to(device)\n",
    "            train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "            train_x = F.normalize(train_x)\n",
    "\n",
    "            train_y = torch.tensor(train_ds.scores['norm_' + score]).to(device)\n",
    "            \n",
    "            test_x =  torch.stack(test_ds.embeddings[encoding]).to(device)\n",
    "            test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "            test_x = F.normalize(test_x)\n",
    "\n",
    "            test_y = torch.tensor(test_ds.scores['norm_' + score]).to(device)\n",
    "\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model = ExactGP(train_x, train_y, likelihood)\n",
    "        likelihood = likelihood.to(device)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        model.train()\n",
    "        likelihood.train()\n",
    "        # Use the adam optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Includes GaussianLikelihood parameters\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "        loss_dict = {'loss':[], 'noise': [], 'train_iter': [], \n",
    "                     'mae':[], 'nlpd':[], 'msll':[], 'mse':[]}\n",
    "        for i in range(training_iter):\n",
    "            model.train()\n",
    "            likelihood.train() \n",
    "            \n",
    "            # Zero gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Output from model\n",
    "            output = model(train_x)\n",
    "            # Calc loss and backprop gradients\n",
    "            loss = -mll(output, train_y)\n",
    "            loss.backward()\n",
    "            #print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "            #    i + 1, training_iter, loss.item(),\n",
    "            #    model.covar_module.base_kernel.lengthscale.item(),\n",
    "            #    model.likelihood.noise.item()\n",
    "            #))\n",
    "            if model_name != 'FixedNoiseGP':\n",
    "                print('Iter %d/%d - Loss: %.3f     noise: %.3f' % (\n",
    "                    i + 1, training_iter, loss.item(),\n",
    "                    #model.covar_module.base_kernel.lengthscale.item(),\n",
    "                    model.likelihood.noise.item()\n",
    "                ))\n",
    "                loss_dict['loss'].append(loss.item())\n",
    "                loss_dict['noise'].append(model.likelihood.noise.item())\n",
    "                loss_dict['train_iter'].append(i)\n",
    "            else:\n",
    "                print('Iter %d/%d - Loss: %.3f     noise: %.3f' % (\n",
    "                    i + 1, training_iter, loss.item(),\n",
    "                    #model.covar_module.base_kernel.lengthscale.item(),\n",
    "                    model.likelihood.noise[0].item()\n",
    "                ))\n",
    "                loss_dict['loss'].append(loss.item())\n",
    "                loss_dict['noise'].append(model.likelihood.noise[0].item())\n",
    "                loss_dict['train_iter'].append(i)\n",
    "                \n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            model.eval()\n",
    "            likelihood.eval()\n",
    "            \n",
    "            if model_name != 'FixedNoiseGP':\n",
    "                with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "                    observed_pred = likelihood(model(test_x))\n",
    "                    loss_dict['mae'].append(gpytorch.metrics.mean_absolute_error(observed_pred, test_y).item())\n",
    "                    #loss_dict['mse'].append(gpytorch.metrics.mean_squared_error(observed_pred, test_y).item())\n",
    "                    #loss_dict['nlpd'].append(gpytorch.metrics.negative_log_predictive_density(observed_pred, test_y).item())\n",
    "                    #loss_dict['msll'].append(gpytorch.metrics.mean_standardized_log_loss(observed_pred, test_y).item())\n",
    "            else:\n",
    "                with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "                    test_noises = torch.ones(test_y.shape) * 0.01\n",
    "                    observed_pred = likelihood(model(test_x), noise = test_noises)\n",
    "                    loss_dict['mae'].append(gpytorch.metrics.mean_absolute_error(observed_pred, test_y).item())\n",
    "                \n",
    "        val_per_iter.append(loss_dict)\n",
    "        \n",
    "        model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        # Test points are regularly spaced along [0,1]\n",
    "        # Make predictions by feeding model through likelihood\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            observed_pred = likelihood(model(test_x))\n",
    "            \n",
    "        observed_preds.append(observed_pred)\n",
    "        test_ys.append(test_y)\n",
    "        \n",
    "        trained_models.append(model)\n",
    "    \n",
    "    plot_pearson(observed_preds, test_ys, scores, model_name)\n",
    "    plot_metrics_per_iter(val_per_iter, scores, model_name)\n",
    "    \n",
    "    return (trained_models, observed_preds, test_ys, val_per_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_1 = None\n",
    "train_ds_2 = None\n",
    "test_ds_1 = None\n",
    "test_ds_2 = None\n",
    "embedding_dataset = None\n",
    "train_dl = None\n",
    "test_dl = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df_path = './data/all_scores_pooled.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# Defining the scores (regression values) and labels from the AIzymes run to be used in the torch Dataset\n",
    "scores = ['interface_score', 'total_score', 'catalytic_score', 'interface_potential', 'total_potential', 'catalytic_potential', 'generation', 'mutations']\n",
    "labels = ['score_taken_from', 'design_method', 'cat_resn', 'cat_resi', 'parent_index']\n",
    "    \n",
    "# Filtering out duplicate sequences and averaging scores\n",
    "def select_unique(df, scores, labels):\n",
    "    score_df = df.groupby('sequence')[scores].mean().reset_index()\n",
    "    label_df = df.drop_duplicates('sequence')[labels + ['sequence']]\n",
    "    df = pd.merge(score_df, label_df, on='sequence')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = select_unique(df, scores, labels)\n",
    "\n",
    "df = df[df['cat_resi'] == 14]\n",
    "train_df, test_df = train_test_split(df, test_size = 0.1)\n",
    "gp_ds_train = AIzymesDataset(train_df, scores, labels)\n",
    "gp_ds_test = AIzymesDataset(test_df, scores, labels)\n",
    "\n",
    "gp_ds_train.onehot_sequences()\n",
    "gp_ds_test.onehot_sequences()\n",
    "\n",
    "plm = EnzymePLM(device = device, pca_dim = 50) #Also make that PCA explained variance plot...\n",
    "pooling_methods = ['class'] #will not test 'concatenate' due to high dimensionality\n",
    "\n",
    "gp_ds_train.embed_sequences(plm, pooling_methods)\n",
    "gp_ds_test.embed_sequences(plm, pooling_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gp_ds_train\n",
    "\n",
    "temp = VDJ_dataset(ds.sequences, ds.labels['cat_resi'], task = 'multiclass.classification')\n",
    "temp_loader = torch.utils.data.DataLoader(temp, batch_size=64, shuffle=False)\n",
    "features, labs = gmvae.latent_features(temp_loader, return_labels = True)\n",
    "ds.embeddings['vae'] = [features[i] for i in range(features.shape[0])]\n",
    "\n",
    "t1 = ds\n",
    "\n",
    "\n",
    "ds = gp_ds_test\n",
    "\n",
    "temp = VDJ_dataset(ds.sequences, ds.labels['cat_resi'], task = 'multiclass.classification')\n",
    "temp_loader = torch.utils.data.DataLoader(temp, batch_size=64, shuffle=False)\n",
    "features, labs = gmvae.latent_features(temp_loader, return_labels = True)\n",
    "ds.embeddings['vae'] = [features[i] for i in range(features.shape[0])]\n",
    "\n",
    "tt1 = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import gpytorch\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_name = 'ExactGP'\n",
    "training_iter = 100\n",
    "out = train_gps_simple(model_name = model_name,  \n",
    "                       train_ds = gp_ds_train, \n",
    "                       test_ds = gp_ds_test, \n",
    "                       scores = ['total_score', 'interface_score', 'catalytic_score'], \n",
    "                       training_iter = training_iter, \n",
    "                       device = device, \n",
    "                       lr = 0.1,\n",
    "                       encoding = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {'loss': [], 'score': [], 'dataset': [], 'features': [], 'pearsonr': [], 'pval': []}\n",
    "scores_pred = ['norm_total_score']\n",
    "features = [['vae', 'class'], 'pca_concatenate', 'class', 'average', 'vae', 'onehot']\n",
    "encodings = ['aizymes_features', 'aizymes_features', 'aizymes_features', 'aizymes_features', 'aizymes_features', 'onehot_flatten']\n",
    "dims = [64 + 1280, 50, 1280, 125, 64, 19 * 125]\n",
    "losses = ['bt', 'mse']\n",
    "dataset_splits = ['90-10', 'one-vs-all']\n",
    "\n",
    "\n",
    "scores_pred = ['norm_total_score']\n",
    "features = [['vae', 'class'], ['norm_generation', 'norm_mutations'], ['norm_generation', 'norm_mutations', 'pppl']]\n",
    "encodings = ['aizymes_features', 'onehot_aizymes_features', 'onehot_aizymes_features']\n",
    "dims = [64 + 1280, 19 * 125 + 2, 19 * 125 + 3]\n",
    "losses = ['bt', 'mse']\n",
    "dataset_splits = ['90-10', 'one-vs-all']\n",
    "\n",
    "scores_pred = ['norm_total_score']\n",
    "features = [['pppl']]\n",
    "encodings = ['onehot_aizymes_features']\n",
    "dims = [19 * 125 + 1]\n",
    "losses = ['bt', 'mse']\n",
    "dataset_splits = ['90-10', 'one-vs-all']\n",
    "\n",
    "for data in dataset_splits:\n",
    "    if data == '90-10':\n",
    "        train_dl = torch.utils.data.DataLoader(t1, batch_size = 64)\n",
    "        test_dl = torch.utils.data.DataLoader(tt1, batch_size = len(tt1.sequences))\n",
    "    else:\n",
    "        train_dl = torch.utils.data.DataLoader(t2, batch_size = 64)\n",
    "        test_dl = torch.utils.data.DataLoader(tt2, batch_size = len(tt2.sequences))\n",
    "    \n",
    "    vals = next(iter(test_dl))\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        feature = features[i]\n",
    "            \n",
    "        input_size = dims[i]\n",
    "        encoding = encodings[i]\n",
    "        \n",
    "        for loss in losses:\n",
    "        \n",
    "            epochs = 10 #Seems decent ATM - most valid losses increase past this\n",
    "            n_layers = 2\n",
    "            n_features = [64,1]\n",
    "            dropout_prob = 0.3\n",
    "            model = MLP(input_size, n_layers, n_features, dropout_prob)\n",
    "            optimizer = torch.optim.Adam\n",
    "\n",
    "            trainer = TrainerGeneral(model, optimizer, device, \n",
    "                                     encoding = encoding, loss = loss, features = feature, \n",
    "                                     scores = scores_pred, epochs = epochs)\n",
    "            \n",
    "            models = trainer.train(train_dl, test_dl)\n",
    "\n",
    "            for score in scores_pred:\n",
    "                mc = trainer.predict_mc_dropout(vals, score, forward_passes = 50)\n",
    "                pears = pearsonr(mc['y'], mc['mean']).statistic\n",
    "                pvals = pearsonr(mc['y'], mc['mean']).pvalue\n",
    "                \n",
    "                output['loss'].append(loss)\n",
    "                output['score'].append(score)\n",
    "                output['dataset'].append(data)\n",
    "                feature_name = '_'.join(feature)\n",
    "                output['features'].append(feature_name)\n",
    "                output['pearsonr'].append(pears)\n",
    "                output['pval'].append(pvals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('trained_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=penguins, kind=\"bar\",\n",
    "    x=\"species\", y=\"body_mass_g\", hue=\"sex\",\n",
    "    errorbar=\"sd\", palette=\"dark\", alpha=.6, height=6\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"Body mass (g)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 50\n",
    "model = MLP(input_size, n_layers, n_features, dropout_prob)\n",
    "\n",
    "trainer = TrainerGeneral(model, optimizer, device, \n",
    "                         encoding = 'aizymes_features', loss = 'bt', features = ['pca_concatenate'], \n",
    "                         scores = scores_pred, epochs = 20)\n",
    "\n",
    "models = trainer.train(train_dl, test_dl)\n",
    "mc = trainer.predict_mc_dropout(next(iter(test_dl)), 'norm_total_score', forward_passes = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(mc['y'], mc['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'x_umap': out_umap[:,0],\n",
    "                   'y_umap': out_umap[:,1],\n",
    "                   'x_tsne': out_tsne[:,0],\n",
    "                   'y_tsne': out_tsne[:,1],\n",
    "                   'x_pca': out_pca[:,0],\n",
    "                   'y_pca': out_pca[:,1],\n",
    "                   'interface_score': ds.scores['interface_score'].tolist(),\n",
    "                   'catalytic_score': ds.scores['catalytic_score'].tolist(),\n",
    "                   'total_score': ds.scores['total_score'].tolist(),\n",
    "                   'total_potential': ds.scores['total_potential'].tolist(),\n",
    "                   'interface_potential': ds.scores['interface_potential'].tolist(),\n",
    "                   'catalytic_potential': ds.scores['catalytic_potential'].tolist(),\n",
    "                   'mutations': ds.scores['mutations'].tolist(),\n",
    "                   'generation': ds.scores['generation'].tolist(),\n",
    "                   'score_taken_from': np.array(ds.labels['score_taken_from']).tolist(),\n",
    "                   'design_method': np.array(ds.labels['design_method']).tolist(),\n",
    "                   'cat_resn': np.array(ds.labels['cat_resn']).tolist(),\n",
    "                   'cat_resi': np.array(ds.labels['cat_resi']).tolist(),\n",
    "                   'sequences': np.array(ds.sequences).tolist()\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "temp_df.sort_values(by = ['cat_resi'])\n",
    "temp_df['cat_resi'] = df['cat_resi'].astype(str)\n",
    "for dim in ['pca', 'umap', 'tsne']:\n",
    "    sns.set_style(\"white\")\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "\n",
    "    p = sns.color_palette()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "    fig.suptitle(f'VAE latent {dim} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "    ax1=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "    ax1.title.set_text('interface_score')\n",
    "    ax2=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "    ax2.title.set_text('catalytic_score')\n",
    "    ax3=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "    ax3.title.set_text('total_score')\n",
    "    ax4=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "    ax4.title.set_text('mutations')\n",
    "    ax5=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "    ax5.title.set_text('generation')\n",
    "    ax6=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'cat_resi', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "    ax6.title.set_text('cat_resi')\n",
    "\n",
    "    ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax6.legend(title = 'cat_resi: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use VAE to obtain latent feature vectors for each other dataset\n",
    "features = [features[i] for i in range(features.shape[0])]\n",
    "features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3AwnXvAqb3Y"
   },
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ['interface_score', 'total_score', 'catalytic_score', 'interface_potential', 'total_potential', 'catalytic_potential', 'generation', 'mutations', 'parent_index']\n",
    "labels = ['score_taken_from', 'design_method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['cat_resi'] == 18.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9KD1QoOqgKY"
   },
   "source": [
    "### AIzymes dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 3923,
     "status": "ok",
     "timestamp": 1709475391978,
     "user": {
      "displayName": "Tudor Stefan",
      "userId": "09613310521082799835"
     },
     "user_tz": -60
    },
    "id": "TiuYXl0zz8Xy",
    "outputId": "09b96aa9-eae2-4b92-a154-fe3a5a68e509"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t33_650M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 1050,
     "status": "error",
     "timestamp": 1709475391982,
     "user": {
      "displayName": "Tudor Stefan",
      "userId": "09613310521082799835"
     },
     "user_tz": -60
    },
    "id": "MoajG6gFKAfl",
    "outputId": "903d40d1-2c17-4fe8-d6d6-1601c33e19f3"
   },
   "outputs": [],
   "source": [
    "dss = AIzymesDataset(df, tokenizer, scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1709475410912,
     "user": {
      "displayName": "Tudor Stefan",
      "userId": "09613310521082799835"
     },
     "user_tz": -60
    },
    "id": "yyvwtom1eWW4"
   },
   "outputs": [],
   "source": [
    "train_ds = AIzymesDataset(train_df, tokenizer, scores, labels)\n",
    "test_ds = AIzymesDataset(test_df, tokenizer, scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "error",
     "timestamp": 1709475414397,
     "user": {
      "displayName": "Tudor Stefan",
      "userId": "09613310521082799835"
     },
     "user_tz": -60
    },
    "id": "rGg4lcmcnLTl",
    "outputId": "b902d2a7-5c39-49c2-a69d-668f6c14d6f6"
   },
   "outputs": [],
   "source": [
    "ds.embeddings = {}\n",
    "ds.pppl = {}\n",
    "plm = EnzymePLM(device = device)\n",
    "ds.embeddings['esm2'] = plm.embeddings_all(ds)\n",
    "del plm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "ds.embeddings['onehot'] = dss.onehot_sequences(ds.sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/all_metrics_esm8M_concat_embs.csv')\n",
    "df = df.drop_duplicates('sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['cat_resi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cat_resi'] == 14].iloc[250]['sequences'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in ['pca', 'umap', 'tsne']:\n",
    "    sns.set_style(\"white\")\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "\n",
    "    p = sns.color_palette()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "    fig.suptitle(f'ESM2 embeddings {dim} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "    ax1=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "    ax1.title.set_text('interface_score')\n",
    "    ax2=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "    ax2.title.set_text('catalytic_score')\n",
    "    ax3=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "    ax3.title.set_text('total_score')\n",
    "    ax4=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "    ax4.title.set_text('mutations')\n",
    "    ax5=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "    ax5.title.set_text('generation')\n",
    "    ax6=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'cat_resn', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "    ax6.title.set_text('cat_resn')\n",
    "\n",
    "    ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax6.legend(title = 'cat_resn: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resi in list(set(df['cat_resi'])):\n",
    "    inds = [i == resi for i in ds.labels['cat_resi']]\n",
    "    inds = np.array(inds)\n",
    "\n",
    "    out = np.array(ds.embeddings['esm2'])\n",
    "    out = out[inds]\n",
    "    umap = UMAP()\n",
    "    out_umap = umap.fit_transform(out)\n",
    "    tsne = TSNE(n_components = 2)\n",
    "    out_tsne = tsne.fit_transform(out)\n",
    "    pca = PCA(n_components = 2)\n",
    "    out_pca = pca.fit_transform(out)\n",
    "\n",
    "    temp_df = pd.DataFrame({'x_umap': out_umap[:,0],\n",
    "                       'y_umap': out_umap[:,1],\n",
    "                       'x_tsne': out_tsne[:,0],\n",
    "                       'y_tsne': out_tsne[:,1],\n",
    "                       'x_pca': out_pca[:,0],\n",
    "                       'y_pca': out_pca[:,1],\n",
    "                       'interface_score': ds.scores['interface_score'][inds].tolist(),\n",
    "                       'catalytic_score': ds.scores['catalytic_score'][inds].tolist(),\n",
    "                       'total_score': ds.scores['total_score'][inds].tolist(),\n",
    "                       'total_potential': ds.scores['total_potential'][inds].tolist(),\n",
    "                       'interface_potential': ds.scores['interface_potential'][inds].tolist(),\n",
    "                       'catalytic_potential': ds.scores['catalytic_potential'][inds].tolist(),\n",
    "                       'mutations': ds.scores['mutations'][inds].tolist(),\n",
    "                       'generation': ds.scores['generation'][inds].tolist(),\n",
    "                       'score_taken_from': np.array(ds.labels['score_taken_from'])[inds].tolist(),\n",
    "                       'design_method': np.array(ds.labels['design_method'])[inds].tolist(),\n",
    "                       'cat_resn': np.array(ds.labels['cat_resn'])[inds].tolist(),\n",
    "                       'cat_resi': np.array(ds.labels['cat_resi'])[inds].tolist(),\n",
    "                       'sequences': np.array(ds.sequences)[inds].tolist()\n",
    "                        })\n",
    "    \n",
    "    for dim in ['pca', 'umap', 'tsne']:\n",
    "        sns.set_style(\"white\")\n",
    "        plt.style.use('tableau-colorblind10')\n",
    "\n",
    "        p = sns.color_palette()\n",
    "\n",
    "        fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "        fig.suptitle(f'ESM2 embeddings {dim}_{resi} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "        ax1=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "        ax1.title.set_text('interface_score')\n",
    "        ax2=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "        ax2.title.set_text('catalytic_score')\n",
    "        ax3=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "        ax3.title.set_text('total_score')\n",
    "        ax4=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "        ax4.title.set_text('mutations')\n",
    "        ax5=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "        ax5.title.set_text('generation')\n",
    "        ax6=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'cat_resn', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "        ax6.title.set_text('cat_resn')\n",
    "\n",
    "        ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax6.legend(title = 'cat_resn: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f\"./out/avg_embeddings_{resi}_{dim}.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plm = EnzymePLM(device = device, pooling_method = 'concatenate')\n",
    "ds.embeddings['esm2_concat'] = plm.embeddings_all(ds)\n",
    "del plm\n",
    "\n",
    "plm = EnzymePLM(device = device, pooling_method = 'pooler')\n",
    "ds.embeddings['esm2_class'] = plm.embeddings_all(ds)\n",
    "del plm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resi in list(set(df['cat_resi'])):\n",
    "    inds = [i == resi for i in ds.labels['cat_resi']]\n",
    "    inds = np.array(inds)\n",
    "\n",
    "    out = np.array(ds.embeddings['esm2'])\n",
    "    out = out[inds]\n",
    "\n",
    "    exp_var_pca = pca.explained_variance_ratio_\n",
    "    #\n",
    "    # Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "    # for visualizing the variance explained by each principal component.\n",
    "    #\n",
    "    cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "    #\n",
    "    # Create the visualization plot\n",
    "    #\n",
    "    plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "    plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal component index')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(f\"./out/avg_embeddings_{resi}_{dim}.png\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resi in list(set(df['cat_resi'])):\n",
    "    inds = [i == resi for i in ds.labels['cat_resi']]\n",
    "    inds = np.array(inds)\n",
    "\n",
    "    out = np.array(ds.embeddings['esm2_concat'])\n",
    "    out = out[inds]\n",
    "    pca = PCA(n_components = 50)\n",
    "    out = pca.fit_transform(out)\n",
    "    \n",
    "    umap = UMAP()\n",
    "    out_umap = umap.fit_transform(out)\n",
    "    tsne = TSNE(n_components = 2)\n",
    "    out_tsne = tsne.fit_transform(out)\n",
    "    pca = PCA(n_components = 2)\n",
    "    out_pca = pca.fit_transform(out)\n",
    "\n",
    "    temp_df = pd.DataFrame({'x_umap': out_umap[:,0],\n",
    "                       'y_umap': out_umap[:,1],\n",
    "                       'x_tsne': out_tsne[:,0],\n",
    "                       'y_tsne': out_tsne[:,1],\n",
    "                       'x_pca': out_pca[:,0],\n",
    "                       'y_pca': out_pca[:,1],\n",
    "                       'interface_score': ds.scores['interface_score'][inds].tolist(),\n",
    "                       'catalytic_score': ds.scores['catalytic_score'][inds].tolist(),\n",
    "                       'total_score': ds.scores['total_score'][inds].tolist(),\n",
    "                       'total_potential': ds.scores['total_potential'][inds].tolist(),\n",
    "                       'interface_potential': ds.scores['interface_potential'][inds].tolist(),\n",
    "                       'catalytic_potential': ds.scores['catalytic_potential'][inds].tolist(),\n",
    "                       'mutations': ds.scores['mutations'][inds].tolist(),\n",
    "                       'generation': ds.scores['generation'][inds].tolist(),\n",
    "                       'score_taken_from': np.array(ds.labels['score_taken_from'])[inds].tolist(),\n",
    "                       'design_method': np.array(ds.labels['design_method'])[inds].tolist(),\n",
    "                       'cat_resn': np.array(ds.labels['cat_resn'])[inds].tolist(),\n",
    "                       'cat_resi': np.array(ds.labels['cat_resi'])[inds].tolist(),\n",
    "                       'sequences': np.array(ds.sequences)[inds].tolist()\n",
    "                        })\n",
    "    \n",
    "    for dim in ['pca', 'umap', 'tsne']:\n",
    "        sns.set_style(\"white\")\n",
    "        plt.style.use('tableau-colorblind10')\n",
    "\n",
    "        p = sns.color_palette()\n",
    "\n",
    "        fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "        fig.suptitle(f'ESM2 embeddings {dim}_{resi} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "        ax1=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "        ax1.title.set_text('interface_score')\n",
    "        ax2=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "        ax2.title.set_text('catalytic_score')\n",
    "        ax3=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "        ax3.title.set_text('total_score')\n",
    "        ax4=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "        ax4.title.set_text('mutations')\n",
    "        ax5=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "        ax5.title.set_text('generation')\n",
    "        ax6=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'cat_resn', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "        ax6.title.set_text('cat_resn')\n",
    "\n",
    "        ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax6.legend(title = 'cat_resn: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f\"./out/concat_embeddings_{resi}_{dim}.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resi in list(set(df['cat_resi'])):\n",
    "    inds = [i == resi for i in ds.labels['cat_resi']]\n",
    "    inds = np.array(inds)\n",
    "\n",
    "    out = np.array(ds.embeddings['esm2_class'])\n",
    "    out = out[inds]\n",
    "    umap = UMAP()\n",
    "    out_umap = umap.fit_transform(out)\n",
    "    tsne = TSNE(n_components = 2)\n",
    "    out_tsne = tsne.fit_transform(out)\n",
    "    pca = PCA(n_components = 2)\n",
    "    out_pca = pca.fit_transform(out)\n",
    "\n",
    "    temp_df = pd.DataFrame({'x_umap': out_umap[:,0],\n",
    "                       'y_umap': out_umap[:,1],\n",
    "                       'x_tsne': out_tsne[:,0],\n",
    "                       'y_tsne': out_tsne[:,1],\n",
    "                       'x_pca': out_pca[:,0],\n",
    "                       'y_pca': out_pca[:,1],\n",
    "                       'interface_score': ds.scores['interface_score'][inds].tolist(),\n",
    "                       'catalytic_score': ds.scores['catalytic_score'][inds].tolist(),\n",
    "                       'total_score': ds.scores['total_score'][inds].tolist(),\n",
    "                       'total_potential': ds.scores['total_potential'][inds].tolist(),\n",
    "                       'interface_potential': ds.scores['interface_potential'][inds].tolist(),\n",
    "                       'catalytic_potential': ds.scores['catalytic_potential'][inds].tolist(),\n",
    "                       'mutations': ds.scores['mutations'][inds].tolist(),\n",
    "                       'generation': ds.scores['generation'][inds].tolist(),\n",
    "                       'score_taken_from': np.array(ds.labels['score_taken_from'])[inds].tolist(),\n",
    "                       'design_method': np.array(ds.labels['design_method'])[inds].tolist(),\n",
    "                       'cat_resn': np.array(ds.labels['cat_resn'])[inds].tolist(),\n",
    "                       'cat_resi': np.array(ds.labels['cat_resi'])[inds].tolist(),\n",
    "                       'sequences': np.array(ds.sequences)[inds].tolist()\n",
    "                        })\n",
    "    \n",
    "    for dim in ['pca', 'umap', 'tsne']:\n",
    "        sns.set_style(\"white\")\n",
    "        plt.style.use('tableau-colorblind10')\n",
    "\n",
    "        p = sns.color_palette()\n",
    "\n",
    "        fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "        fig.suptitle(f'ESM2 embeddings {dim}_{resi} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "        ax1=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "        ax1.title.set_text('interface_score')\n",
    "        ax2=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "        ax2.title.set_text('catalytic_score')\n",
    "        ax3=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "        ax3.title.set_text('total_score')\n",
    "        ax4=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "        ax4.title.set_text('mutations')\n",
    "        ax5=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "        ax5.title.set_text('generation')\n",
    "        ax6=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'cat_resn', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "        ax6.title.set_text('cat_resn')\n",
    "\n",
    "        ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax6.legend(title = 'cat_resn: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f\"./out/class_embeddings_{resi}_{dim}.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.array(ds.embeddings['esm2'])\n",
    "\n",
    "umap = UMAP()\n",
    "out_umap = umap.fit_transform(out)\n",
    "tsne = TSNE(n_components = 2)\n",
    "out_tsne = tsne.fit_transform(out)\n",
    "pca = PCA(n_components = 2)\n",
    "out_pca = pca.fit_transform(out)\n",
    "\n",
    "temp_df = pd.DataFrame({'x_umap': out_umap[:,0],\n",
    "                   'y_umap': out_umap[:,1],\n",
    "                   'x_tsne': out_tsne[:,0],\n",
    "                   'y_tsne': out_tsne[:,1],\n",
    "                   'x_pca': out_pca[:,0],\n",
    "                   'y_pca': out_pca[:,1],\n",
    "                   'interface_score': ds.scores['interface_score'].tolist(),\n",
    "                   'catalytic_score': ds.scores['catalytic_score'].tolist(),\n",
    "                   'total_score': ds.scores['total_score'].tolist(),\n",
    "                   'total_potential': ds.scores['total_potential'].tolist(),\n",
    "                   'interface_potential': ds.scores['interface_potential'].tolist(),\n",
    "                   'catalytic_potential': ds.scores['catalytic_potential'].tolist(),\n",
    "                   'mutations': ds.scores['mutations'].tolist(),\n",
    "                   'generation': ds.scores['generation'].tolist(),\n",
    "                   'score_taken_from': ds.labels['score_taken_from'],\n",
    "                   'design_method': ds.labels['design_method'],\n",
    "                   'cat_resn': ds.labels['cat_resn'],\n",
    "                   'cat_resi': cat_resi,\n",
    "                   'sequences': ds.sequences\n",
    "                    })\n",
    "\n",
    "for dim in ['pca', 'umap', 'tsne']:\n",
    "    sns.set_style(\"white\")\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "\n",
    "    p = sns.color_palette()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "    fig.suptitle(f'ESM2 embeddings all_{dim} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "    ax1=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "    ax1.title.set_text('interface_score')\n",
    "    ax2=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "    ax2.title.set_text('catalytic_score')\n",
    "    ax3=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "    ax3.title.set_text('total_score')\n",
    "    ax4=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "    ax4.title.set_text('mutations')\n",
    "    ax5=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "    ax5.title.set_text('generation')\n",
    "    ax6=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'cat_resi', ax = axs[1,2], edgecolor = None, s=4)\n",
    "    ax6.title.set_text('cat_resi')\n",
    "\n",
    "    ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax6.legend(title = 'cat_resi: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"./out/avg_embeddings_all_{dim}.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in ['pca', 'umap', 'tsne']:\n",
    "    sns.set_style(\"white\")\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "\n",
    "    p = sns.color_palette()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "    fig.suptitle(f'ESM2 embeddings all_{dim} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "    ax1=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "    ax1.title.set_text('interface_score')\n",
    "    ax2=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "    ax2.title.set_text('catalytic_score')\n",
    "    ax3=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "    ax3.title.set_text('total_score')\n",
    "    ax4=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "    ax4.title.set_text('mutations')\n",
    "    ax5=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "    ax5.title.set_text('generation')\n",
    "    ax6=sns.scatterplot(data=temp_df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'cat_resi', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "    ax6.title.set_text('cat_resi')\n",
    "\n",
    "    ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax6.legend(title = 'cat_resi: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"./out/class_embeddings_all_{dim}.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "id": "93QiYrcverug"
   },
   "outputs": [],
   "source": [
    "train_ds.embeddings = {}\n",
    "test_ds.embeddings = {}\n",
    "\n",
    "plm = EnzymePLM(device = device)\n",
    "train_ds.embeddings['esm2'] = plm.embeddings_all(train_ds)\n",
    "test_ds.embeddings['esm2'] = plm.embeddings_all(test_ds)\n",
    "\n",
    "del plm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPO_u0-YnL0Y"
   },
   "outputs": [],
   "source": [
    "plm = EnzymePLM(device = device, plm = 'esm2_masked')\n",
    "ds.pppl['esm2'] = plm.pppl_all(ds)\n",
    "del plm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "vals_per_iter = val_per_iter[0]\n",
    "maes = vals_per_iter['mae'].cpu().detach().numpy()\n",
    "maes = np.array_split(maes, 3, axis = -1)\n",
    "maes = [flatten(x.tolist()) for x in maes]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(3, len(scores), figsize=(12, 9), sharex=True)\n",
    "p = sns.color_palette(\"Set2\")\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.suptitle(f'{model_name}', fontsize = 14, weight = 'bold')\n",
    "\n",
    "for i in range(len(scores)):\n",
    "\n",
    "    axs[i][0].plot(val_per_iter[0]['train_iter'], val_per_iter[0]['loss'], \n",
    "                   c = p[i],\n",
    "                   linewidth=2.5)\n",
    "    axs[i][1].plot(val_per_iter[0]['train_iter'], val_per_iter[0]['noise'], '--',\n",
    "                   c = p[i],\n",
    "                   linewidth=2.5)\n",
    "    axs[i][2].plot(val_per_iter[0]['train_iter'], maes[i], '-.r',\n",
    "                   c = p[i],\n",
    "                   linewidth=2.5)\n",
    "\n",
    "    axs[i][0].title.set_text(f'{scores[i]} - loss per train_iter')\n",
    "    axs[i][1].title.set_text(f'{scores[i]} - noise per train_iter')\n",
    "    axs[i][2].title.set_text(f'{scores[i]} - MAE per train_iter')\n",
    "\n",
    "    axs[i][0].set_xlabel('train_iter')\n",
    "    axs[i][0].set_ylabel('Loss')\n",
    "\n",
    "    axs[i][1].set_xlabel('train_iter')\n",
    "    axs[i][1].set_ylabel('Noise')\n",
    "\n",
    "    axs[i][2].set_xlabel('train_iter')\n",
    "    axs[i][2].set_ylabel('MAE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./{model_name}_metrics.pdf\", bbox_inches='tight')\n",
    "plt.savefig(f\"./{model_name}_metrics.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdlNklQkP9Of"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJzHfrMOh2TU"
   },
   "outputs": [],
   "source": [
    "def roll_col(X, shift):\n",
    "    \"\"\"\n",
    "    Rotate columns to right by shift.\n",
    "    \"\"\"\n",
    "    return torch.cat((X[..., -shift:], X[..., :-shift]), dim=-1)\n",
    "\n",
    "\n",
    "def compute_ranking_loss(f_samps, target_y):\n",
    "    \"\"\"\n",
    "    Compute ranking loss for each sample from the posterior over target points.\n",
    "\n",
    "    Args:\n",
    "        f_samps: `n_samples x (n) x n`-dim tensor of samples\n",
    "        target_y: `n x 1`-dim tensor of targets\n",
    "    Returns:\n",
    "        Tensor: `n_samples`-dim tensor containing the ranking loss across each sample\n",
    "    \"\"\"\n",
    "    n = target_y.shape[0]\n",
    "    if f_samps.ndim == 3:\n",
    "        # Compute ranking loss for target model\n",
    "        # take cartesian product of target_y\n",
    "        cartesian_y = torch.cartesian_prod(\n",
    "            target_y.squeeze(-1),\n",
    "            target_y.squeeze(-1),\n",
    "        ).view(n, n, 2)\n",
    "        # the diagonal of f_samps are the out-of-sample predictions\n",
    "        # for each LOO model, compare the out of sample predictions to each in-sample prediction\n",
    "        rank_loss = (\n",
    "            (\n",
    "                (f_samps.diagonal(dim1=1, dim2=2).unsqueeze(-1) < f_samps)\n",
    "                ^ (cartesian_y[..., 0] < cartesian_y[..., 1])\n",
    "            )\n",
    "            .sum(dim=-1)\n",
    "            .sum(dim=-1)\n",
    "        )\n",
    "    else:\n",
    "        rank_loss = torch.zeros(\n",
    "            f_samps.shape[0], dtype=torch.long, device=target_y.device\n",
    "        )\n",
    "        y_stack = target_y.squeeze(-1).expand(f_samps.shape)\n",
    "        for i in range(1, target_y.shape[0]):\n",
    "            rank_loss += (\n",
    "                (roll_col(f_samps, i) < f_samps) ^ (roll_col(y_stack, i) < y_stack)\n",
    "            ).sum(dim=-1)\n",
    "    return rank_loss\n",
    "\n",
    "\n",
    "def get_target_model_loocv_sample_preds(\n",
    "    train_x, train_y, target_model, num_samples\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a batch-mode LOOCV GP and draw a joint sample across all points from the target task.\n",
    "\n",
    "    Args:\n",
    "        train_x: `n x d` tensor of training points\n",
    "        train_y: `n x 1` tensor of training targets\n",
    "        target_model: fitted target model\n",
    "        num_samples: number of mc samples to draw\n",
    "\n",
    "    Return: `num_samples x n x n`-dim tensor of samples, where dim=1 represents the `n` LOO models,\n",
    "        and dim=2 represents the `n` training points.\n",
    "    \"\"\"\n",
    "    batch_size = len(train_x)\n",
    "    masks = torch.eye(len(train_x), dtype=torch.uint8, device=device).bool()\n",
    "    train_x_cv = torch.stack([train_x[~m] for m in masks])\n",
    "    train_y_cv = torch.stack([train_y[~m] for m in masks])\n",
    "    state_dict = target_model.state_dict()\n",
    "    # expand to batch size of batch_mode LOOCV model\n",
    "    state_dict_expanded = {\n",
    "        name: t.expand(batch_size, *[-1 for _ in range(t.ndim)])\n",
    "        for name, t in state_dict.items()\n",
    "    }\n",
    "    model = get_fitted_model(\n",
    "        train_x_cv, train_y_cv, state_dict=state_dict_expanded\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        posterior = model.posterior(train_x)\n",
    "        # Since we have a batch mode gp and model.posterior always returns an output dimension,\n",
    "        # the output from `posterior.sample()` here `num_samples x n x n x 1`, so let's squeeze\n",
    "        # the last dimension.\n",
    "        sampler = SobolQMCNormalSampler(sample_shape=torch.Size([num_samples]))\n",
    "        return sampler(posterior).squeeze(-1)\n",
    "\n",
    "\n",
    "def compute_rank_weights(train_x, train_y, base_models, target_model, num_samples):\n",
    "    \"\"\"\n",
    "    Compute ranking weights for each base model and the target model (using\n",
    "        LOOCV for the target model). Note: This implementation does not currently\n",
    "        address weight dilution, since we only have a small number of base models.\n",
    "\n",
    "    Args:\n",
    "        train_x: `n x d` tensor of training points (for target task)\n",
    "        train_y: `n` tensor of training targets (for target task)\n",
    "        base_models: list of base models\n",
    "        target_model: target model\n",
    "        num_samples: number of mc samples\n",
    "\n",
    "    Returns:\n",
    "        Tensor: `n_t`-dim tensor with the ranking weight for each model\n",
    "    \"\"\"\n",
    "    ranking_losses = []\n",
    "    # compute ranking loss for each base model\n",
    "    for task in range(len(base_models)):\n",
    "        model = base_models[task]\n",
    "        # compute posterior over training points for target task\n",
    "        posterior = model.posterior(train_x)\n",
    "        sampler = SobolQMCNormalSampler(sample_shape=torch.Size([num_samples]))\n",
    "        base_f_samps = sampler(posterior).squeeze(-1).squeeze(-1)\n",
    "        # compute and save ranking loss\n",
    "        ranking_losses.append(compute_ranking_loss(base_f_samps, train_y))\n",
    "    # compute ranking loss for target model using LOOCV\n",
    "    # f_samps\n",
    "    target_f_samps = get_target_model_loocv_sample_preds(\n",
    "        train_x,\n",
    "        train_y,\n",
    "        target_model,\n",
    "        num_samples,\n",
    "    )\n",
    "    ranking_losses.append(compute_ranking_loss(target_f_samps, train_y))\n",
    "    ranking_loss_tensor = torch.stack(ranking_losses)\n",
    "    # compute best model (minimum ranking loss) for each sample\n",
    "    best_models = torch.argmin(ranking_loss_tensor, dim=0)\n",
    "    # compute proportion of samples for which each model is best\n",
    "    rank_weights = (\n",
    "        best_models.bincount(minlength=len(ranking_losses)).type_as(train_x)\n",
    "        / num_samples\n",
    "    )\n",
    "    return rank_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzaFmVLe0_ZA"
   },
   "outputs": [],
   "source": [
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from gpytorch.models import GP\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.lazy import PsdSumLazyTensor\n",
    "from gpytorch.likelihoods import LikelihoodList\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "\n",
    "class RGPE(GP, GPyTorchModel):\n",
    "    \"\"\"\n",
    "    Rank-weighted GP ensemble. Note: this class inherits from GPyTorchModel which provides an\n",
    "        interface for GPyTorch models in botorch.\n",
    "    \"\"\"\n",
    "\n",
    "    _num_outputs = 1  # metadata for botorch\n",
    "\n",
    "    def __init__(self, models, weights):\n",
    "        super().__init__()\n",
    "        self.models = ModuleList(models)\n",
    "        for m in models:\n",
    "            if not hasattr(m, \"likelihood\"):\n",
    "                raise ValueError(\n",
    "                    \"RGPE currently only supports models that have a likelihood (e.g. ExactGPs)\"\n",
    "                )\n",
    "        self.likelihood = LikelihoodList(*[m.likelihood for m in models])\n",
    "        self.weights = weights\n",
    "        self.to(weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weighted_means = []\n",
    "        weighted_covars = []\n",
    "        # filter model with zero weights\n",
    "        # weights on covariance matrices are weight**2\n",
    "        non_zero_weight_indices = (self.weights**2 > 0).nonzero()\n",
    "        non_zero_weights = self.weights[non_zero_weight_indices]\n",
    "        # re-normalize\n",
    "        non_zero_weights /= non_zero_weights.sum()\n",
    "\n",
    "        for non_zero_weight_idx in range(non_zero_weight_indices.shape[0]):\n",
    "            raw_idx = non_zero_weight_indices[non_zero_weight_idx].item()\n",
    "            model = self.models[raw_idx]\n",
    "            posterior = model.posterior(x)\n",
    "            # unstandardize predictions\n",
    "            posterior_mean = posterior.mean.squeeze(-1) * model.Y_std + model.Y_mean\n",
    "            posterior_cov = posterior.mvn.lazy_covariance_matrix * model.Y_std.pow(2)\n",
    "            # apply weight\n",
    "            weight = non_zero_weights[non_zero_weight_idx]\n",
    "            weighted_means.append(weight * posterior_mean)\n",
    "            weighted_covars.append(posterior_cov * weight**2)\n",
    "        # set mean and covariance to be the rank-weighted sum the means and covariances of the\n",
    "        # base models and target model\n",
    "        mean_x = torch.stack(weighted_means).sum(dim=0)\n",
    "        covar_x = PsdSumLazyTensor(*weighted_covars)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwwnXqVxo59U"
   },
   "outputs": [],
   "source": [
    "from botorch.models.transforms import Normalize, Standardize\n",
    "\n",
    "def get_fitted_model(train_X, train_Y, state_dict=None):\n",
    "    \"\"\"\n",
    "    Get a single task GP. The model will be fit unless a state_dict with model\n",
    "        hyperparameters is provided.\n",
    "    \"\"\"\n",
    "    Y_mean = train_Y.mean(dim=-2, keepdim=True)\n",
    "    Y_std = train_Y.std(dim=-2, keepdim=True)\n",
    "    model = SingleTaskGP(train_X, (train_Y - Y_mean) / Y_std)\n",
    "    model.Y_mean = Y_mean\n",
    "    model.Y_std = Y_std\n",
    "    if state_dict is None:\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model).to(train_X)\n",
    "        fit_gpytorch_mll(mll)\n",
    "    else:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2XFWHejo6LV"
   },
   "outputs": [],
   "source": [
    "def train_model(train_X, train_Y, model, state_dict = None):\n",
    "    \"\"\"\n",
    "    Get a single task GP. The model will be fit unless a state_dict with model\n",
    "        hyperparameters is provided.\n",
    "    \"\"\"\n",
    "    Y_mean = train_Y.mean(dim=-2, keepdim=True)\n",
    "    Y_std = train_Y.std(dim=-2, keepdim=True)\n",
    "    #model = SingleTaskGP(train_X, (train_Y - Y_mean) / Y_std)\n",
    "    model.Y_mean = Y_mean\n",
    "    model.Y_std = Y_std\n",
    "    if state_dict is None:\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model).to(train_X)\n",
    "        fit_gpytorch_mll(mll)\n",
    "    else:\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmKeOFUdgrhD"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import normalize, unnormalize\n",
    "\n",
    "# suppress GPyTorch warnings about adding jitter\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"^.*jitter.*\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "best_rgpe_all = []\n",
    "best_random_all = []\n",
    "best_vanilla_nei_all = []\n",
    "N_BATCH = 128 if not SMOKE_TEST else 2\n",
    "NUM_POSTERIOR_SAMPLES = 256 if not SMOKE_TEST else 16\n",
    "RANDOM_INITIALIZATION_SIZE = 3\n",
    "N_TRIALS = 10 if not SMOKE_TEST else 2\n",
    "MC_SAMPLES = 512 if not SMOKE_TEST else 32\n",
    "N_RESTART_CANDIDATES = 512 if not SMOKE_TEST else 8\n",
    "N_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "Q_BATCH_SIZE = 1\n",
    "N_EPOCHS = 1000\n",
    "noise_std = 0.05\n",
    "\n",
    "BOUNDS = torch.tensor([[-10.0], [10.0]], dtype=dtype, device=device)\n",
    "\n",
    "\n",
    "best_rgpe = []\n",
    "final_rank_weights = []\n",
    "tasks = ['interface_score', 'catalytic_score']\n",
    "\n",
    "base_model_list = []\n",
    "dl = torch.utils.data.DataLoader(train_ds, batch_size = N_BATCH)\n",
    "\n",
    "batch = next(iter(dl))\n",
    "\n",
    "for task in tasks:\n",
    "    print(f\"Fitting base model {task}\")\n",
    "    train_x = batch['esm2'].double().cuda()\n",
    "    train_x = normalize(train_x, bounds = BOUNDS)\n",
    "    train_y = batch[task].double()\n",
    "    train_y = train_y.unsqueeze(1).cuda()\n",
    "\n",
    "\n",
    "    model = get_fitted_model(\n",
    "        train_x,\n",
    "        train_y,\n",
    "\n",
    "    )\n",
    "\n",
    "    base_model_list.append(model)\n",
    "\n",
    "train_x = batch['esm2'].double().cuda()\n",
    "train_x = normalize(train_x, bounds = BOUNDS)\n",
    "train_y = batch['total_score'].double()\n",
    "train_y = train_y.unsqueeze(1).cuda()\n",
    "\n",
    "target_model = get_fitted_model(\n",
    "        train_x,\n",
    "        train_y,\n",
    "    )\n",
    "\n",
    "model_list = base_model_list + [target_model]\n",
    "\n",
    "\n",
    "# keep track of the best observed point at each iteration\n",
    "# best_value = train_y.max().item()\n",
    "#dl = torch.utils.data.DataLoader(train_ds, batch_size = N_BATCH)\n",
    "\n",
    "\n",
    "out_dict = {task:[] for task in tasks}\n",
    "out_dict.update({'step':[], 'epoch':[]})\n",
    "out_dict.update({'total_score':[]})\n",
    "\n",
    "for iteration in range(N_EPOCHS):\n",
    "    #step=0\n",
    "    for step, batch in enumerate(dl, 0):\n",
    "        for i, task in enumerate(tasks):\n",
    "            print(f\"Fitting base model {task}\")\n",
    "            train_x = batch['esm2'].double().cuda()\n",
    "            train_x = normalize(train_x, bounds = BOUNDS)\n",
    "            train_y = batch[task].double()\n",
    "            train_y = train_y.unsqueeze(1).cuda()\n",
    "\n",
    "\n",
    "            base_model_list[i] = train_model(\n",
    "                train_x,\n",
    "                train_y,\n",
    "                base_model_list[i]\n",
    "            )\n",
    "\n",
    "        train_x = batch['esm2'].double().cuda()\n",
    "        train_x = normalize(train_x, bounds = BOUNDS)\n",
    "        train_y = batch['total_score'].double()\n",
    "        train_y = train_y.unsqueeze(1).cuda()\n",
    "\n",
    "\n",
    "        model_list[len(model_list)-1] = train_model(train_x, train_y, model_list[len(model_list)-1])\n",
    "        target_model = model_list[len(model_list)-1]\n",
    "        rank_weights = compute_rank_weights(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            base_model_list,\n",
    "            target_model,\n",
    "            NUM_POSTERIOR_SAMPLES,\n",
    "        )\n",
    "\n",
    "       #rgpe_model = RGPE(model_list, rank_weights)\n",
    "\n",
    "        out = dict(zip(tasks + ['total_score'], rank_weights))\n",
    "        for key in out.keys():\n",
    "            out_dict[key].append(out[key].item())\n",
    "\n",
    "        out_dict['step'].append(step)\n",
    "        out_dict['epoch'].append(iteration)\n",
    "        #step += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 1820,
     "status": "error",
     "timestamp": 1709082604356,
     "user": {
      "displayName": "Tudor Stefan",
      "userId": "09613310521082799835"
     },
     "user_tz": -60
    },
    "id": "qlL74xgb2AGY",
    "outputId": "8fa78fef-1b1e-4707-ea44-3e6a5107fa23"
   },
   "outputs": [],
   "source": [
    "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import normalize, unnormalize\n",
    "\n",
    "# suppress GPyTorch warnings about adding jitter\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \"^.*jitter.*\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "best_rgpe_all = []\n",
    "best_random_all = []\n",
    "best_vanilla_nei_all = []\n",
    "N_BATCH = 10 if not SMOKE_TEST else 2\n",
    "NUM_POSTERIOR_SAMPLES = 256 if not SMOKE_TEST else 16\n",
    "RANDOM_INITIALIZATION_SIZE = 3\n",
    "N_TRIALS = 10 if not SMOKE_TEST else 2\n",
    "MC_SAMPLES = 512 if not SMOKE_TEST else 32\n",
    "N_RESTART_CANDIDATES = 512 if not SMOKE_TEST else 8\n",
    "N_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "Q_BATCH_SIZE = 1\n",
    "\n",
    "\n",
    "\n",
    "best_rgpe = []\n",
    "best_random = []\n",
    "best_vanilla_nei = []\n",
    "\n",
    "train_x = torch.tensor(ds.embeddings['esm2']).double().cuda()\n",
    "train_y = torch.tensor(ds.scores['total_score']).double()\n",
    "train_y = train_y.unsqueeze(1).cuda()\n",
    "train_yvar = torch.full_like(train_y, noise_std**2).cuda()\n",
    "vanilla_nei_train_x = train_x.clone()\n",
    "vanilla_nei_train_y = train_y.clone()\n",
    "vanilla_nei_train_yvar = train_yvar.clone()\n",
    "# keep track of the best observed point at each iteration\n",
    "best_value = train_y.max().item()\n",
    "best_rgpe.append(best_value)\n",
    "best_random.append(best_value)\n",
    "vanilla_nei_best_value = best_value\n",
    "best_vanilla_nei.append(vanilla_nei_best_value)\n",
    "\n",
    "# Run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "for iteration in range(N_BATCH):\n",
    "    target_model = get_fitted_model(train_x[:100,], train_y[:100,], train_yvar[:100,])\n",
    "    model_list = base_model_list + [target_model]\n",
    "    rank_weights = compute_rank_weights(\n",
    "        train_x.double(),\n",
    "        train_y.double(),\n",
    "        base_model_list,\n",
    "        target_model,\n",
    "        NUM_POSTERIOR_SAMPLES,\n",
    "    )\n",
    "\n",
    "    # create model and acquisition function; acquisition = sobol sample by PC1\n",
    "    rgpe_model = RGPE(model_list, rank_weights)\n",
    "    sampler_qnei = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
    "    qNEI = qNoisyExpectedImprovement(\n",
    "        model=rgpe_model,\n",
    "        X_baseline=train_x,\n",
    "        sampler=sampler_qnei,\n",
    "        prune_baseline=False,\n",
    "    )\n",
    "\n",
    "    # optimize\n",
    "    candidate, _ = optimize_acqf(\n",
    "        acq_function=qNEI,\n",
    "        bounds=torch.tensor([[0.0], [1.0]], dtype=dtype, device=device),\n",
    "        q=Q_BATCH_SIZE,\n",
    "        num_restarts=N_RESTARTS,\n",
    "        raw_samples=N_RESTART_CANDIDATES,\n",
    "    )\n",
    "\n",
    "    # fetch the new values\n",
    "    new_x = candidate.detach()\n",
    "    new_y_noiseless = f(unnormalize(new_x, bounds=BOUNDS))\n",
    "    new_y = new_y_noiseless + noise_std * torch.randn_like(new_y_noiseless)\n",
    "    new_yvar = torch.full_like(new_y, noise_std**2)\n",
    "\n",
    "    # update training points\n",
    "    train_x = torch.cat((train_x, new_x))\n",
    "    train_y = torch.cat((train_y, new_y))\n",
    "    train_yvar = torch.cat((train_yvar, new_yvar))\n",
    "    random_candidate = torch.rand(1, dtype=dtype, device=device)\n",
    "    next_random_noiseless = f(unnormalize(random_candidate, bounds=BOUNDS))\n",
    "    next_random = next_random_noiseless + noise_std * torch.randn_like(\n",
    "        next_random_noiseless\n",
    "    )\n",
    "    next_random_best = next_random.max().item()\n",
    "    best_random.append(max(best_random[-1], next_random_best))\n",
    "\n",
    "    # get the new best observed value\n",
    "    best_value = train_y.max().item()\n",
    "    best_rgpe.append(best_value)\n",
    "\n",
    "    # Run Vanilla NEI for comparison\n",
    "    vanilla_nei_model = get_fitted_model(\n",
    "        vanilla_nei_train_x,\n",
    "        vanilla_nei_train_y,\n",
    "        vanilla_nei_train_yvar,\n",
    "    )\n",
    "    vanilla_nei_sampler = SobolQMCNormalSampler(\n",
    "        sample_shape=torch.Size([MC_SAMPLES])\n",
    "    )\n",
    "    vanilla_qNEI = qNoisyExpectedImprovement(\n",
    "        model=vanilla_nei_model,\n",
    "        X_baseline=vanilla_nei_train_x,\n",
    "        sampler=vanilla_nei_sampler,\n",
    "    )\n",
    "    vanilla_nei_candidate, _ = optimize_acqf(\n",
    "        acq_function=vanilla_qNEI,\n",
    "        bounds=torch.tensor([[0.0], [1.0]], dtype=dtype, device=device),\n",
    "        q=Q_BATCH_SIZE,\n",
    "        num_restarts=N_RESTARTS,\n",
    "        raw_samples=N_RESTART_CANDIDATES,\n",
    "    )\n",
    "    # fetch the new values\n",
    "    vanilla_nei_new_x = vanilla_nei_candidate.detach()\n",
    "    vanilla_nei_new_y_noiseless = f(unnormalize(vanilla_nei_new_x, bounds=BOUNDS))\n",
    "    vanilla_nei_new_y = vanilla_nei_new_y_noiseless + noise_std * torch.randn_like(\n",
    "        new_y_noiseless\n",
    "    )\n",
    "    vanilla_nei_new_yvar = torch.full_like(vanilla_nei_new_y, noise_std**2)\n",
    "\n",
    "    # update training points\n",
    "    vanilla_nei_train_x = torch.cat([vanilla_nei_train_x, vanilla_nei_new_x])\n",
    "    vanilla_nei_train_y = torch.cat([vanilla_nei_train_y, vanilla_nei_new_y])\n",
    "    vanilla_nei_train_yvar = torch.cat(\n",
    "        [vanilla_nei_train_yvar, vanilla_nei_new_yvar]\n",
    "    )\n",
    "\n",
    "    # get the new best observed value\n",
    "    vanilla_nei_best_value = vanilla_nei_train_y.max().item()\n",
    "    best_vanilla_nei.append(vanilla_nei_best_value)\n",
    "\n",
    "best_rgpe_all.append(best_rgpe)\n",
    "best_random_all.append(best_random)\n",
    "best_vanilla_nei_all.append(best_vanilla_nei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESlYZKCbNglZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWTc0YyvneNw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-fljkVyn8Fz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZjtJhg0pbMk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ot7u4QEZqKF-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDktMzs8RRxg"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdiJVKQdWHXm"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x_umap': out_umap[:,0],\n",
    "                   'y_umap': out_umap[:,1],\n",
    "                   'x_tsne': out_tsne[:,0],\n",
    "                   'y_tsne': out_tsne[:,1],\n",
    "                   'x_pca': out_pca[:,0],\n",
    "                   'y_pca': out_pca[:,1],\n",
    "                   'interface_score': ds.scores['interface_score'].tolist(),\n",
    "                   'catalytic_score': ds.scores['catalytic_score'].tolist(),\n",
    "                   'total_score': ds.scores['total_score'].tolist(),\n",
    "                   'total_potential': ds.scores['total_potential'].tolist(),\n",
    "                   'interface_potential': ds.scores['interface_potential'].tolist(),\n",
    "                   'catalytic_potential': ds.scores['catalytic_potential'].tolist(),\n",
    "                   'mutations': ds.scores['mutations'].tolist(),\n",
    "                   'generation': ds.scores['generation'].tolist(),\n",
    "                   'score_taken_from': ds.labels['score_taken_from'],\n",
    "                   'design_method': ds.labels['design_method'],\n",
    "                   'cat_resn': ds.labels['cat_resn'],\n",
    "                   'cat_resi': ds.labels['cat_resi'],\n",
    "                   'sequences': ds.sequences,\n",
    "                   'pppl': ds.pppl['esm2']\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCFQX1ZlW_mq"
   },
   "outputs": [],
   "source": [
    "embs_df = pd.DataFrame(ds.embeddings['esm2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJiZtt5BXCkL"
   },
   "outputs": [],
   "source": [
    "embs_df['sequences'] = ds.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3D791R03XFKn"
   },
   "outputs": [],
   "source": [
    "#df.to_csv('./data/all_metrics_esm8M_concat_embs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHkb6tSfW6PQ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/all_metrics_esm8M_concat_embs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cYcBDK3MWAP"
   },
   "outputs": [],
   "source": [
    "df['cat_resi'] = df['cat_resi'].astype(float)\n",
    "\n",
    "df = df.sort_values(by = ['cat_resi', 'cat_resn'])\n",
    "df['cat_resi'] = df['cat_resi'].astype(str)\n",
    "df['cat_resn'] = df['cat_resn'].astype(str)\n",
    "df['cat'] = df['cat_resn'] + '_' + df['cat_resi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbfJbBgYNhwM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr=df.groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROPS = {'boxprops':{'edgecolor':'black'}}\n",
    "p = sns.color_palette()\n",
    "\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.style.use('tableau-colorblind10')\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = sns.violinplot(data = df, x = 'pppl', y = 'interface_score',hue = 'cat_resn',\n",
    "                    split= True, palette = p, inner=\"quart\")\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12, family = 'Futura', weight = 'bold')\n",
    "plt.ylabel(\"Interface score\", fontsize=14, family = 'Futura')\n",
    "plt.xlabel(\"cat_resi\", fontsize=14, family = 'Futura')\n",
    "plt.title(f'Interface score per catalytic residue index', fontsize = 20, weight = 'bold', family = 'Futura')\n",
    "fig.tight_layout()\n",
    "\n",
    "#plt.savefig('boxplot.png', facecolor= ax.get_facecolor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKgz1HiAWNlg"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy import stats\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "\n",
    "def annotate(ax, data, x, y):\n",
    "    slope, intercept, rvalue, pvalue, stderr = scipy.stats.linregress(x=data[x], y=data[y])\n",
    "    rmse = mean_squared_error(data[x], data[y], squared=False)\n",
    "    ax.text(.02, .9, f'R2={rvalue ** 2:.3f}, p={pvalue:.4g},', transform=ax.transAxes, fontsize = 10, family = 'Futura')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['cat_resi'] == 30.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/all_metrics_esm8M_concat_embs.csv')\n",
    "df = df.drop_duplicates('sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(df['pppl'], df['total_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(df['pppl'], df['total_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kbX6UQFZ9QH"
   },
   "outputs": [],
   "source": [
    "p = sns.color_palette()\n",
    "fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "\n",
    "\n",
    "ax1 = sns.scatterplot(data=df, x='pppl', y=\"interface_score\", ax = axs[0][0], edgecolor = None, linewidth=1.5, s=5, color = p[0])\n",
    "ax1.title.set_text('interface_score')\n",
    "annotate(ax1, data=df, x='pppl', y='interface_score')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['pppl'], df['interface_score'])\n",
    "p1 = sns.regplot(data = df, x = 'pppl', y = 'interface_score', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[0][0], scatter = False, ci = None)\n",
    "\n",
    "ax2 = sns.scatterplot(data=df, x='pppl', y=\"catalytic_score\", ax = axs[0][1], edgecolor = None, linewidth=1.5, s=5, color = p[1])\n",
    "ax2.title.set_text('catalytic_score')\n",
    "annotate(ax2, data=df, x='pppl', y='catalytic_score')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['pppl'], df['catalytic_score'])\n",
    "p2 = sns.regplot(data = df, x = 'pppl', y = 'catalytic_score', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[0][1], scatter = False, ci = None)\n",
    "\n",
    "ax3 = sns.scatterplot(data=df, x='pppl', y=\"total_score\", ax = axs[0][2], edgecolor = None, linewidth=1.5, s=5, color = p[2])\n",
    "ax3.title.set_text('total_score')\n",
    "annotate(ax3, data=df, x='pppl', y='total_score')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['pppl'], df['total_score'])\n",
    "p3 = sns.regplot(data = df, x = 'pppl', y = 'total_score', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[0][2], scatter = False, ci = None)\n",
    "\n",
    "ax4 = sns.scatterplot(data=df, x='pppl', y=\"generation\", ax = axs[1][0], edgecolor = None, linewidth=1.5, s=5, color = p[3])\n",
    "ax4.title.set_text('generation')\n",
    "annotate(ax4, data=df, x='pppl', y='generation')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['pppl'], df['generation'])\n",
    "p4 = sns.regplot(data = df, x = 'pppl', y = 'generation', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[1][0], scatter = False, ci = None)\n",
    "\n",
    "ax5 = sns.scatterplot(data=df, x='pppl', y=\"mutations\", ax = axs[1][1], edgecolor = None, linewidth=1.5, s=5, color = p[4])\n",
    "ax5.title.set_text('mutations')\n",
    "annotate(ax5, data=df, x='pppl', y='mutations')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['pppl'], df['mutations'])\n",
    "p5 = sns.regplot(data = df, x = 'pppl', y = 'mutations', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[1][1], scatter = False, ci = None)\n",
    "\n",
    "ax6 = sns.scatterplot(data=df, x='pppl', y=\"total_potential\", ax = axs[1][2], edgecolor = None, linewidth=1.5, s=5, color = p[5])\n",
    "ax6.title.set_text('total_potential')\n",
    "annotate(ax6, data=df, x='pppl', y='total_potential')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df['pppl'], df['total_potential'])\n",
    "p6 = sns.regplot(data = df, x = 'pppl', y = 'total_potential', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[1][2], scatter = False, ci = None)\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"./out/corrs_pppl_all.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKdwrBvpzWbr"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5959,
     "status": "ok",
     "timestamp": 1709209148501,
     "user": {
      "displayName": "Tudor Stefan",
      "userId": "09613310521082799835"
     },
     "user_tz": -60
    },
    "id": "T44xaVqYfS5s",
    "outputId": "b5d84842-d277-41eb-bc8c-07687640acd5"
   },
   "outputs": [],
   "source": [
    "p = sns.color_palette()\n",
    "fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "\n",
    "x = 'total_score'\n",
    "ax1 = sns.scatterplot(data=df, x=x, y=\"interface_score\", ax = axs[0][0], edgecolor = None, linewidth=1.5, s=5, color = p[0])\n",
    "ax1.title.set_text('interface_score')\n",
    "annotate(ax1, data=df, x=x, y='interface_score')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df[x], df['interface_score'])\n",
    "p1 = sns.regplot(data = df, x = x, y = 'interface_score', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[0][0], scatter = False, ci = None)\n",
    "\n",
    "ax2 = sns.scatterplot(data=df, x=x, y=\"catalytic_score\", ax = axs[0][1], edgecolor = None, linewidth=1.5, s=5, color = p[1])\n",
    "ax2.title.set_text('catalytic_score')\n",
    "annotate(ax2, data=df, x=x, y='catalytic_score')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df[x], df['catalytic_score'])\n",
    "p2 = sns.regplot(data = df, x =x, y = 'catalytic_score', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[0][1], scatter = False, ci = None)\n",
    "\n",
    "ax3 = sns.scatterplot(data=df, x=x, y=\"pppl\", ax = axs[0][2], edgecolor = None, linewidth=1.5, s=5, color = p[2])\n",
    "ax3.title.set_text('pppl')\n",
    "annotate(ax3, data=df, x=x, y='pppl')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df[x], df['total_score'])\n",
    "p3 = sns.regplot(data = df, x = x, y = 'pppl', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[0][2], scatter = False, ci = None)\n",
    "\n",
    "ax4 = sns.scatterplot(data=df, x=x, y=\"generation\", ax = axs[1][0], edgecolor = None, linewidth=1.5, s=5, color = p[3])\n",
    "ax4.title.set_text('generation')\n",
    "annotate(ax4, data=df, x=x, y='generation')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df[x], df['generation'])\n",
    "p4 = sns.regplot(data = df, x = x, y = 'generation', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[1][0], scatter = False, ci = None)\n",
    "\n",
    "ax5 = sns.scatterplot(data=df, x=x, y=\"mutations\", ax = axs[1][1], edgecolor = None, linewidth=1.5, s=5, color = p[4])\n",
    "ax5.title.set_text('mutations')\n",
    "annotate(ax5, data=df, x=x, y='mutations')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df[x], df['mutations'])\n",
    "p5 = sns.regplot(data = df, x = x, y = 'mutations', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[1][1], scatter = False, ci = None)\n",
    "\n",
    "ax6 = sns.scatterplot(data=df, x=x, y=\"total_potential\", ax = axs[1][2], edgecolor = None, linewidth=1.5, s=5, color = p[5])\n",
    "ax6.title.set_text('total_potential')\n",
    "annotate(ax6, data=df, x=x, y='total_potential')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df[x], df['total_potential'])\n",
    "p6 = sns.regplot(data = df, x = x, y = 'total_potential', line_kws={'label':\"y = {0:.2f} x {1:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'},\n",
    "                 ax = axs[1][2], scatter = False, ci = None)\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"./out/corrs_totalpot_all.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bb4mdh4DN61k"
   },
   "outputs": [],
   "source": [
    "df_temp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8__bLDOCRtA1"
   },
   "outputs": [],
   "source": [
    "seq, idx = np.unique(ds.sequences, return_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvVznmFVRieH"
   },
   "outputs": [],
   "source": [
    "df_temp = df_temp.iloc[idx,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FV_lYJkgO9Zu"
   },
   "outputs": [],
   "source": [
    "df = df_temp[df_temp['cat_resi'] == '14.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['cat_resi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = df[['total_score', 'catalytic_score', 'interface_score', 'pppl','cat_resi']].groupby(['cat_resi']).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = df[['total_score', 'catalytic_score', 'interface_score', 'pppl','cat_resi']].groupby(['cat_resi']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = df[['total_score', 'catalytic_score', 'interface_score', 'pppl','cat_resi']].groupby(['cat_resi']).sem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_resi = std.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "p = mcolors.XKCD_COLORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.color_palette()\n",
    "p = ['#F75C55','#F9DA7A','#ADA59E','#FE6E34','#2219D1','#F5D7BC','#D5DCF2','#590925','#1AFFD5','#007FFF','#7D83FF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.extend(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(cat_resi)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(ax, data, x, y):\n",
    "    slope, intercept, rvalue, pvalue, stderr = scipy.stats.linregress(x=data[x], y=data[y])\n",
    "    rmse = mean_squared_error(data[x], data[y], squared=False)\n",
    "    ax.text(.02, .9, f'R2={rvalue ** 2:.3f}, p={pvalue:.4g},', transform=ax.transAxes, fontsize = 10, family = 'Futura')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg['cat_resi'] = avg.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.annotate(txt, (avg_sub['pppl'] * 1.01, avg_sub['total_score']), ha='right', va='bottom', bbox=dict(facecolor='none', edgecolor='black', boxstyle='round', alpha=0.3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope, intercept, r_value, p_value, std_err = stats.linregress(avg['interface_score'], avg['pppl'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 'total_score'\n",
    "sns.set_style(\"white\")\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "\n",
    "axs = [[] for i in range(len(cat_resi))]\n",
    "ts = []\n",
    "for i, txt in enumerate(cat_resi):\n",
    "    avg_sub = avg.iloc[i]\n",
    "    std_sub = std.iloc[i]\n",
    "\n",
    "    c = colors[i]\n",
    "    axs[i] = plt.errorbar(avg_sub['pppl'], avg_sub[score], xerr=std_sub['pppl'], yerr=std_sub[score], fmt='o', c = c, capsize = 2, label = cat_resi[i])\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(avg['pppl'], avg[score])\n",
    "sns.regplot(data = avg, x = 'pppl', y = score, line_kws={'label':\"R2 = {2:.3f}, p = {3:.3f}\".format(slope,intercept, r_value, p_value), 'color':'black', 'ls':'--'})\n",
    "plt.title(score)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"./out/{score}.png\", bbox_inches='tight')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [list(p.values())[i] for i in range(len(std.index.tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=df, x=\"pppl\", y=\"total_score\", errorbar=\"sd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for resi in list(set(temp_df['cat_resi'])):\n",
    "    df = temp_df[temp_df['cat_resi'] == resi]\n",
    "\n",
    "    for dim in ['pca']:\n",
    "        sns.set_style(\"white\")\n",
    "        plt.style.use('tableau-colorblind10')\n",
    "\n",
    "        p = sns.color_palette()\n",
    "\n",
    "        fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "        fig.suptitle(f'ESM2 embeddings {dim}_{resi} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "        ax1=sns.scatterplot(data=df, x=f\"x_{dim}\", y='interface_score', hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "        ax1.title.set_text('interface_score')\n",
    "        ax2=sns.scatterplot(data=df, x=f\"x_{dim}\", y='catalytic_score', hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "        ax2.title.set_text('catalytic_score')\n",
    "        ax3=sns.scatterplot(data=df, x=f\"x_{dim}\", y='total_score', hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "        ax3.title.set_text('total_score')\n",
    "        ax4=sns.scatterplot(data=df, x=f\"x_{dim}\", y='mutations', hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "        ax4.title.set_text('mutations')\n",
    "        ax5=sns.scatterplot(data=df, x=f\"x_{dim}\", y='generation', hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "        ax5.title.set_text('generation')\n",
    "        ax6=sns.scatterplot(data=df, x=f\"x_{dim}\", y='pppl', hue = 'pppl', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "        ax6.title.set_text('pppl')\n",
    "\n",
    "        ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax6.legend(title = 'pppl: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f\"./out/embeddings_{resi}_{dim}.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = temp_df.copy()\n",
    "for dim in ['pca', 'umap', 'tsne']:\n",
    "        sns.set_style(\"white\")\n",
    "        plt.style.use('tableau-colorblind10')\n",
    "\n",
    "        p = sns.color_palette()\n",
    "\n",
    "        fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "        fig.suptitle(f'ESM2 embeddings {dim}_all colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "        ax1=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "        ax1.title.set_text('interface_score')\n",
    "        ax2=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "        ax2.title.set_text('catalytic_score')\n",
    "        ax3=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "        ax3.title.set_text('total_score')\n",
    "        ax4=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "        ax4.title.set_text('mutations')\n",
    "        ax5=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "        ax5.title.set_text('generation')\n",
    "        ax6=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'pppl', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "        ax6.title.set_text('pppl')\n",
    "\n",
    "        ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax6.legend(title = 'pppl: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f\"./out/embeddings_all_{dim}.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "executionInfo": {
     "elapsed": 10144,
     "status": "ok",
     "timestamp": 1709209610815,
     "user": {
      "displayName": "Tudor Stefan",
      "userId": "09613310521082799835"
     },
     "user_tz": -60
    },
    "id": "SsNuqe0WZ82Q",
    "outputId": "62f3582f-f055-4812-a9b0-2694156c92f3"
   },
   "outputs": [],
   "source": [
    "#temp_df = df.copy()\n",
    "for resi in list(set(temp_df['cat_resi'])):\n",
    "    df = temp_df[temp_df['cat_resi'] == resi]\n",
    "\n",
    "    for dim in ['pca', 'umap', 'tsne']:\n",
    "        sns.set_style(\"white\")\n",
    "        plt.style.use('tableau-colorblind10')\n",
    "\n",
    "        p = sns.color_palette()\n",
    "\n",
    "        fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "        fig.suptitle(f'ESM2 embeddings {dim}_{resi} colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "        ax1=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=4)\n",
    "        ax1.title.set_text('interface_score')\n",
    "        ax2=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=4)\n",
    "        ax2.title.set_text('catalytic_score')\n",
    "        ax3=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=4)\n",
    "        ax3.title.set_text('total_score')\n",
    "        ax4=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=4)\n",
    "        ax4.title.set_text('mutations')\n",
    "        ax5=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=4)\n",
    "        ax5.title.set_text('generation')\n",
    "        ax6=sns.scatterplot(data=df, x=f\"x_{dim}\", y=f\"y_{dim}\", hue = 'pppl', color = p[5], ax = axs[1,2], edgecolor = None, s=4)\n",
    "        ax6.title.set_text('pppl')\n",
    "\n",
    "        ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "        ax6.legend(title = 'pppl: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(f\"./out/embeddings_{resi}_{dim}.png\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 509
    },
    "executionInfo": {
     "elapsed": 9813,
     "status": "ok",
     "timestamp": 1709209644586,
     "user": {
      "displayName": "Tudor Stefan",
      "userId": "09613310521082799835"
     },
     "user_tz": -60
    },
    "id": "SiqvunVT0KAK",
    "outputId": "5e054682-5670-4f3f-8f26-506ece4ed6ba"
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "p = sns.color_palette()\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "fig.suptitle('ESM2 embeddings (PCA) colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "ax1=sns.scatterplot(data=df, x=\"x_umap\", y=\"y_umap\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=1)\n",
    "ax1.title.set_text('interface_score')\n",
    "ax2=sns.scatterplot(data=df, x=\"x_umap\", y=\"y_umap\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=1)\n",
    "ax2.title.set_text('catalytic_score')\n",
    "ax3=sns.scatterplot(data=df, x=\"x_umap\", y=\"y_umap\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=1)\n",
    "ax3.title.set_text('total_score')\n",
    "ax4=sns.scatterplot(data=df, x=\"x_umap\", y=\"y_umap\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=1)\n",
    "ax4.title.set_text('mutations')\n",
    "ax5=sns.scatterplot(data=df, x=\"x_umap\", y=\"y_umap\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=1)\n",
    "ax5.title.set_text('generation')\n",
    "ax6=sns.scatterplot(data=df, x=\"x_umap\", y=\"y_umap\", hue = 'pppl', color = p[5], ax = axs[1,2], edgecolor = None, s=1)\n",
    "ax6.title.set_text('cat')\n",
    "\n",
    "ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax6.legend(title = 'cat: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(\"embeddings.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings_metrics(df, projection, save_to):\n",
    "    \n",
    "    if projection.lower() == 'umap':\n",
    "        x = 'x_tsne'\n",
    "        y = 'y_tsne'\n",
    "        \n",
    "    elif projection.lower() == 'tsne':\n",
    "        x = 'x_tsne'\n",
    "        y = 'y_tsne'\n",
    "        \n",
    "    elif projection.lower() == 'pca':\n",
    "        x = 'x_pca'\n",
    "        y = 'y_pca'\n",
    "        \n",
    "    \n",
    "    sns.set_style(\"white\")\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "\n",
    "    p = sns.color_palette()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "    fig.suptitle(f'ESM2 embeddings ({projection}) colored by all_scores metrics', fontsize = 15, weight = 'bold')\n",
    "\n",
    "    ax1=sns.scatterplot(data=df, x=x, y=y, hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=1)\n",
    "    ax1.title.set_text('interface_score')\n",
    "    ax2=sns.scatterplot(data=df, x=x, y=y, hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=1)\n",
    "    ax2.title.set_text('catalytic_score')\n",
    "    ax3=sns.scatterplot(data=df, x=x, y=y, hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=1)\n",
    "    ax3.title.set_text('total_score')\n",
    "    ax4=sns.scatterplot(data=df, x=x, y=y, hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=1)\n",
    "    ax4.title.set_text('mutations')\n",
    "    ax5=sns.scatterplot(data=df, x=x, y=y, hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=1)\n",
    "    ax5.title.set_text('generation')\n",
    "    ax6=sns.scatterplot(data=df, x=x, y=y, hue = 'cat', color = p[5], ax = axs[1,2], edgecolor = None, s=1)\n",
    "    ax6.title.set_text('cat')\n",
    "\n",
    "    ax1.legend(title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax2.legend(title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax3.legend(title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax4.legend(title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax5.legend(title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    ax6.legend(title = 'cat: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    #plt.savefig(\"embeddings.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pppl_barplot(df, metric, save_to):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_distributions(df, metrics, save_to):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_duplicate_metrics(df, metrics, save_to):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_metrics(model, save_to):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_metrics(model, save_to):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoGJBdPd4hhr"
   },
   "outputs": [],
   "source": [
    "font1 = font_manager.FontProperties(family='Futura',\n",
    "                                    weight='bold',\n",
    "                                    style='normal')\n",
    "font2 = font_manager.FontProperties(family='Futura',\n",
    "                                    style='normal')\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "p = sns.color_palette()\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, sharex = True, figsize=(12, 6))\n",
    "fig.suptitle('ESM2 embeddings (PCA) colored by all_scores metrics', fontsize = 15, weight = 'bold', family = 'Futura')\n",
    "\n",
    "ax1=sns.scatterplot(data=df, x=\"x\", y=\"y\", hue = 'interface_score', color = p[0], ax = axs[0,0], edgecolor = None, s=10)\n",
    "ax1.title.set_text('interface_score')\n",
    "ax2=sns.scatterplot(data=df, x=\"x\", y=\"y\", hue = 'catalytic_score', color = p[1], ax = axs[0,1], edgecolor = None, s=10)\n",
    "ax2.title.set_text('catalytic_score')\n",
    "ax3=sns.scatterplot(data=df, x=\"x\", y=\"y\", hue = 'total_score', color = p[2], ax = axs[0,2], edgecolor = None, s=10)\n",
    "ax3.title.set_text('total_score')\n",
    "ax4=sns.scatterplot(data=df, x=\"x\", y=\"y\", hue = 'mutations', color = p[3], ax = axs[1,0], edgecolor = None, s=10)\n",
    "ax4.title.set_text('mutations')\n",
    "ax5=sns.scatterplot(data=df, x=\"x\", y=\"y\", hue = 'generation', color = p[4], ax = axs[1,1], edgecolor = None, s=10)\n",
    "ax5.title.set_text('generation')\n",
    "ax6=sns.scatterplot(data=df, x=\"x\", y=\"y\", hue = 'pppl', color = p[5], ax = axs[1,2], edgecolor = None, s=10)\n",
    "ax6.title.set_text('pppl')\n",
    "\n",
    "ax1.legend(prop=font2, title_fontproperties = font1, title = 'interface_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax2.legend(prop=font2, title_fontproperties = font1, title = 'catalytic_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax3.legend(prop=font2, title_fontproperties = font1, title = 'total_score: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax4.legend(prop=font2, title_fontproperties = font1, title = 'mutations: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax5.legend(prop=font2, title_fontproperties = font1, title = 'generation: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "ax6.legend(prop=font2, title_fontproperties = font1, title = 'pppl: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"embeddings.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbJOwNhcRNdG"
   },
   "outputs": [],
   "source": [
    "palette ={\"No\": \"C1\", \"Yes\": \"#80b559\"}\n",
    "from __future__ import unicode_literals\n",
    "mu = \"μ\"\n",
    "font1 = font_manager.FontProperties(family='Futura',\n",
    "                                   weight='bold',\n",
    "                                   style='normal')\n",
    "font2 = font_manager.FontProperties(family='Futura',\n",
    "                                   style='normal')\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.figure(figsize=(6,4.8), dpi=400)\n",
    "ax = sns.histplot(data=df, x=\"Droplet volume (μm3)\", bins = 20, hue = 'Surfactant', kde=True, edgecolor = 'black', palette = palette)\n",
    "#plt.legend(prop=font2, title_fontproperties = font1, title = 'Treatment: ')\n",
    "#plt.title(f'Monodispersity histograms with and without surfactants', fontsize = 14, weight = 'bold', family = 'Futura')\n",
    "plt.xlabel('Droplet volume ($\\mathregular{μm^3}$)', fontsize=12, family = 'Futura')\n",
    "plt.ylabel('Count', fontsize=12, family = 'Futura')\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='9', family = 'Futura') # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='12', family = 'Futura') # for legend text\n",
    "plt.tight_layout(pad = 1)\n",
    "plt.savefig('histogram_monodispersity_sampled.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "djKjn2Hwn-Hv"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': out[:,0],\n",
    "                   'y': out[:,1],\n",
    "                   'interface_score': ds.scores['interface_score'].tolist()})\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=260)\n",
    "sns.scatterplot(data=df, x='x', y=\"y\", hue = 'interface_score', s=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqfpbXH3QscA"
   },
   "outputs": [],
   "source": [
    "    font1 = font_manager.FontProperties(family='Futura',\n",
    "                                       weight='bold',\n",
    "                                       style='normal')\n",
    "    font2 = font_manager.FontProperties(family='Futura',\n",
    "                                       style='normal')\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "    plt.style.use('tableau-colorblind10')\n",
    "\n",
    "    p = sns.color_palette()\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, sharex = True, figsize=(10, 6))\n",
    "    fig.suptitle('Multiclass prediction metrics per identity% (true sequence - closest hit)', fontsize = 15, weight = 'bold', family = 'Futura')\n",
    "\n",
    "    sns.scatterplot(data=df, x=group_by, y=\"accuracy\", color = p[0], ax = axs[0,0], edgecolor = 'black', s=50)\n",
    "    sns.scatterplot(data=df, x=group_by, y=\"precision\", color = p[1], ax = axs[0,1], edgecolor = 'black', s=50)\n",
    "    sns.scatterplot(data=df, x=group_by, y=\"recall\", color = p[2], ax = axs[0,2], edgecolor = 'black', s=50)\n",
    "    sns.scatterplot(data=df, x=group_by, y=\"f1_score\", color = p[3], ax = axs[1,0], edgecolor = 'black', s=50)\n",
    "    sns.scatterplot(data=df, x=group_by, y=\"mcc\", color = p[4], ax = axs[1,1], edgecolor = 'black', s=50)\n",
    "    sns.scatterplot(data=df, x=group_by, y=\"balanced_accuracy\", color = p[5], ax = axs[1,2], edgecolor = 'black', s=50)\n",
    "    #plt.legend(prop=font2, title_fontproperties = font1, title = 'Classification metric: ', bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    #plt.ylabel(fontsize=10, family = 'Futura')\n",
    "    #plt.xlabel(fontsize=10, family = 'Futura')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(save_to, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyObrEHTyOtz2+r6yzmTv6sH",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1MDjE2FjfFUm0ZYipDOfNb4DJ6naFM1VK",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0685663edb54463497a70cecece305c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_195a7eeb4bbe40e6a67318294edce7f9",
      "placeholder": "​",
      "style": "IPY_MODEL_df22a32e193445fb821bae8f3b40c2ac",
      "value": "config.json: 100%"
     }
    },
    "06d01ec036014b339823c3296e312e31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa9dfe9ad32a41b883c18dc06a59876f",
      "placeholder": "​",
      "style": "IPY_MODEL_96a56abb377245e2934f37cfe57118a2",
      "value": " 93.0/93.0 [00:00&lt;00:00, 5.48kB/s]"
     }
    },
    "0eb253e874af4269b67c7717a1f56597": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f27dac103454c388722b54569c48cf3",
      "placeholder": "​",
      "style": "IPY_MODEL_736a6066ff294f74a9857dba9212b27b",
      "value": " 95.0/95.0 [00:00&lt;00:00, 4.75kB/s]"
     }
    },
    "14a7a93ed8f44f91a31e52f0b677541f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3053dad5ff24deaa923a4cef0aff837",
      "placeholder": "​",
      "style": "IPY_MODEL_d60cd4dae8b34b8e813c27e5975666a0",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "195a7eeb4bbe40e6a67318294edce7f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a9c55319d9646cb80bda143bb190938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b672df5f1ed84c3aaf7b6dbc11a46c78",
      "placeholder": "​",
      "style": "IPY_MODEL_dd9d474c360e4171b7712996b868f439",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "20cfba0371e947d8b18629f803ac18eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "271305e70aae4ab98a79f27744c2599b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "299a6f90958e4f448b2cfc5627404ec3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e1c65ed167e48088da7fe8401e28645": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f27dac103454c388722b54569c48cf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "301df300360044de8ee80f96fb3d0a68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14a7a93ed8f44f91a31e52f0b677541f",
       "IPY_MODEL_95a5fceea4ad40e0b463c5e075853344",
       "IPY_MODEL_0eb253e874af4269b67c7717a1f56597"
      ],
      "layout": "IPY_MODEL_ff48e9361e6342f5a9009965e3d09039"
     }
    },
    "339ce7fe87df4a028ac1affa989b54ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a9c55319d9646cb80bda143bb190938",
       "IPY_MODEL_ff2f95e52aaa4e358844a1c6945bc8d3",
       "IPY_MODEL_423399811ffa47d69f9c862dd274000b"
      ],
      "layout": "IPY_MODEL_c1eadaf0f621476f99c73024492b19ad"
     }
    },
    "357d73aaa73f477f962afff42cb6f81f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3833247573114ec981c0b4fcda1b783a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89d4d52874914091b0fd9ea316a0163f",
      "placeholder": "​",
      "style": "IPY_MODEL_f96af849eade46e79e0bdb581dbbfab1",
      "value": "vocab.txt: 100%"
     }
    },
    "401b660832f7432e8c3235a87422d16c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "423399811ffa47d69f9c862dd274000b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_728926f260a3439bab938db36036a85d",
      "placeholder": "​",
      "style": "IPY_MODEL_7158d9e526144a1bacd19166968ab205",
      "value": " 125/125 [00:00&lt;00:00, 4.38kB/s]"
     }
    },
    "465100248add4e22913dbca477bfce3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48a3b56b63f44d97bc14a7d4d798f358": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "49bdff3fe9cf4eb696cb05f59504f488": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_357d73aaa73f477f962afff42cb6f81f",
      "max": 724,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8cdceccb6ab4e79b5acfc719b9b7c07",
      "value": 724
     }
    },
    "68e58036535441ba82951472d1ca3f74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7158d9e526144a1bacd19166968ab205": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "728926f260a3439bab938db36036a85d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "736a6066ff294f74a9857dba9212b27b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "846e2867fbc44228aab07841dcd6ff83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87ace0ff733641748dfa0838b1b0f25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_846e2867fbc44228aab07841dcd6ff83",
      "placeholder": "​",
      "style": "IPY_MODEL_2e1c65ed167e48088da7fe8401e28645",
      "value": " 2.61G/2.61G [01:08&lt;00:00, 34.3MB/s]"
     }
    },
    "89d4d52874914091b0fd9ea316a0163f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93241e3217bd4e44b7c97152b025be61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95a5fceea4ad40e0b463c5e075853344": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5a2cb5f3936466abcc9eea18c272dcd",
      "max": 95,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7224b5df9604acda4fe309968aef84a",
      "value": 95
     }
    },
    "96a56abb377245e2934f37cfe57118a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a119cd8082a74a7d8ec704fdbd8fc8e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a546623d81b34b9f953a4ebbc46cc432": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a68e590aee41411c9ffa640329c63456": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa9dfe9ad32a41b883c18dc06a59876f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad87090ee3f94c34b2e66e8b6f51b006": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4852d2d60fa4188a1787fe082da6794",
      "placeholder": "​",
      "style": "IPY_MODEL_271305e70aae4ab98a79f27744c2599b",
      "value": " 724/724 [00:00&lt;00:00, 7.17kB/s]"
     }
    },
    "aea9e2e1a31747bb9e966a91b2ee9374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a68e590aee41411c9ffa640329c63456",
      "max": 2609506392,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48a3b56b63f44d97bc14a7d4d798f358",
      "value": 2609506392
     }
    },
    "b05d3a06d9f1476483ae8dbd1c015861": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb22a762225d4bd48aa0de7466d809b8",
       "IPY_MODEL_aea9e2e1a31747bb9e966a91b2ee9374",
       "IPY_MODEL_87ace0ff733641748dfa0838b1b0f25f"
      ],
      "layout": "IPY_MODEL_401b660832f7432e8c3235a87422d16c"
     }
    },
    "b3a5accd48b647889d14537f8205cbe8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3833247573114ec981c0b4fcda1b783a",
       "IPY_MODEL_ee02837a16854e74802f2e592372ad21",
       "IPY_MODEL_06d01ec036014b339823c3296e312e31"
      ],
      "layout": "IPY_MODEL_68e58036535441ba82951472d1ca3f74"
     }
    },
    "b672df5f1ed84c3aaf7b6dbc11a46c78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b90111b46ee744b59d379923fb499f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1eadaf0f621476f99c73024492b19ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4852d2d60fa4188a1787fe082da6794": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7224b5df9604acda4fe309968aef84a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cb22a762225d4bd48aa0de7466d809b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_299a6f90958e4f448b2cfc5627404ec3",
      "placeholder": "​",
      "style": "IPY_MODEL_b90111b46ee744b59d379923fb499f98",
      "value": "model.safetensors: 100%"
     }
    },
    "d60cd4dae8b34b8e813c27e5975666a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dab6f88626164e568782846a55b6e0c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0685663edb54463497a70cecece305c4",
       "IPY_MODEL_49bdff3fe9cf4eb696cb05f59504f488",
       "IPY_MODEL_ad87090ee3f94c34b2e66e8b6f51b006"
      ],
      "layout": "IPY_MODEL_93241e3217bd4e44b7c97152b025be61"
     }
    },
    "dd9d474c360e4171b7712996b868f439": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df22a32e193445fb821bae8f3b40c2ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee02837a16854e74802f2e592372ad21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_465100248add4e22913dbca477bfce3d",
      "max": 93,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a546623d81b34b9f953a4ebbc46cc432",
      "value": 93
     }
    },
    "f3053dad5ff24deaa923a4cef0aff837": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5a2cb5f3936466abcc9eea18c272dcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8cdceccb6ab4e79b5acfc719b9b7c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f96af849eade46e79e0bdb581dbbfab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff2f95e52aaa4e358844a1c6945bc8d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a119cd8082a74a7d8ec704fdbd8fc8e6",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20cfba0371e947d8b18629f803ac18eb",
      "value": 125
     }
    },
    "ff48e9361e6342f5a9009965e3d09039": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
