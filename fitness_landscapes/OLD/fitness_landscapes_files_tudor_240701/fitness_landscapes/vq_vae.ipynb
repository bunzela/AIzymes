{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69237f-38c2-4864-bcf2-a5aa315c20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.init as init\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d36be-6b04-4ff8-9035-38138d9eb65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as distributed\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "def is_protein(seq, aa_list):\n",
    "    \"\"\"\n",
    "    Check if a str corresponds to a protein sequence\n",
    "    return bool\n",
    "    \"\"\"\n",
    "    for aa in seq:\n",
    "        if aa not in aa_list:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def l_out_cnn1d(L_in:int,K:int,S:int,P:int,D:int=1) -> float:\n",
    "    '''Formula to find the L_out dimension of an input (dim=L_in)\n",
    "    in cnn_1d.'''\n",
    "    return (L_in+2*P-D*(K-1)-1)/S + 1\n",
    "\n",
    "def find_optimal_cnn1d_padding(L_in:int,K,S:int) -> Tuple[int,int]:\n",
    "    '''Find the minimal padding giving the kernel size K and stride S \n",
    "    for a CNN1D without losing any piece of information.'''\n",
    "    P=0\n",
    "    L_out = l_out_cnn1d(L_in,K,S,P)\n",
    "\n",
    "    assert L_in>=K, 'Kernel size higher than input dimension, the conv1d will not work'\n",
    "\n",
    "    while not L_out.is_integer() and 2*P<=S:\n",
    "        L_out = l_out_cnn1d(L_in,K,S,P)\n",
    "        P+=1\n",
    "\n",
    "    if 2*P>=S: P-=1\n",
    "    return math.floor(L_out), P\n",
    "\n",
    "def l_out_cnn1d_transpose(L_in:int,K:int,S:int,P:int,D:int=1) -> int:\n",
    "    '''Formula to find the L_out dimension of an input (dim=L_in)\n",
    "    in cnn_1d.'''\n",
    "    return (L_in-1)*S -2*P + D*(K-1) + 1\n",
    "\n",
    "def find_out_padding_cnn1d_transpose(L_obj:int,L_in:int,K:int,S:int,P:int) -> int:\n",
    "    '''Find the minimal output padding giving the kernel size K and stride S \n",
    "    to add after a CNN1D transpose layer to reach L_obj (objective).'''\n",
    "    L_out = l_out_cnn1d_transpose(L_in,K,S,P)\n",
    "    assert L_obj>=L_out, 'Make sure the padding is correct, the ouput \\\n",
    "            of the CNN1D transpose is larger than expeceted'\n",
    "    return L_obj-L_out\n",
    "\n",
    "# From the enhancing VQ (https://github.com/lucidrains/vector-quantize-pytorch/blob/master/vector_quantize_pytorch/vector_quantize_pytorch.py)\n",
    "# Copyright (c) 2020 Phil Wang (MIT Licenced)\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def noop(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "def l2norm(t):\n",
    "    return F.normalize(t, p = 2, dim = -1)\n",
    "\n",
    "def log(t, eps = 1e-20):\n",
    "    return torch.log(t.clamp(min = eps))\n",
    "\n",
    "def uniform_init(*shape):\n",
    "    t = torch.empty(shape)\n",
    "    nn.init.kaiming_uniform_(t)\n",
    "    return t\n",
    "\n",
    "def gumbel_noise(t):\n",
    "    noise = torch.zeros_like(t).uniform_(0, 1)\n",
    "    return -log(-log(noise))\n",
    "\n",
    "def gumbel_sample(t, temperature = 1., dim = -1):\n",
    "    if temperature == 0:\n",
    "        return t.argmax(dim = dim)\n",
    "\n",
    "    return ((t / temperature) + gumbel_noise(t)).argmax(dim = dim)\n",
    "\n",
    "def ema_inplace(moving_avg, new, decay):\n",
    "    moving_avg.data.mul_(decay).add_(new, alpha = (1 - decay))\n",
    "\n",
    "def laplace_smoothing(x, n_categories, eps = 1e-5):\n",
    "    return (x + eps) / (x.sum() + n_categories * eps)\n",
    "\n",
    "def sample_vectors(samples, num):\n",
    "    num_samples, device = samples.shape[0], samples.device\n",
    "    if num_samples >= num:\n",
    "        indices = torch.randperm(num_samples, device = device)[:num]\n",
    "    else:\n",
    "        indices = torch.randint(0, num_samples, (num,), device = device)\n",
    "\n",
    "    return samples[indices]\n",
    "\n",
    "def batched_sample_vectors(samples, num):\n",
    "    return torch.stack([sample_vectors(sample, num) for sample in samples.unbind(dim = 0)], dim = 0)\n",
    "\n",
    "def pad_shape(shape, size, dim = 0):\n",
    "    return [size if i == dim else s for i, s in enumerate(shape)]\n",
    "\n",
    "def sample_multinomial(total_count, probs):\n",
    "    device = probs.device\n",
    "    probs = probs.cpu()\n",
    "\n",
    "    total_count = probs.new_full((), total_count)\n",
    "    remainder = probs.new_ones(())\n",
    "    sample = torch.empty_like(probs, dtype = torch.long)\n",
    "\n",
    "    for i, p in enumerate(probs):\n",
    "        s = torch.binomial(total_count, p / remainder)\n",
    "        sample[i] = s\n",
    "        total_count -= s\n",
    "        remainder -= p\n",
    "\n",
    "    return sample.to(device)\n",
    "\n",
    "def all_gather_sizes(x, dim):\n",
    "    size = torch.tensor(x.shape[dim], dtype = torch.long, device = x.device)\n",
    "    all_sizes = [torch.empty_like(size) for _ in range(distributed.get_world_size())]\n",
    "    distributed.all_gather(all_sizes, size)\n",
    "    return torch.stack(all_sizes)\n",
    "\n",
    "def all_gather_variably_sized(x, sizes, dim = 0):\n",
    "    rank = distributed.get_rank()\n",
    "    all_x = []\n",
    "\n",
    "    for i, size in enumerate(sizes):\n",
    "        t = x if i == rank else x.new_empty(pad_shape(x.shape, size, dim))\n",
    "        distributed.broadcast(t, src = i, async_op = True)\n",
    "        all_x.append(t)\n",
    "\n",
    "    distributed.barrier()\n",
    "    return all_x\n",
    "\n",
    "def sample_vectors_distributed(local_samples, num):\n",
    "    local_samples = rearrange(local_samples, '1 ... -> ...')\n",
    "\n",
    "    rank = distributed.get_rank()\n",
    "    all_num_samples = all_gather_sizes(local_samples, dim = 0)\n",
    "\n",
    "    if rank == 0:\n",
    "        samples_per_rank = sample_multinomial(num, all_num_samples / all_num_samples.sum())\n",
    "    else:\n",
    "        samples_per_rank = torch.empty_like(all_num_samples)\n",
    "\n",
    "    distributed.broadcast(samples_per_rank, src = 0)\n",
    "    samples_per_rank = samples_per_rank.tolist()\n",
    "\n",
    "    local_samples = sample_vectors(local_samples, samples_per_rank[rank])\n",
    "    all_samples = all_gather_variably_sized(local_samples, samples_per_rank, dim = 0)\n",
    "    out = torch.cat(all_samples, dim = 0)\n",
    "\n",
    "    return rearrange(out, '... -> 1 ...')\n",
    "\n",
    "def batched_bincount(x, *, minlength):\n",
    "    batch, dtype, device = x.shape[0], x.dtype, x.device\n",
    "    target = torch.zeros(batch, minlength, dtype = dtype, device = device)\n",
    "    values = torch.ones_like(x)\n",
    "    target.scatter_add_(-1, x, values)\n",
    "    return target\n",
    "\n",
    "def kmeans(\n",
    "    samples,\n",
    "    num_clusters,\n",
    "    num_iters = 10,\n",
    "    use_cosine_sim = False,\n",
    "    sample_fn = batched_sample_vectors,\n",
    "    all_reduce_fn = noop\n",
    "):\n",
    "    num_codebooks, dim, dtype, device = samples.shape[0], samples.shape[-1], samples.dtype, samples.device\n",
    "\n",
    "    means = sample_fn(samples, num_clusters)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        if use_cosine_sim:\n",
    "            dists = samples @ rearrange(means, 'h n d -> h d n')\n",
    "        else:\n",
    "            dists = -torch.cdist(samples, means, p = 2)\n",
    "\n",
    "        buckets = torch.argmax(dists, dim = -1)\n",
    "        bins = batched_bincount(buckets, minlength = num_clusters)\n",
    "        all_reduce_fn(bins)\n",
    "\n",
    "        zero_mask = bins == 0\n",
    "        bins_min_clamped = bins.masked_fill(zero_mask, 1)\n",
    "\n",
    "        new_means = buckets.new_zeros(num_codebooks, num_clusters, dim, dtype = dtype)\n",
    "\n",
    "        new_means.scatter_add_(1, repeat(buckets, 'h n -> h n d', d = dim), samples)\n",
    "        new_means = new_means / rearrange(bins_min_clamped, '... -> ... 1')\n",
    "        all_reduce_fn(new_means)\n",
    "\n",
    "        if use_cosine_sim:\n",
    "            new_means = l2norm(new_means)\n",
    "\n",
    "        means = torch.where(\n",
    "            rearrange(zero_mask, '... -> ... 1'),\n",
    "            means,\n",
    "            new_means\n",
    "        )\n",
    "\n",
    "    return means, bins\n",
    "\n",
    "def batched_embedding(indices, embeds):\n",
    "    batch, dim = indices.shape[1], embeds.shape[-1]\n",
    "    indices = repeat(indices, 'h b n -> h b n d', d = dim)\n",
    "    embeds = repeat(embeds, 'h c d -> h b c d', b = batch)\n",
    "    return embeds.gather(2, indices)\n",
    "\n",
    "# regularization losses\n",
    "\n",
    "def orthogonal_loss_fn(t):\n",
    "    # eq (2) from https://arxiv.org/abs/2112.00384\n",
    "    h, n = t.shape[:2]\n",
    "    normed_codes = l2norm(t)\n",
    "    cosine_sim = einsum('h i d, h j d -> h i j', normed_codes, normed_codes)\n",
    "    return (cosine_sim ** 2).sum() / (h * n ** 2) - (1 / n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f7504b-22b2-4ef4-b0d9-00e703de254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as distributed\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "class CosineSimCodebook(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        codebook_size,\n",
    "        num_codebooks = 1,\n",
    "        kmeans_init = False,\n",
    "        kmeans_iters = 10,\n",
    "        sync_kmeans = True,\n",
    "        decay = 0.8,\n",
    "        eps = 1e-5,\n",
    "        threshold_ema_dead_code = 3,\n",
    "        use_ddp = False,\n",
    "        learnable_codebook = False,\n",
    "        sample_codebook_temp = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.decay = decay\n",
    "\n",
    "        if not kmeans_init:\n",
    "            embed = l2norm(uniform_init(num_codebooks, codebook_size, dim))\n",
    "        else:\n",
    "            embed = torch.zeros(num_codebooks, codebook_size, dim)\n",
    "\n",
    "        self.codebook_size = codebook_size\n",
    "        self.num_codebooks = num_codebooks\n",
    "\n",
    "        self.kmeans_iters = kmeans_iters\n",
    "        self.eps = eps\n",
    "        self.threshold_ema_dead_code = threshold_ema_dead_code\n",
    "        self.sample_codebook_temp = sample_codebook_temp\n",
    "\n",
    "        self.sample_fn = sample_vectors_distributed if use_ddp and sync_kmeans else batched_sample_vectors\n",
    "        self.kmeans_all_reduce_fn = distributed.all_reduce if use_ddp and sync_kmeans else noop\n",
    "        self.all_reduce_fn = distributed.all_reduce if use_ddp else noop\n",
    "\n",
    "        self.register_buffer('initted', torch.Tensor([not kmeans_init]))\n",
    "        self.register_buffer('cluster_size', torch.zeros(num_codebooks, codebook_size))\n",
    "\n",
    "        self.learnable_codebook = learnable_codebook\n",
    "        if learnable_codebook:\n",
    "            self.embed = nn.Parameter(embed)\n",
    "        else:\n",
    "            self.register_buffer('embed', embed)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def init_embed_(self, data):\n",
    "        if self.initted:\n",
    "            return\n",
    "\n",
    "        embed, cluster_size = kmeans(\n",
    "            data,\n",
    "            self.codebook_size,\n",
    "            self.kmeans_iters,\n",
    "            use_cosine_sim = True,\n",
    "            sample_fn = self.sample_fn,\n",
    "            all_reduce_fn = self.kmeans_all_reduce_fn\n",
    "        )\n",
    "\n",
    "        self.embed.data.copy_(embed)\n",
    "        self.cluster_size.data.copy_(cluster_size)\n",
    "        self.initted.data.copy_(torch.Tensor([True]))\n",
    "\n",
    "    def replace(self, batch_samples, batch_mask):\n",
    "        batch_samples = l2norm(batch_samples)\n",
    "\n",
    "        for ind, (samples, mask) in enumerate(zip(batch_samples.unbind(dim = 0), batch_mask.unbind(dim = 0))):\n",
    "            if not torch.any(mask):\n",
    "                continue\n",
    "\n",
    "            sampled = self.sample_fn(rearrange(samples, '... -> 1 ...'), mask.sum().item())\n",
    "            self.embed.data[ind][mask] = rearrange(sampled, '1 ... -> ...')\n",
    "\n",
    "    def expire_codes_(self, batch_samples):\n",
    "        if self.threshold_ema_dead_code == 0:\n",
    "            return\n",
    "\n",
    "        expired_codes = self.cluster_size < self.threshold_ema_dead_code\n",
    "\n",
    "        if not torch.any(expired_codes):\n",
    "            return\n",
    "\n",
    "        batch_samples = rearrange(batch_samples, 'h ... d -> h (...) d')\n",
    "        self.replace(batch_samples, batch_mask = expired_codes)\n",
    "\n",
    "    @autocast(enabled = False)\n",
    "    def forward(self, x):\n",
    "        needs_codebook_dim = x.ndim < 4\n",
    "\n",
    "        x = x.float()\n",
    "\n",
    "        if needs_codebook_dim:\n",
    "            x = rearrange(x, '... -> 1 ...')\n",
    "\n",
    "        shape, dtype = x.shape, x.dtype\n",
    "\n",
    "        flatten = rearrange(x, 'h ... d -> h (...) d')\n",
    "        flatten = l2norm(flatten)\n",
    "\n",
    "        self.init_embed_(flatten)\n",
    "\n",
    "        embed = self.embed if not self.learnable_codebook else self.embed.detach()\n",
    "        embed = l2norm(embed)\n",
    "\n",
    "        dist = einsum('h n d, h c d -> h n c', flatten, embed)\n",
    "        embed_ind = gumbel_sample(dist, dim = -1, temperature = self.sample_codebook_temp)\n",
    "        embed_onehot = F.one_hot(embed_ind, self.codebook_size).type(dtype)\n",
    "        embed_ind = embed_ind.view(*shape[:-1])\n",
    "\n",
    "        quantize = batched_embedding(embed_ind, self.embed)\n",
    "\n",
    "        if self.training:\n",
    "            bins = embed_onehot.sum(dim = 1)\n",
    "            self.all_reduce_fn(bins)\n",
    "\n",
    "            ema_inplace(self.cluster_size, bins, self.decay)\n",
    "\n",
    "            zero_mask = (bins == 0)\n",
    "            bins = bins.masked_fill(zero_mask, 1.)\n",
    "\n",
    "            embed_sum = einsum('h n d, h n c -> h c d', flatten, embed_onehot)\n",
    "            self.all_reduce_fn(embed_sum)\n",
    "\n",
    "            embed_normalized = embed_sum / rearrange(bins, '... -> ... 1')\n",
    "            embed_normalized = l2norm(embed_normalized)\n",
    "\n",
    "            embed_normalized = torch.where(\n",
    "                rearrange(zero_mask, '... -> ... 1'),\n",
    "                embed,\n",
    "                embed_normalized\n",
    "            )\n",
    "\n",
    "            ema_inplace(self.embed, embed_normalized, self.decay)\n",
    "            self.expire_codes_(x)\n",
    "\n",
    "        if needs_codebook_dim:\n",
    "            quantize, embed_ind = map(lambda t: rearrange(t, '1 ... -> ...'), (quantize, embed_ind))\n",
    "\n",
    "        return quantize, embed_ind\n",
    "\n",
    "\n",
    "class VectorQuantize(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        codebook_size,\n",
    "        codebook_dim,\n",
    "        heads = 1,\n",
    "        separate_codebook_per_head = False,\n",
    "        decay = 0.8,\n",
    "        eps = 1e-5,\n",
    "        kmeans_init = True,\n",
    "        kmeans_iters = 10,\n",
    "        sync_kmeans = True,\n",
    "        threshold_ema_dead_code = 3,\n",
    "        commitment_weight = 1.,\n",
    "        orthogonal_reg_weight = 0.,\n",
    "        orthogonal_reg_active_codes_only = False,\n",
    "        orthogonal_reg_max_codes = None,\n",
    "        sample_codebook_temp = 0.,\n",
    "        sync_codebook = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.separate_codebook_per_head = separate_codebook_per_head\n",
    "\n",
    "        codebook_dim = default(codebook_dim, dim)\n",
    "        codebook_input_dim = codebook_dim * heads\n",
    "\n",
    "        requires_projection = codebook_input_dim != dim\n",
    "        self.project_in = nn.Linear(dim, codebook_input_dim) if requires_projection else nn.Identity()\n",
    "        self.project_out = nn.Linear(codebook_input_dim, dim) if requires_projection else nn.Identity()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.commitment_weight = commitment_weight\n",
    "\n",
    "        has_codebook_orthogonal_loss = orthogonal_reg_weight > 0\n",
    "        self.orthogonal_reg_weight = orthogonal_reg_weight\n",
    "        self.orthogonal_reg_active_codes_only = orthogonal_reg_active_codes_only\n",
    "        self.orthogonal_reg_max_codes = orthogonal_reg_max_codes\n",
    "\n",
    "        codebook_class = CosineSimCodebook\n",
    "\n",
    "        self._codebook = codebook_class(\n",
    "            dim = codebook_dim,\n",
    "            num_codebooks = heads if separate_codebook_per_head else 1,\n",
    "            codebook_size = codebook_size,\n",
    "            kmeans_init = kmeans_init,\n",
    "            kmeans_iters = kmeans_iters,\n",
    "            sync_kmeans = sync_kmeans,\n",
    "            decay = decay,\n",
    "            eps = eps,\n",
    "            threshold_ema_dead_code = threshold_ema_dead_code,\n",
    "            use_ddp = sync_codebook,\n",
    "            learnable_codebook = has_codebook_orthogonal_loss,\n",
    "            sample_codebook_temp = sample_codebook_temp\n",
    "        )\n",
    "\n",
    "        self.codebook_size = codebook_size\n",
    "\n",
    "    @property\n",
    "    def codebook(self):\n",
    "        codebook = self._codebook.embed\n",
    "        if self.separate_codebook_per_head:\n",
    "            return codebook\n",
    "\n",
    "        return rearrange(codebook, '1 ... -> ...')\n",
    "\n",
    "    def forward(self, x,):\n",
    "        shape, device, heads, is_multiheaded, codebook_size = x.shape, x.device, self.heads, self.heads > 1, self.codebook_size\n",
    "\n",
    "        x = self.project_in(x)\n",
    "\n",
    "        if is_multiheaded:\n",
    "            ein_rhs_eq = 'h b n d' if self.separate_codebook_per_head else '1 (b h) n d'\n",
    "            x = rearrange(x, f'b n (h d) -> {ein_rhs_eq}', h = heads)\n",
    "\n",
    "        quantize, embed_ind = self._codebook(x)\n",
    "\n",
    "        if self.training:\n",
    "            quantize = x + (quantize - x).detach()\n",
    "\n",
    "        \n",
    "        detached_inputs = x.detach()\n",
    "        loss = F.mse_loss(quantize, detached_inputs, reduction='none')\n",
    "        loss_pbe = torch.mean(loss, dim=(1,2)) # (batch_size)\n",
    "\n",
    "        if self.commitment_weight > 0:\n",
    "            detached_quantize = quantize.detach()\n",
    "            commit_loss = F.mse_loss(detached_quantize, x, reduction='none')\n",
    "\n",
    "            loss_pbe = loss_pbe + torch.mean(commit_loss * self.commitment_weight, dim=(1,2)) # (batch_size)\n",
    "\n",
    "        if is_multiheaded:\n",
    "            if self.separate_codebook_per_head:\n",
    "                quantize = rearrange(quantize, 'h b n d -> b n (h d)', h = heads)\n",
    "                embed_ind = rearrange(embed_ind, 'h b n -> b n h', h = heads)\n",
    "            else:\n",
    "                quantize = rearrange(quantize, '1 (b h) n d -> b n (h d)', h = heads)\n",
    "                embed_ind = rearrange(embed_ind, '1 (b h) n -> b n h', h = heads)\n",
    "\n",
    "        quantize_latent = quantize.detach().clone()\n",
    "        quantize = self.project_out(quantize)\n",
    "\n",
    "        avg_probs = torch.mean(F.one_hot(embed_ind, self.codebook_size).type(torch.float32).view((-1, self.codebook_size)), 0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "\n",
    "        return {\n",
    "        'quantize_projected_in': x, # (batch_size, l_r, codebook_dim)\n",
    "        'quantize_latent': quantize_latent, # (batch_size, l_r, codebook_dim)\n",
    "        'quantize_projected_out': quantize, # (batch_size, l_r, dim)\n",
    "        'loss_vq_commit_pbe': loss_pbe, # (batch_size)\n",
    "        'perplexity': perplexity, # (batch_size)\n",
    "        'encoding_indices': embed_ind # (batch_size, l_r)\n",
    "    } \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059fa97-d5ab-43bb-9ce1-e10d76d28917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from Bio import SeqIO\n",
    "import torch\n",
    "\n",
    "alphabet = ['A', 'C', 'D', 'E', 'F', 'G','H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
    "\n",
    "def data_loader_masking_bert_onehot_fasta(seq: list, batch_size: int, perc_masked_residues: float, \n",
    "                                          is_masking: bool) -> torch.utils.data.DataLoader:\n",
    "    ''' \n",
    "    Generate a Torch dataloader iterator from fp_data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fp_data: str\n",
    "        Filepath to the fasta file with the sequences of interest.\n",
    "    batch_size: int\n",
    "    perc_masked_residues: float\n",
    "        Ratio of residues to apply the BERT masking on (between 0 and 1).\n",
    "    is_masking: bool\n",
    "\n",
    "    '''\n",
    "    iterator = IterableMaskingBertOnehotDatasetFasta(seq, perc_masked_residues=perc_masked_residues, is_masking=is_masking)\n",
    "    loader = torch.utils.data.DataLoader(iterator, batch_size=batch_size, num_workers=0, shuffle=is_masking)\n",
    "    return loader \n",
    "\n",
    "\n",
    "class IterableMaskingBertOnehotDatasetFasta(torch.utils.data.IterableDataset):\n",
    "    '''\n",
    "    BERT-style masking onehot generator for all sequences given a fasta file.\n",
    "    '''\n",
    "    def __init__(self, seq, perc_masked_residues=0.0, is_masking=False):\n",
    "        self.seq = seq\n",
    "        self.perc_masked_residues = perc_masked_residues\n",
    "        self.is_masking = is_masking\n",
    "\n",
    "    def __iter__(self) -> torch.utils.data.IterableDataset:\n",
    "        for sequence in self.seq:\n",
    "            yield torch_masking_BERT_onehot(sequence, perc_masked_residues=self.perc_masked_residues,is_masking=self.is_masking)\n",
    "\n",
    "\n",
    "        \n",
    "def torch_masking_BERT_onehot(seq: str, perc_masked_residues: float=0.0, \n",
    "                              is_masking: bool=False, alphabet: list=alphabet) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    '''\n",
    "    BERT-style masking on a one-hot encoding input. When a residue is masked, it is replaced \n",
    "    by the dummie vector [1/21,...,1/21] of size 21. 80% of perc_masked_residues are masked, \n",
    "    10% are replaced by another residue, 10% are left as they are.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seq: str\n",
    "    perc_masked_residues: float\n",
    "        Ratio of residues to apply the BERT masking on (between 0 and 1).\n",
    "    is_masking: bool\n",
    "        False for evaluation.\n",
    "    alphabet: list \n",
    "        List of string of the alphabet of residues used in the one hot encoder\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    onehot_seq: tensor\n",
    "        One hot encoded input.\n",
    "    m_tf_onehot_seq: tensor \n",
    "        BERT masked one hot encoded input.\n",
    "\n",
    "    '''\n",
    "\n",
    "    alphabet = ['A', 'C', 'D', 'E', 'F', 'G','H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
    "\n",
    "    # One Hot Encoding\n",
    "    onehot_seq = np.array((pd.get_dummies(pd.Series(list(seq)).astype(CategoricalDtype(categories=alphabet))))).astype(float)\n",
    "    onehot_seq = torch.tensor(onehot_seq, dtype=torch.float32)\n",
    "    ln_seq = len(onehot_seq)\n",
    "\n",
    "    m_tf_onehot_seq = onehot_seq.clone().detach()\n",
    "\n",
    "    if is_masking:\n",
    "        if perc_masked_residues > 1:\n",
    "            raise NotImplementedError('Masking percentage should be between 0 and 1.')\n",
    "\n",
    "        # the onehot vector of the masked residue\n",
    "        len_alphabet = len(alphabet)\n",
    "        masked_letter = [1/len_alphabet]*len_alphabet\n",
    "\n",
    "        # MASKING\n",
    "        nb_masking = math.floor(ln_seq * perc_masked_residues)\n",
    "        nb_to_mask = math.floor(nb_masking*0.8) #80% replace with mask token\n",
    "        nb_to_replace = math.floor(nb_masking*0.1) #10% replace with random residue\n",
    "\n",
    "        if nb_to_mask != 0:\n",
    "\n",
    "            rd_ids = torch.Tensor(random.sample(range(ln_seq),ln_seq)[:nb_to_mask+nb_to_replace]).type(torch.int64)\n",
    "\n",
    "            rd_alphabet_selection_to_replace = random.choices(alphabet, k=nb_to_replace)\n",
    "            dummies_to_replace =  np.array((pd.get_dummies(pd.Series(rd_alphabet_selection_to_replace).astype(CategoricalDtype(categories=alphabet)))))\n",
    "\n",
    "            updates = np.array([masked_letter]*nb_to_mask)\n",
    "            updates = torch.Tensor(np.concatenate((updates,dummies_to_replace)))\n",
    "\n",
    "            m_tf_onehot_seq[rd_ids] = updates\n",
    "\n",
    "    return onehot_seq, m_tf_onehot_seq             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495e3fb-cebf-42c1-a28e-1d65517ec642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_embedding, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_embedding, 2) * (-math.log(10000.0) / d_embedding))\n",
    "        pe = torch.zeros(max_len, d_embedding)\n",
    "\n",
    "        # apply sin to even indices in the array; 2i\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        # apply cos to odd indices in the array; 2i+1\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, input_seq_len, d_embedding]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(1)]\n",
    "        return x\n",
    "\n",
    "class MHAEncoderBlock(nn.Module):\n",
    "  def __init__(self, d_embedding, num_heads, d_ff, dropout):\n",
    "    super(MHAEncoderBlock, self).__init__()\n",
    "\n",
    "    self.self_MHA = torch.nn.MultiheadAttention(d_embedding, num_heads, batch_first=True)\n",
    "\n",
    "    self.MLperceptron = nn.Sequential(\n",
    "            nn.Linear(d_embedding, d_ff),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(d_ff, d_embedding))\n",
    "\n",
    "    self.layernorm1 = nn.LayerNorm(d_embedding, eps=1e-6)\n",
    "    self.layernorm2 = nn.LayerNorm(d_embedding, eps=1e-6)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: Tensor, shape [batch_size, input_seq_len, d_embedding]\n",
    "    \"\"\"\n",
    "    # Attention\n",
    "    attn_output, attn_output_weights = self.self_MHA(x, x, x)  # (batch_size, input_seq_len, d_embedding)\n",
    "    x = x + self.dropout(attn_output)\n",
    "    x = self.layernorm1(x)\n",
    "\n",
    "    # MLP \n",
    "    linear_output = self.MLperceptron(x) \n",
    "    x = x + self.dropout(linear_output)\n",
    "    x = self.layernorm2(x) # (batch_size, input_seq_len, d_embedding) + residual \n",
    "\n",
    "    return x, attn_output_weights\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, d_embedding, kernel, stride, num_heads, num_mha_layers, d_ff,\n",
    "              length_seq, alphabet_size, dropout=0):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    # CNN1d embedding\n",
    "    self.l_red, self.padding = find_optimal_cnn1d_padding(L_in=length_seq, K=kernel, S=stride)\n",
    "    self.cnn_embedding =  nn.Sequential(Rearrange('b l r -> b r l'),\n",
    "                nn.Conv1d(alphabet_size, d_embedding, kernel_size=kernel, stride=stride, padding=self.padding),\n",
    "                Rearrange('b r l -> b l r'))\n",
    "\n",
    "    # Positional encoding\n",
    "    self.en_pos_encoding = PositionalEncoding(d_embedding, max_len=self.l_red)\n",
    "    self.en_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # MHA blocks\n",
    "    self.en_MHA_blocks = nn.ModuleList([MHAEncoderBlock(d_embedding, num_heads, d_ff, dropout)\n",
    "                       for _ in range(num_mha_layers)])\n",
    "\n",
    "  def forward(self, x) -> torch.Tensor: \n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: Tensor, shape [batch_size, input_seq_len, alphabet_size]\n",
    "    \"\"\"\n",
    "    # CNN1d Embedding\n",
    "    h = self.cnn_embedding(x) # (batch_size, l_red, d_embedding)\n",
    "\n",
    "    # Positional encoding\n",
    "    h = self.en_pos_encoding(h) \n",
    "    h = self.en_dropout(h) \n",
    "\n",
    "    # MHA blocks\n",
    "    for i, l in enumerate(self.en_MHA_blocks):\n",
    "      h, attn_enc_weights = self.en_MHA_blocks[i](h) # (batch_size, l_red, d_embedding)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, d_embedding, kernel, stride, num_heads, num_mha_layers, d_ff,\n",
    "                  length_seq, alphabet_size, dropout=0):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    # Positional encoding\n",
    "    self.l_red, self.padding = find_optimal_cnn1d_padding(L_in=length_seq, K=kernel, S=stride)\n",
    "    self.de_pos_encoding = PositionalEncoding(d_embedding, max_len=self.l_red)\n",
    "    self.de_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # MHA blocks\n",
    "    self.de_MHA_blocks = nn.ModuleList([MHAEncoderBlock(d_embedding, num_heads, d_ff, dropout)\n",
    "                       for _ in range(num_mha_layers)])\n",
    "\n",
    "    # Dense reconstruction\n",
    "    self.dense_to_alphabet = nn.Linear(d_embedding, alphabet_size)\n",
    "    self.dense_reconstruction = nn.Linear(alphabet_size*self.l_red, length_seq*alphabet_size)\n",
    "\n",
    "    # CNN1d reconstruction\n",
    "    self.out_pad = find_out_padding_cnn1d_transpose(L_obj=length_seq, L_in=self.l_red, K=kernel, S=stride, P=self.padding)\n",
    "    self.cnn_reconstruction =  nn.Sequential(Rearrange('b l r -> b r l'),\n",
    "                nn.ConvTranspose1d(d_embedding, alphabet_size, kernel_size=kernel, stride=stride, \n",
    "                              padding=self.padding, output_padding=self.out_pad),\n",
    "                Rearrange('b r l -> b l r'))\n",
    "    \n",
    "  \n",
    "  def forward(self, q) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      q: Tensor, shape [batch_size, l_red, d_embedding]\n",
    "    \"\"\"\n",
    "    # Positional encoding\n",
    "    z = self.de_pos_encoding(q) \n",
    "    z = self.de_dropout(z) \n",
    "\n",
    "    # MHA blocks\n",
    "    for i, l in enumerate(self.de_MHA_blocks):\n",
    "      z, attn_dec_weights = self.de_MHA_blocks[i](z) # (batch_size, l_red, d_embedding)\n",
    "      \n",
    "    # CNN reconstruction \n",
    "    z = self.cnn_reconstruction(z) # (batch_size, input_seq_len, alphabet_size)\n",
    "    z_recon = F.softmax(z, dim=-1)\n",
    "\n",
    "    return z_recon\n",
    "\n",
    "\n",
    "class AbNatiV_Model(pl.LightningModule):\n",
    "  def __init__(self, hparams: dict):\n",
    "    super(AbNatiV_Model, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(hparams['d_embedding'], hparams['kernel'], hparams['stride'], hparams['num_heads'], \n",
    "                            hparams['num_mha_layers'], hparams['d_ff'], hparams['length_seq'], \n",
    "                            hparams['alphabet_size'], dropout=hparams['drop'])\n",
    "\n",
    "    self.decoder = Decoder(hparams['d_embedding'], hparams['kernel'], hparams['stride'], hparams['num_heads'], \n",
    "                            hparams['num_mha_layers'], hparams['d_ff'], hparams['length_seq'], \n",
    "                            hparams['alphabet_size'], dropout=hparams['drop'])\n",
    "\n",
    "    self.vqvae = VectorQuantize(\n",
    "            dim=hparams['d_embedding'],\n",
    "            codebook_size=hparams['num_embeddings'],\n",
    "            codebook_dim=hparams['embedding_dim_code_book'],\n",
    "            decay=hparams['decay'],\n",
    "            kmeans_init=True,\n",
    "            commitment_weight=hparams['commitment_cost']\n",
    "            )\n",
    "\n",
    "    self.learning_rate = hparams['learning_rate']\n",
    "    self.save_hyperparameters()\n",
    "\n",
    "\n",
    "  def forward(self, data) -> dict:\n",
    "    inputs = data[:][0][:][:]\n",
    "    m_inputs = data[:][1][:][:]\n",
    "\n",
    "\n",
    "    x = self.encoder(m_inputs)\n",
    "    vq_outputs = self.vqvae(x)\n",
    "    x_recon = self.decoder(vq_outputs['quantize_projected_out'])\n",
    "\n",
    "    # Loss computing \n",
    "    recon_error_pres_pposi = F.mse_loss(x_recon, inputs, reduction='none')\n",
    "    recon_error_pposi = torch.mean(recon_error_pres_pposi, dim=-1)\n",
    "    recon_error_pbe = torch.mean(recon_error_pposi, dim=1)\n",
    "\n",
    "    loss_pbe = torch.add(recon_error_pbe, vq_outputs['loss_vq_commit_pbe'])\n",
    "\n",
    "    return {\n",
    "        'inputs': inputs, # (batch_size, input_seq_len, alphabet_size)\n",
    "        'x_recon': x_recon, # (batch_size, input_seq_len, alphabet_size)\n",
    "        'recon_error_pres_pposi': recon_error_pres_pposi, # (batch_size, input_seq_len, alphabet_size)\n",
    "        'recon_error_pposi': recon_error_pposi, # (batch_size, input_seq_len)\n",
    "        'recon_error_pbe': recon_error_pbe, # (batch_size)\n",
    "        'loss_pbe': loss_pbe, # (batch_size)\n",
    "        **vq_outputs\n",
    "    }\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optim_groups = list(self.encoder.parameters()) + \\\n",
    "                    list(self.decoder.parameters()) + \\\n",
    "                    list(self.vqvae.parameters()) \n",
    "\n",
    "    return torch.optim.AdamW(optim_groups, lr=self.learning_rate)\n",
    "\n",
    "  def training_step(self, batch, batch_idx) -> torch.float32:\n",
    "    vqvae_output = self(batch)\n",
    "\n",
    "    loss_vqvae = torch.mean(vqvae_output['loss_pbe'])\n",
    "    self.log(\"train_loss_vqvae\", loss_vqvae, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "    loss_vq_commit = torch.mean(vqvae_output['loss_vq_commit_pbe'])\n",
    "    self.log(\"train_loss_vq_commit\", loss_vq_commit, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "    nmse_accuracy = torch.mean(vqvae_output['recon_error_pbe'])\n",
    "    self.log(\"train_loss_nmse_recons\", nmse_accuracy, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "    perplexity = vqvae_output['perplexity']\n",
    "    self.log(\"train_perplexity\", perplexity, on_step=True, prog_bar=True, logger=True)\n",
    "\n",
    "    return loss_vqvae\n",
    "\n",
    "  def validation_step(self, batch, batch_idx) -> dict:\n",
    "    model_output = self(batch)\n",
    "    return {'val_loss': torch.mean(model_output['loss_pbe']), 'model_output': model_output}\n",
    "\n",
    "  def on_validation_epoch_end(self, outputs) -> dict:\n",
    "\n",
    "    val_losses = torch.Tensor([out['val_loss'] for out in outputs])\n",
    "    total_val_loss = torch.mean(val_losses)\n",
    "    self.log('val_loss', total_val_loss, on_epoch=True, logger=True)\n",
    "\n",
    "    val_accuracies = torch.Tensor([torch.mean(out['model_output']['recon_error_pbe']) for out in outputs])\n",
    "    total_val_accuracy = torch.mean(val_accuracies)\n",
    "    self.log('val_nmse_accuracy', total_val_accuracy, on_epoch=True, logger=True)\n",
    "\n",
    "    val_perplexities = torch.Tensor([out['model_output']['perplexity'] for out in outputs])\n",
    "    total_val_perplexity = torch.mean(val_perplexities)\n",
    "    self.log('val_perplexity', total_val_perplexity, on_epoch=True, logger=True)\n",
    "    \n",
    "    return {'val_loss': total_val_loss, 'val_nmse_accuracy': total_val_accuracy, 'val_perplexity': total_val_perplexity}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433eee5-94a3-4d25-895a-0aeece46e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "    def __init__(self):\n",
    "        self.alphabet_size=21\n",
    "        self.batch_size=64\n",
    "        self.commitment_cost=2 # In the loss function\n",
    "        self.d_embedding=768 # assert d_embedding % num_heads == 0\n",
    "        self.d_ff=128 # Hidden layer dimension of point wise feed forward network\n",
    "        self.decay=0.90 # This is only used for EMA updates.\n",
    "        self.drop=0\n",
    "        self.embedding_dim_code_book=64\n",
    "        self.kernel=8\n",
    "        self.learning_rate=4.0e-05\n",
    "        self.length_seq=125\n",
    "        self.limit_val_batches=400\n",
    "        self.max_epochs=15\n",
    "        self.num_embeddings=512\n",
    "        self.num_heads=8\n",
    "        self.num_mha_layers=1\n",
    "        self.perc_masked_residues=0.15\n",
    "        self.run_name='abnativ_v1'\n",
    "        self.stride=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71744f35-7897-4657-a7d1-7de68f30df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "class VDJ_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, vdj, labels, task, max_len = None):\n",
    "        self.task = task\n",
    "        self.max_len = max_len\n",
    "\n",
    "        if max_len is None:\n",
    "            self.max_len = self.get_max_len(vdj)\n",
    "        else:\n",
    "            self.max_len = max_len\n",
    "        vdj = self.add_mask(vdj)\n",
    "        self.vdj = self.encode_sequences(vdj)\n",
    "\n",
    "        if labels is not None:\n",
    "            if self.task == 'binary.classification' or self.task == 'multiclass.classification':\n",
    "                self.label_to_ix = dict(zip(set(labels), range(len(set(labels)))))\n",
    "                self.ix_to_label =  dict(zip(range(len(set(labels))), set(labels)))\n",
    "                self.labels = [self.label_to_ix[label] for label in labels]\n",
    "                self.n_classes = len(np.unique(self.labels))\n",
    "                print('Found {} classes for {}'.format(self.n_classes, self.task))\n",
    "\n",
    "                #self.class_weights = self.make_weights_for_balanced_classes(self.labels)\n",
    "                #self.labels = [F.one_hot(torch.tensor(label), self.n_classes).float() for label in self.labels]\n",
    "                self.labels = [torch.tensor(label).int() for label in self.labels]\n",
    "\n",
    "            elif self.task == 'gex':\n",
    "                self.label_to_ix = None\n",
    "                self.ix_to_label = None\n",
    "                self.labels = np.array(labels)\n",
    "                self.n_classes = self.labels.shape[-1]        #To do: Add gex normalization!\n",
    "                print('Found {} genes for {}'.format(self.n_classes, self.task))\n",
    "                \n",
    "                self.labels = [torch.Tensor(label) for label in self.labels]\n",
    "\n",
    "\n",
    "            elif self.task == 'regression':\n",
    "                self.label_to_ix = None\n",
    "                self.ix_to_label = None\n",
    "                self.labels = np.array(labels)\n",
    "                self.labels = self.z_score(self.min_max(self.labels))\n",
    "                \n",
    "        else:\n",
    "            self.label_to_ix = None\n",
    "            self.ix_to_label = None\n",
    "            self.labels = None\n",
    "            self.n_classes =  None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vdj)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        vdj = self.vdj[item]\n",
    "        label = self.labels[item]\n",
    "\n",
    "        return (vdj, label)\n",
    "      \n",
    "    def get_max_len(self, sequences):\n",
    "        current_len = 0\n",
    "        for seq in sequences:\n",
    "            current_len = max(current_len, len(seq))\n",
    "\n",
    "        return current_len\n",
    "    \n",
    "    def add_mask(self, sequences, mask_token = '-'):\n",
    "        padded = []\n",
    "        for sequence in sequences:\n",
    "            padding = [mask_token] * (self.max_len - len(sequence))\n",
    "            sequence += ''.join(padding)\n",
    "            padded.append(sequence)\n",
    "        \n",
    "        return padded\n",
    "        \n",
    "    def encode_sequences(self, sequences):\n",
    "        ids = [list(set(i)) for i in sequences]\n",
    "        ids = set(chain(*ids))\n",
    "        self.seq_to_ids = dict(zip( ids, list(range(len(ids)))))\n",
    "        self.ids_to_seq = dict(zip( list(range(len(ids))), ids ))\n",
    "        self.n_residues = len(ids)\n",
    "\n",
    "        sequences = [F.one_hot(torch.Tensor([self.seq_to_ids[residue] for residue in sequence]).to(torch.int64), num_classes = self.n_residues).float() for sequence in sequences]\n",
    "        sequences = [F.pad(sequence, (0,0,0,self.max_len - sequence.size(0))) for sequence in sequences]\n",
    "\n",
    "        return sequences\n",
    "    \n",
    "    def min_max(self, scores):\n",
    "        return (scores - scores.min()) / (scores.max() - scores.min())\n",
    "\n",
    "    def z_score(self, scores):\n",
    "        scores = np.array(scores)\n",
    "        out = (scores - scores.mean()) / scores.std()\n",
    "        return scores.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388bba4-cd70-4374-9465-f31ada6a0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206a6a8f-03a7-49b5-a615-f9db777f24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VDJ = pd.read_csv('./data/VDJ_IgG_all.csv')\n",
    "VDJ = VDJ.drop_duplicates(['pasted_cdr3'])\n",
    "seq = VDJ['pasted_cdr3'].tolist()\n",
    "label = VDJ['antigen'].tolist()\n",
    "dataset = VDJ_dataset(seq, label, task = 'multiclass.classification')\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "seq = dataset.add_mask(seq)\n",
    "seq_len = dataset.max_len\n",
    "vocab = dataset.n_residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6d685-3f75-41ad-9626-1ba23208de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os \n",
    "files = os.listdir('./data/fasta')\n",
    "sequences = []\n",
    "labels = []\n",
    "numbers = ['1','2','3','4','5','6','7','8','9','0'] \n",
    "for input_file in files:\n",
    "    fasta_sequences = SeqIO.parse(open('./data/fasta/'+input_file),'fasta')\n",
    "    for fasta in fasta_sequences:\n",
    "        sequence = str(fasta.seq)\n",
    "        if(any(ext in sequence for ext in numbers) is False):\n",
    "            sequences.append(sequence)\n",
    "        \n",
    "        if input_file.startswith('antig1'):\n",
    "            labels.append('TNFR2')\n",
    "        else:\n",
    "            labels.append('OVA')\n",
    "\n",
    "_, ids = np.unique(sequences, return_index =True)\n",
    "sequences = np.array(sequences)[ids]\n",
    "labels = np.array(labels)[ids]\n",
    "lens = np.array([len(s) for s in sequences])\n",
    "ids = np.where(lens <= 300)\n",
    "sequences = np.array(sequences)[ids].tolist()\n",
    "labels = np.array(labels)[ids].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb01bd5-a029-41fe-b049-924a193783b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_unique(df, scores, labels):\n",
    "    score_df = df.groupby('sequence')[scores].mean().reset_index()\n",
    "    label_df = df.drop_duplicates(['sequence'])[labels + ['sequence']]\n",
    "    df = pd.merge(score_df, label_df, on='sequence')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('/cluster/home/tcotet/fitness_landscapes/data/all_scores_pooled.csv')\n",
    "scores = ['interface_score', 'total_score', 'catalytic_score', 'interface_potential', 'total_potential', 'catalytic_potential', 'generation', 'mutations']\n",
    "labels = ['score_taken_from', 'design_method', 'cat_resn', 'cat_resi', 'parent_index']\n",
    "df = df[df['sequence'].notnull()]\n",
    "df = select_unique(df, scores, labels)\n",
    "sequences = df['sequence'].tolist()\n",
    "labels = df['cat_resi'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d36d2-3fae-44c2-90ca-9382794116f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VDJ_dataset(sequences, labels, task = 'multiclass.classification')\n",
    "sequences = dataset.add_mask(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a64a7b-79bf-4ff3-87b4-5cc49114fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HParams()\n",
    "hparams = hp.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2797be4-87f4-4f52-b335-85a2294b9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data_loader_masking_bert_onehot_fasta(sequences, hparams['batch_size'],\n",
    "                        hparams['perc_masked_residues'], is_masking=False)\n",
    "val_loader = data_loader_masking_bert_onehot_fasta(sequences, hparams['batch_size'],\n",
    "                        perc_masked_residues=0, is_masking=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a51cc6-81e2-4137-a952-c6146f71a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7ab4c-e453-4334-8d59-b57542fd650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AbNatiV_Model(hparams).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc503ff5-96cd-4494-b9cf-91f132028976",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942c6a4-cb24-4bb5-9e04-add9afb1b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419a63c-57d2-41e6-9793-f2d9e7954b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "model.train()\n",
    "losses = []\n",
    "print('Started training')\n",
    "for epoch in range(hparams['max_epochs']):\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch[0] = batch[0].to(device)\n",
    "        batch[1] = batch[1].to(device)\n",
    "\n",
    "        # train step\n",
    "        loss = model.training_step(batch, idx)\n",
    "\n",
    "        # clear gradients\n",
    "        # backward\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.detach().item())\n",
    "    print(f\"epoch: {epoch + 1} loss {np.array(losses).mean()}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f366a4-0a2c-46c3-b2f6-06496396a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a0842-60b2-464c-adc3-761ef698b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8842b345-9d38-4a29-93a7-feacd19f6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    encoded = model.encoder(batch[0])\n",
    "    vq_outputs = model.vqvae(encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb679797-98bf-4025-86f2-7879e76b7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['A', 'C', 'D', 'E', 'F', 'G','H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '-']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4cc7f-1156-4247-b5d9-434c75a92c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = [out.reshape(-1, dataset.max_len, 21) for out in outs]\n",
    "idd = [torch.max(torch.tensor(out), dim = -1)[1].detach().tolist()[0] for out in o]\n",
    "recons = [''.join([alphabet[j] for j in idd[i]]).replace('-','') for i in range(len(idd))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e8de3c-4c1e-4e66-a2ba-8d5801fd799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ae3d6-99b0-4b5c-b821-ff9ade218364",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c40a2-b78d-445f-9784-ef4ba526af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = [out.reshape(-1, dataset.max_len, 21) for out in outs]\n",
    "idd = [torch.max(torch.tensor(out), dim = -1)[1].detach().tolist()[0] for out in o]\n",
    "recons1 = [''.join([alphabet[j] for j in idd[i]]).replace('-','') for i in range(len(idd))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c6282-e1dc-4d74-bf40-642add0d6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "recons1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803afef-1796-4185-9f43-af313175ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = [data.reshape(-1, dataset.max_len, 21) for out in outs]\n",
    "idd = [torch.max(torch.tensor(out), dim = -1)[1].detach().tolist()[0] for out in o]\n",
    "recons2 = [''.join([alphabet[j] for j in idd[i]]).replace('-','') for i in range(len(idd))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1a01d-5b9a-4850-b89b-80fded3b2644",
   "metadata": {},
   "outputs": [],
   "source": [
    "recons2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79918bd-c02d-479b-94a0-04fc54cc9c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "encoded = torch.randn((10, D,768))\n",
    "vq_outputs = model.vqvae(encoded)\n",
    "outs = model.decoder(vq_outputs['quantize_projected_out'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac98a5-5b51-453c-96cd-04a78617b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lv\n",
    "dists = [lv.distance(recons[i], recons1[i]) for i in range(len(recons))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af93594-44a8-4cbf-8c8c-d15846e86ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outs = model.decoder(vq_outputs['quantize_projected_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e8ab2-33ba-4dcc-8199-2faa7f6d9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "encoded = model.encoder(data)\n",
    "vq_outputs = model.vqvae(encoded)\n",
    "outs = model.decoder(vq_outputs['quantize_projected_out'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6cbc6-e48a-4d5f-8eda-79c3c0fdf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ed716-2b01-46a6-886a-2bed4cc7b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8f6a2-b4b6-4935-aa75-86b6d9b24a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "N = len(sequences)\n",
    "D = 16\n",
    "encoded_features = np.zeros((N, D * 768))\n",
    "proj_in_features = np.zeros((N, D * 64))\n",
    "latent_features = np.zeros((N, D * 64))\n",
    "proj_out_features = np.zeros((N, D * 768))\n",
    "decoded = []\n",
    "start_ind = 0\n",
    "with torch.no_grad():\n",
    "    for (data, labels) in data_loader:\n",
    "        encoded = model.encoder(data)\n",
    "        encoded_feat = encoded.reshape(-1, D*768).cpu().detach().numpy()  \n",
    "        vq_outputs = model.vqvae(encoded)\n",
    "        \n",
    "        end_ind = min(start_ind + data.size(0), N+1)\n",
    "    \n",
    "        encoded_features[start_ind:end_ind] = encoded_feat\n",
    "        proj_in_features[start_ind:end_ind] = vq_outputs['quantize_projected_in'].reshape(-1, D*64).cpu().detach().numpy()  \n",
    "        latent_features[start_ind:end_ind] = vq_outputs['quantize_latent'].reshape(-1, D*64).cpu().detach().numpy()  \n",
    "        proj_out_features[start_ind:end_ind] = vq_outputs['quantize_projected_out'].reshape(-1, D*768).cpu().detach().numpy()  \n",
    "\n",
    "        start_ind += data.size(0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7f8cb-1b0d-4400-985e-727b10c8e2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [dataset.label_to_ix[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad8bae-242e-4da7-9192-a9c84ab52088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features, labs = gmvae.latent_features(train_loader, return_labels = True)\n",
    "pca = PCA(n_components = 2)\n",
    "tsne = TSNE(n_components = 2)\n",
    "umap = UMAP()\n",
    "#features = tsne.fit_transform(latent_features)\n",
    "features = pca.fit_transform(proj_out_features)\n",
    "#features = umap.fit_transform(latent_features)\n",
    "p = ['#F75C55','#F9DA7A','#ADA59E','#FE6E34','#2219D1','#F5D7BC','#D5DCF2','#590925','#1AFFD5','#007FFF','#7D83FF']\n",
    "cols = [p[lab] for lab in labels]\n",
    "# plot only the first 2 dimensions\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.scatter(features[:, 0], features[:, 1], marker='o', c = cols,\n",
    "        edgecolor='none', s = 1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12c1b9-088e-4556-aa8c-96eb51a9babd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab758632-93f1-433c-817f-2ae7d8835a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(11)\n",
    "# Logging\n",
    "\n",
    "# Checkpointing\n",
    "logger = MLFlowLogger(experiment_name='vqvae', run_name='test1')\n",
    "\n",
    "\n",
    "ckpt_root_dir = os.path.join('checkpoints', 'test1')\n",
    "ckpt_callback = ModelCheckpoint(ckpt_root_dir, save_top_k=-1) # to save every epoch\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=hparams['max_epochs'], \n",
    "                     deterministic=True, accelerator='auto') \n",
    "\n",
    "\n",
    "# Training \n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe80427-8346-4643-8709-789c629e7b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587eff92-f32c-44e6-b5a1-832b50643a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
