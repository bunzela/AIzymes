{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca6cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVELOPER NOTES\n",
    "# ProteinMPNN starting to be implemented but not yet completed\n",
    "# BACKGROUND_JOB starting to be implemented but not yet completed\n",
    "# Add backup information to the folder for each design\n",
    "\n",
    "# add penalty for same sequence? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba281b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import statistics\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "#import mdtraj as md\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB import PDBParser\n",
    "from datetime import datetime\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from scipy.stats import gmean, pearsonr\n",
    "\n",
    "# Setting initial options\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None \n",
    "matplotlib_axes_logger.setLevel('INFO')\n",
    "\n",
    "DESIGN_COUNT = {}\n",
    "\n",
    "GRID = False\n",
    "BLUEPEBBLE = True\n",
    "\n",
    "if GRID:\n",
    "    USERNAME = os.getlogin()\n",
    "    FOLDER_HOME = f'/home/{USERNAME}/{os.getcwd().split(\"/\")[-1]}/{DESIGN_FOLDER}'\n",
    "if BLUEPEBBLE:\n",
    "    FOLDER_HOME = f'{os.getcwd()}/{DESIGN_FOLDER}'\n",
    "# if BACKGROUND_JOB:\n",
    "#     FOLDER_HOME = f'{os.getcwd()}/{DESIGN_FOLDER}'\n",
    "\n",
    "os.makedirs(FOLDER_HOME, exist_ok=True)\n",
    "FOLDER_INPUT = f'{os.getcwd()}/Input'\n",
    "if not os.path.isdir(FOLDER_INPUT): print(\"ERROR! Input folder missing!\")\n",
    "LOG_FILE = f'{FOLDER_HOME}.log'\n",
    "ALL_SCORES_CSV = f'{FOLDER_HOME}/all_scores.csv'\n",
    "BLOCKED_DAT    = f'{FOLDER_HOME}/blocked.dat'\n",
    "VARIABLES_JSON  = f'{FOLDER_HOME}/variables.json'\n",
    "\n",
    "# Configure logging file\n",
    "log_format = '%(asctime)s - %(levelname)s - %(message)s'\n",
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "# Remove all handlers associated with the root logger\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Basic configuration for logging to a file\n",
    "logging.basicConfig(filename=LOG_FILE, level=logging.DEBUG, format=log_format, datefmt=date_format)\n",
    "#logging.basicConfig(filename=LOG_FILE, level=logging.INFO, format=log_format, datefmt=date_format)\n",
    "\n",
    "# Create a StreamHandler for console output\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_handler.setFormatter(logging.Formatter(log_format, datefmt=date_format))\n",
    "\n",
    "# Add the console handler to the root logger\n",
    "logging.getLogger().addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200550d5",
   "metadata": {},
   "source": [
    "# main functions - running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e896b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller(RESET=False, EXPLORE=False, UNBLOCK_ALL=False, \n",
    "               PRINT_VAR=True, PLOT_DATA=True, \n",
    "               BLUEPEBBLE=False, GRID=True):\n",
    "    \n",
    "    # Main AI.zymes functions. Controls the whole design process\n",
    "\n",
    "    # Startup, will only be executed once in the beginning\n",
    "    setup_aizymes(RESET, EXPLORE) \n",
    "    \n",
    "    # Check if Startup is done, if done, read in all_scores_df\n",
    "    all_scores_df = startup_controller(UNBLOCK_ALL, \n",
    "                                       RESET,\n",
    "                                       PRINT_VAR=PRINT_VAR, \n",
    "                                       PLOT_DATA=PLOT_DATA)\n",
    "    \n",
    "    while not os.path.exists(os.path.join(FOLDER_HOME, str(MAX_DESIGNS))):\n",
    "\n",
    "        # Check how many jobs are currently running\n",
    "        num_running_jobs = check_running_jobs()\n",
    "        \n",
    "        if num_running_jobs >= MAX_JOBS: \n",
    "            \n",
    "            time.sleep(60)\n",
    "            \n",
    "        else:\n",
    "                        \n",
    "            # Update scores\n",
    "            all_scores_df = update_scores(all_scores_df)\n",
    "            \n",
    "            # Check if parent designs are done, if not, start design\n",
    "            parent_done, all_scores_df = start_parent_design(all_scores_df)\n",
    "\n",
    "            if parent_done:\n",
    "                \n",
    "                # Boltzmann Selection\n",
    "                selected_index = boltzmann_selection(all_scores_df)#, blocked_df)\n",
    "\n",
    "                # Decide Fate of selected index\n",
    "                #all_scores_df, blocked_df = start_calculation(all_scores_df, blocked_df, selected_index)\n",
    "                all_scores_df = start_calculation(all_scores_df, selected_index)\n",
    "    \n",
    "        time.sleep(1)\n",
    "        \n",
    "    print(f\"Stopped because {os.path.join(FOLDER_HOME, str(MAX_DESIGNS))} exists.\")\n",
    "\n",
    "def check_running_jobs():\n",
    "    \n",
    "    if GRID:\n",
    "        jobs = subprocess.check_output([\"qstat\", \"-u\", USERNAME]).decode(\"utf-8\").split(\"\\n\")\n",
    "        jobs = [job for job in jobs if SUBMIT_PREFIX in job]\n",
    "        return len(jobs)\n",
    "        \n",
    "    if BLUEPEBBLE:\n",
    "        jobs = subprocess.check_output([\"squeue\",\"--me\"]).decode(\"utf-8\").split(\"\\n\")\n",
    "        jobs = [job for job in jobs if SUBMIT_PREFIX in job]\n",
    "        return len(jobs)\n",
    "        \n",
    "    if BACKGROUND_JOB:\n",
    "        with open(f'{FOLDER_HOME}/n_running_jobs.dat', 'r'): jobs = int(f.read())\n",
    "        return jobs\n",
    "\n",
    "def update_potential(score_type, score, index, all_scores_df, score_file):\n",
    "\n",
    "    if index == 'Parent': return all_scores_df\n",
    "    \n",
    "    # Make potential_XXX.dat file\n",
    "    filename = f\"{FOLDER_HOME}/{int(float(index))}/{score_type}_potential.dat\"\n",
    "    if os.path.isfile(filename): \n",
    "        with open(filename, \"r\") as f: potential = f.readlines()\n",
    "    else:\n",
    "        potential = []\n",
    "            \n",
    "    if score_file == \"score_rosetta_relax.sc\": \n",
    "        potential = []\n",
    "        \n",
    "    potential.append(str(score))\n",
    "    potential = [item.replace('\\n', '') for item in potential if item.replace('\\n', '')] #cleanup list, might not be needed\n",
    "    with open(filename, \"w\") as f: f.write('\\n'.join(potential))\n",
    "\n",
    "    #Update dataframe\n",
    "    all_scores_df.at[index, f'{score_type}_potential'] = np.average([float(i) for i in potential])\n",
    "    all_scores_df = all_scores_df.dropna(subset=['index'])\n",
    "    \n",
    "    return all_scores_df\n",
    "        \n",
    "def update_scores(all_scores_df):\n",
    "    # Update total_score, interface_score, and score\n",
    "\n",
    "    #Why would there be nan in the index?\n",
    "    all_scores_df = all_scores_df.dropna(subset=['index'])\n",
    "\n",
    "    for index, row in all_scores_df.iterrows():\n",
    "\n",
    "        ## why is index reinitialised?\n",
    "        index = row['index']\n",
    "        parent_index = row['parent_index']\n",
    "        \n",
    "        # do NOT update score if score was taken from a relax file. Prevents repeated scoring!\n",
    "        score_file_path = f\"{FOLDER_HOME}/{int(index)}/score_rosetta_relax.sc\"\n",
    "        if row['score_taken_from'] == 'Relax': continue\n",
    "\n",
    "        # change scorefile path if run is a RosettaDesign and if score_rosetta_relax.sc does not exist\n",
    "        if row['design_method'] == \"RosettaDesign\":\n",
    "            if not os.path.exists(score_file_path):\n",
    "                score_file_path = f\"{FOLDER_HOME}/{int(index)}/score_rosetta_design.sc\" #? \n",
    "                \n",
    "                # do NOT update score if score was taken from a design file. Prevents repeated scoring!\n",
    "                if row['score_taken_from'] == 'Design': continue\n",
    "                    \n",
    "                # do NOT update score if design pdb does not exist. This should not happen! Sometimes shit happens...\n",
    "                pdb_path = f\"{FOLDER_HOME}/{int(index)}/{WT}_Rosetta_Design_{int(index)}.pdb\"\n",
    "                if not os.path.isfile(pdb_path): continue\n",
    "\n",
    "        if not os.path.exists(score_file_path): continue\n",
    "        with open(score_file_path, \"r\") as f: scores = f.readlines()\n",
    "            \n",
    "        if len(scores) < 3: continue # if the timing is bad, the score file is not fully written. Check if len(scores) > 2!\n",
    "        \n",
    "        headers = scores[1].split()\n",
    "        scores  = scores[2].split()\n",
    "\n",
    "        catalytic_score = 0.0\n",
    "        interface_score = 0.0\n",
    "        for idx_headers, header in enumerate(headers):\n",
    "            if header == 'total_score':                total_score      = float(scores[idx_headers])\n",
    "            if header == 'interface_delta_X':          interface_score += float(scores[idx_headers])\n",
    "            if header in ['if_X_angle_constraint', \n",
    "                          'if_X_atom_pair_constraint', \n",
    "                          'if_X_dihedral_constraint']: interface_score -= float(scores[idx_headers])   \n",
    "            if header in ['angle_constraint', \n",
    "                          'atom_pair_constraint', \n",
    "                          'dihedral_constraint']:      catalytic_score += float(scores[idx_headers])                    \n",
    "\n",
    "        # Update scores\n",
    "        all_scores_df.at[index, 'total_score']     = total_score\n",
    "        all_scores_df.at[index, 'interface_score'] = interface_score                \n",
    "        all_scores_df.at[index, 'catalytic_score'] = catalytic_score\n",
    "        \n",
    "        for score_type in ['total', 'interface', 'catalytic']:        \n",
    "                \n",
    "            all_scores_df = update_potential(score_type,\n",
    "                                             all_scores_df.at[int(index), f'{score_type}_score'],\n",
    "                                             index, \n",
    "                                             all_scores_df,\n",
    "                                             score_file_path.split('/')[-1])\n",
    "\n",
    "            if score_file_path.split('/')[-1] == 'score_rosetta_relax.sc': # Only update parent if score comes from relax\n",
    "                all_scores_df = update_potential(score_type,\n",
    "                                                 all_scores_df.at[int(index), f'{score_type}_score'],\n",
    "                                                 all_scores_df.at[int(index), \"parent_index\"], \n",
    "                                                 all_scores_df,\n",
    "                                                 \"updating_parent_score\")\n",
    "\n",
    "        all_scores_df['score_taken_from'] = all_scores_df['score_taken_from'].astype('object')    \n",
    "\n",
    "        if score_file_path == f\"{FOLDER_HOME}/{int(index)}/score_rosetta_relax.sc\":\n",
    "            all_scores_df.at[index, 'score_taken_from'] = 'Relax'\n",
    "        if score_file_path == f\"{FOLDER_HOME}/{int(index)}/score_rosetta_design.sc\":\n",
    "            all_scores_df.at[index, 'score_taken_from'] = 'Design'\n",
    "\n",
    "        logging.info(f\"Updated total_score, interface_delta_X, and catalytic_score of index {int(index)}.\")\n",
    "        \n",
    "        #unblock index if relaxed file exists\n",
    "        ### come up with logic to get list of indices that are blocked from all_scores_df\n",
    "        if all_scores_df.at[index, \"blocked\"] == True:\n",
    "        #if index in blocked_df:\n",
    "            if f\"{WT}_Rosetta_Relax_{int(index)}.pdb\" in os.listdir(os.path.join(FOLDER_HOME, str(int(index)))):\n",
    "                \n",
    "                all_scores_df.at[index, \"blocked\"] = False\n",
    "                \n",
    "                logging.debug(f\"Unblocked index {int(index)}.\")\n",
    "\n",
    "                # if blocked_df != []:\n",
    "                #     blocked_df = [i for i in blocked_df if i != index]\n",
    "                # if blocked_df == []:\n",
    "                #     np.savetxt(BLOCKED_DAT, np.array([], dtype=int), fmt='%d')\n",
    "                # else:\n",
    "                #     np.savetxt(BLOCKED_DAT, blocked_df)\n",
    "        \n",
    "        pdb_path = f\"{FOLDER_HOME}/{int(index)}/{WT}_Rosetta_Design_{int(index)}.pdb\"\n",
    "     \n",
    "        # Update catalytic residues\n",
    "        all_scores_df = save_cat_res_into_all_scores_df(all_scores_df, index, pdb_path)\n",
    "\n",
    "        # Update sequence and mutations\n",
    "        reference_sequence = extract_sequence_from_pdb(f\"{FOLDER_INPUT}/{WT}.pdb\")\n",
    "        current_sequence = extract_sequence_from_pdb(pdb_path)\n",
    "        mutations = sum(1 for a, b in zip(current_sequence, reference_sequence) if a != b)\n",
    "        all_scores_df['sequence'] = all_scores_df['sequence'].astype('object')\n",
    "        all_scores_df.at[index, 'sequence']  = current_sequence\n",
    "        all_scores_df.at[index, 'mutations'] = int(mutations)\n",
    "        \n",
    "    save_all_scores_df(all_scores_df)\n",
    "    \n",
    "    return all_scores_df#, blocked_df \n",
    "\n",
    "def normalize_scores(unblocked_all_scores_df, print_norm=False, norm_all=False, extension=\"score\"):\n",
    "    \n",
    "    def neg_norm_array(array, score_type):\n",
    "\n",
    "        if len(array) > 1:  ##check that it's not only one value\n",
    "            \n",
    "            array    = -array\n",
    "            \n",
    "            if norm_all:\n",
    "                if print_norm:\n",
    "                    print(score_type,NORM[score_type],end=\" \")\n",
    "                array = (array-NORM[score_type][0])/(NORM[score_type][1]-NORM[score_type][0])\n",
    "                array[array < 0] = 0.0\n",
    "                if np.any(array > 1.0): print(\"\\nNORMALIZATION ERROR!\",score_type,\"has a value >1!\") \n",
    "            else:\n",
    "                if print_norm:\n",
    "                    print(score_type,[np.nanmin(array),np.nanmax(array)],end=\" \")\n",
    "                array = (array-np.nanmin(array))/(np.nanmax(array)-np.nanmin(array))\n",
    "                array[array < 0] = 0.0\n",
    "            return array\n",
    "        \n",
    "        else:\n",
    "            #return array\n",
    "            # return a probability of 1 if there's only one value in the array\n",
    "            return np.array([1.0])\n",
    "         \n",
    "    catalytic_scores    = unblocked_all_scores_df[f\"catalytic_{extension}\"]\n",
    "    catalytic_scores    = neg_norm_array(catalytic_scores, f\"catalytic_{extension}\")   \n",
    "    \n",
    "    total_scores        = unblocked_all_scores_df[f\"total_{extension}\"]\n",
    "    total_scores        = neg_norm_array(total_scores, f\"total_{extension}\")   \n",
    "    \n",
    "    interface_scores    = unblocked_all_scores_df[f\"interface_{extension}\"]\n",
    "    interface_scores    = neg_norm_array(interface_scores, f\"interface_{extension}\")  \n",
    "    \n",
    "    \n",
    "    if len(total_scores) == 0:\n",
    "        combined_scores = []\n",
    "    else:\n",
    "        #combined_scores     = np.stack((total_scores, interface_scores))\n",
    "        combined_scores     = np.stack((catalytic_scores, total_scores, interface_scores))\n",
    "        combined_scores     = gmean(combined_scores, axis=0)\n",
    "          \n",
    "    if print_norm:\n",
    "        if combined_scores != []:\n",
    "            print(\"HIGHSCORE:\",\"{:.2f}\".format(np.amax(combined_scores)),end=\" \")\n",
    "            print(\"Designs:\",len(combined_scores),end=\" \")\n",
    "            PARENTS = [i for i in os.listdir(FOLDER_PARENT) if i[-4:] == \".pdb\"]\n",
    "            print(\"Parents:\",len(PARENTS))\n",
    "        \n",
    "    return catalytic_scores, total_scores, interface_scores, combined_scores\n",
    "        \n",
    "def boltzmann_selection(all_scores_df):\n",
    "\n",
    "    # Drop rows that are blocked\n",
    "    ### come up with logic to get list of indices that are NOT blocked from all_scores_df --> altenretaively filter all_scores_df\n",
    "    # blocked_df = np.loadtxt(BLOCKED_DAT).tolist()\n",
    "    # if not isinstance(blocked_df, list): blocked_df = [blocked_df]\n",
    "    # blocked_df = [str(int(i)) for i in blocked_df]\n",
    "    \n",
    "    all_scores_df = pd.read_csv(ALL_SCORES_CSV)\n",
    "\n",
    "    unblocked_all_scores_df = all_scores_df[all_scores_df[\"blocked\"] == False]\n",
    "\n",
    "    # relaxed_indices = all_scores_df[all_scores_df['score_taken_from'] == 'Relax']\n",
    "    # relaxed_indices = [str(i) for i in relaxed_indices.index]\n",
    "\n",
    "    # parent_indices  = set(all_scores_df['parent_index'].values)\n",
    "    # filtered_indices = [index for index in relaxed_indices  if index not in parent_indices]\n",
    "    # filtered_indices = [index for index in filtered_indices if index not in blocked_df]\n",
    "\n",
    "    # If there are structures that ran through RosettaRelax but have never been used for design, run 1 design\n",
    "    relaxed_all_scores_df = unblocked_all_scores_df[unblocked_all_scores_df['score_taken_from'] == 'Relax']\n",
    "\n",
    "    if len(relaxed_all_scores_df[\"index\"]) >= 1:\n",
    "        selected_index = int(relaxed_all_scores_df.index[0])\n",
    "        logging.info(f\"{selected_index} selected because its relaxed but nothing was designed from it.\")\n",
    "        return selected_index\n",
    "    \n",
    "    # Drop rows where 'total_score' is NaN or those that are blocked\n",
    "    unblocked_all_scores_df  = unblocked_all_scores_df.dropna(subset=['total_score'])\n",
    "            \n",
    "    # Do Boltzmann Selection if some scores exist\n",
    "    _, _, _, combined_potentials = normalize_scores(unblocked_all_scores_df, norm_all=False, extension=\"potential\", print_norm = False)\n",
    "    selected_index = 0\n",
    "    \n",
    "    if len(combined_potentials) > 0:\n",
    "        \n",
    "        if isinstance(KBT_BOLTZMANN, (float, int)):\n",
    "            kbt_boltzmann = KBT_BOLTZMANN\n",
    "        else:\n",
    "            if len(KBT_BOLTZMANN) == 2:\n",
    "                kbt_boltzmann = KBT_BOLTZMANN[0] * 10**(-KBT_BOLTZMANN[1]*all_scores_df['index'].max()) ##?? Should this be including blocked indices or not?\n",
    "\n",
    "        boltzmann_factors = np.exp(combined_potentials / (kbt_boltzmann))  \n",
    "        probabilities = boltzmann_factors / sum(boltzmann_factors)\n",
    "        #selected_index = int(np.random.choice(np.array(all_scores_df[\"index\"].tolist()), p=probabilities))\n",
    "        selected_index = int(np.random.choice(unblocked_all_scores_df[\"index\"].to_numpy(), p=probabilities))\n",
    "\n",
    "    return selected_index\n",
    "\n",
    "def start_parent_design(all_scores_df):\n",
    "\n",
    "    number_of_indices = len(all_scores_df)\n",
    "    PARENTS = [i for i in os.listdir(FOLDER_PARENT) if i[-4:] == \".pdb\"]\n",
    "    \n",
    "    if number_of_indices < N_PARENT_JOBS * len(PARENTS):\n",
    "        \n",
    "        parent_done = False\n",
    "        selected_index = int(number_of_indices / N_PARENT_JOBS)\n",
    "        parent = PARENTS[selected_index][:-4]\n",
    "        \n",
    "        new_index, all_scores_df = create_new_index(parent_index=\"Parent\", all_scores_df=all_scores_df)\n",
    "        all_scores_df['design_method'] = all_scores_df['design_method'].astype('object') #?\n",
    "        all_scores_df.at[new_index, 'design_method'] = \"RosettaDesign\"\n",
    "        all_scores_df['luca'] = all_scores_df['luca'].astype('object') #?\n",
    "        all_scores_df.at[new_index, 'luca'] = parent\n",
    "        \n",
    "        run_RosettaDesign(parent_index=parent, new_index=new_index, all_scores_df=all_scores_df, parent_done=parent_done)                      \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        parent_done = True\n",
    "    \n",
    "    save_all_scores_df(all_scores_df)\n",
    "    return parent_done, all_scores_df\n",
    "\n",
    "# Decides what to do with selected index\n",
    "def start_calculation(all_scores_df, selected_index):\n",
    "    \n",
    "    logging.debug(f\"Starting new calculation for index {selected_index}.\")\n",
    "\n",
    "    # Adjust and get info right away from df\n",
    "    blocked = False\n",
    "    # blocked_df = np.loadtxt(BLOCKED_DAT).tolist()\n",
    "    # if not isinstance(blocked_df, list): blocked_df = [blocked_df]    \n",
    "    # if selected_index in blocked_df: blocked = True\n",
    "    if all_scores_df.at[selected_index, \"blocked\"] == True:\n",
    "        blocked = True\n",
    "        \n",
    "    relaxed = False\n",
    "    if f\"{WT}_Rosetta_Relax_{selected_index}.pdb\" in os.listdir(os.path.join(FOLDER_HOME, str(selected_index))):\n",
    "        relaxed = True\n",
    "\n",
    "    # Check if ESMfold_Rosetta_Relax is done\n",
    "    if relaxed:\n",
    "\n",
    "        # ESMfold_Rosetta_Relax is done, create a new index\n",
    "        new_index, all_scores_df = create_new_index(parent_index=selected_index, all_scores_df=all_scores_df)\n",
    "\n",
    "        #####\n",
    "        # Here, we can add an AI to decide on the next steps\n",
    "        #####\n",
    "\n",
    "        # Run Rosetta_Design with new_index\n",
    "        if random.random() < ProteinMPNN_PROB:  \n",
    "            all_scores_df.at[new_index, 'design_method'] = \"ProteinMPNN\"\n",
    "            run_ProteinMPNN(parent_index=selected_index, new_index=new_index, all_scores_df=all_scores_df) \n",
    "        else:                    \n",
    "            all_scores_df.at[new_index, 'design_method'] = \"RosettaDesign\"\n",
    "            run_RosettaDesign(parent_index=selected_index, new_index=new_index, all_scores_df=all_scores_df) \n",
    "        save_all_scores_df(all_scores_df)\n",
    "        \n",
    "    else:\n",
    "        # ESMfold_Rosetta_Relax is not done, check if Index is blocked\n",
    "        if blocked:\n",
    "            # Blocked --> ESMfold_Rosetta_Relax is still running, do not do antyting. This shouldn't happen!\n",
    "            logging.error(f\"Index {selected_index} is being worked on. Skipping index.\")\n",
    "            logging.error(f\"Note: This should not happen! Check blocking and Boltzman selection.\")\n",
    "        else:\n",
    "            # Not blocked --> submit ESMfold_Rosetta_Relax and block index\n",
    "            logging.info(f\"Index {selected_index} has no relaxed structure, starting ESMfold_Rosetta_Relax.\")\n",
    "            submitted_status = run_ESMfold_RosettaRelax(index=selected_index, all_scores_df=all_scores_df, OnlyRelax=True, EXPLORE=EXPLORE)\n",
    "\n",
    "\n",
    "            # not needed anymore\n",
    "            # blocked_df = np.loadtxt(BLOCKED_DAT).tolist()\n",
    "            # if not isinstance(blocked_df, list): \n",
    "            #     blocked_df = [blocked_df]\n",
    "            # blocked_df.append(selected_index)\n",
    "\n",
    "            #Check if submission executed correctly before blocking\n",
    "            if submitted_status:\n",
    "                all_scores_df.at[selected_index, \"blocked\"] = True\n",
    "\n",
    "            #np.savetxt(BLOCKED_DAT, blocked_df)\n",
    "        save_all_scores_df(all_scores_df)\n",
    "        \n",
    "    return all_scores_df#, blocked_df  \n",
    "\n",
    "def create_new_index(parent_index, all_scores_df):\n",
    "    \n",
    "    # Create a new line with the next index and parent_index\n",
    "    new_index = len(all_scores_df) \n",
    "    \n",
    "    # Append the new line to the DataFrame and save to  all_scores_df.csv\n",
    "    if isinstance(KBT_BOLTZMANN, (float, int)):\n",
    "        kbt_boltzmann = KBT_BOLTZMANN\n",
    "    else:\n",
    "        if len(KBT_BOLTZMANN) == 2:\n",
    "            kbt_boltzmann = KBT_BOLTZMANN[0] * 10 ** (- KBT_BOLTZMANN[1] * new_index)\n",
    "    if parent_index == 'Parent':\n",
    "        generation = 0\n",
    "        luca = \"x\"\n",
    "    else:\n",
    "        generation = all_scores_df['generation'][int(parent_index)]+1\n",
    "        luca       = all_scores_df['luca'][int(parent_index)]\n",
    "        \n",
    "    # all_scores_df = all_scores_df.append({'index': new_index, \n",
    "    #                                       'parent_index': parent_index,\n",
    "    #                                       'kbt_boltzmann': kbt_boltzmann,\n",
    "    #                                       'generation': generation,\n",
    "    #                                       'luca': luca\n",
    "    #                                      }, ignore_index=True)\n",
    "    \n",
    "    new_index_df = pd.DataFrame({'index': new_index, \n",
    "                                 'parent_index': parent_index,\n",
    "                                 'kbt_boltzmann': kbt_boltzmann,\n",
    "                                 'generation': generation,\n",
    "                                 'luca': luca,\n",
    "                                 'blocked': False,\n",
    "                                 }, index = [0])\n",
    "\n",
    "    all_scores_df = pd.concat([all_scores_df, new_index_df], ignore_index=True)\n",
    "\n",
    "    save_all_scores_df(all_scores_df)\n",
    "\n",
    "    # Create the folders for the new index\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{new_index}/scripts\", exist_ok=True)\n",
    "           \n",
    "    logging.debug(f\"Child index {new_index} created for {parent_index}.\")\n",
    "    \n",
    "    return new_index, all_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c413036e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all [0.         0.54426437 0.71544153 0.54371637 0.58641531 0.\n",
      " 0.57488546 0.89851831 0.23409759 0.360488  ]\n",
      "   index                                           sequence parent_index  \\\n",
      "6      6  MNTPEHITAVVQRFVAALNAGDLDGIVALFADDATVEIPVGSEPRS...       Parent   \n",
      "\n",
      "   interface_score  total_score  catalytic_score  interface_potential  \\\n",
      "6           -17.27     -309.645            1.495               -17.27   \n",
      "\n",
      "   total_potential  catalytic_potential  generation  mutations  design_method  \\\n",
      "6         -309.645                1.495           0       16.0  RosettaDesign   \n",
      "\n",
      "  score_taken_from  blocked  kbt_boltzmann  luca  cat_resi cat_resn  \n",
      "6           Design     True           0.02  1ohp        99      ASP  \n",
      "one row [1.]\n"
     ]
    }
   ],
   "source": [
    "# all_scores_df = pd.read_csv(\"Design_A1/all_scores.csv\")\n",
    "\n",
    "# unblocked_all_scores_df = all_scores_df[all_scores_df[\"blocked\"] == False]\n",
    "\n",
    "# unblocked_all_scores_df  = unblocked_all_scores_df.dropna(subset=['total_score'])\n",
    "# #print(all_scores_df)\n",
    "        \n",
    "# # # Do Boltzmann Selection if some scores exist\n",
    "# a, b, c, combined_potentials = normalize_scores(all_scores_df, norm_all=False, extension=\"potential\", print_norm = False)\n",
    "\n",
    "# print('all', combined_potentials)\n",
    "\n",
    "# one_row_df = all_scores_df[all_scores_df[\"index\"] == 6]\n",
    "\n",
    "# print(one_row_df)\n",
    "\n",
    "# a, b, c, combined_potentials = normalize_scores(one_row_df, norm_all=False, extension=\"potential\", print_norm = False)\n",
    "\n",
    "# print('one row', combined_potentials)\n",
    "\n",
    "# catalytic_scores = np.array([132.662])\n",
    "\n",
    "# neg_norm_array(catalytic_scores, f\"catalytic_scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95a62476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "# var = 32.662\n",
    "\n",
    "# print(type(var))\n",
    "\n",
    "# series = all_scores_df[\"total_score\"]\n",
    "\n",
    "# print(type(series))\n",
    "\n",
    "# if type(var) == float:\n",
    "#     print(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f152761b",
   "metadata": {},
   "source": [
    "# main functions - design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5725702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ESMfold_RosettaRelax(index, all_scores_df, OnlyRelax=False, ProteinMPNN=False, PreMatchRelax=False,\n",
    "                             ProteinMPNN_parent_index=0, cmd=\"\", bash=False, EXPLORE=False):\n",
    "    \n",
    "    # Giving the ESMfold algorihm the needed inputs\n",
    "    output_file = f'{FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_output_{index}.pdb'\n",
    "    sequence_file = f'{FOLDER_HOME}/{index}/ESMfold/{WT}_{index}.seq'\n",
    "\n",
    "    # Make directories\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{index}/ESMfold\", exist_ok=True)\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{index}/scripts\", exist_ok=True)\n",
    "        \n",
    "    # Options for EXPLORE, accelerated script for testing\n",
    "    ex = \"-ex1 -ex2\"\n",
    "    if EXPLORE: ex = \"\"\n",
    "        \n",
    "    # Get Name of parent PDB\n",
    "    if OnlyRelax: \n",
    "        PDBFile = f\"{FOLDER_HOME}/{index}/{WT}_Rosetta_Design_{index}.pdb\"\n",
    "    elif PreMatchRelax: \n",
    "        PDBFile = f\"{FOLDER_INPUT}/{WT}.pdb\"\n",
    "    elif ProteinMPNN:\n",
    "        PDBFile = f\"{FOLDER_HOME}/{ProteinMPNN_parent_index}/{WT}_Rosetta_Relax_{ProteinMPNN_parent_index}.pdb\"\n",
    "    else:\n",
    "        print(\"I don't know what you want me to do\")\n",
    "        return\n",
    "    if not os.path.isfile(PDBFile):\n",
    "        logging.error(f\"{PDBFile} not present!\")\n",
    "        return False\n",
    "\n",
    "    # Make sequence file\n",
    "    if OnlyRelax or PreMatchRelax: \n",
    "        seq = extract_sequence_from_pdb(PDBFile)\n",
    "        with open(f\"{FOLDER_HOME}/{index}/ESMfold/{WT}_{index}.seq\",\"w\") as f: f.write(seq)\n",
    "                    \n",
    "    # Get the pdb file from the last step and strip away ligand and hydrogens \n",
    "    cpptraj = f'''parm    {PDBFile}\n",
    "trajin  {PDBFile}\n",
    "strip   :{LIGAND}\n",
    "strip   !@C,N,O,CA\n",
    "trajout {FOLDER_HOME}/{index}/ESMfold/{WT}_CPPTraj_Apo_{index}.pdb\n",
    "'''\n",
    "    with open(f'{FOLDER_HOME}/{index}/ESMfold/CPPTraj_Apo_{index}.in','w') as f: f.write(cpptraj)\n",
    "\n",
    "    # Get the pdb file from the last step and strip away everything except the ligand\n",
    "    cpptraj = f'''parm    {PDBFile}\n",
    "trajin  {PDBFile}\n",
    "strip   !:{LIGAND}\n",
    "trajout {FOLDER_HOME}/{index}/ESMfold/{WT}_CPPTraj_Lig_{index}.pdb\n",
    "'''\n",
    "    with open(f'{FOLDER_HOME}/{index}/ESMfold/CPPTraj_Lig_{index}.in','w') as f: f.write(cpptraj)\n",
    "\n",
    "    # Get the ESMfold pdb file and strip away all hydrogens\n",
    "    cpptraj = f'''parm    {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_output_{index}.pdb\n",
    "trajin  {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_output_{index}.pdb\n",
    "strip   !@C,N,O,CA\n",
    "trajout {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_no_hydrogens_{index}.pdb\n",
    "'''\n",
    "    with open(f'{FOLDER_HOME}/{index}/ESMfold/CPPTraj_no_hydrogens_{index}.in','w') as f: f.write(cpptraj)\n",
    "\n",
    "    # Align substrate and ESM prediction of scaffold without hydrogens\n",
    "    cpptraj = f'''parm    {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_no_hydrogens_{index}.pdb\n",
    "reference {FOLDER_HOME}/{index}/ESMfold/{WT}_CPPTraj_Apo_{index}.pdb [apo]\n",
    "trajin    {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_no_hydrogens_{index}.pdb\n",
    "rmsd      @CA ref [apo]\n",
    "trajout   {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_aligned_{index}.pdb noter\n",
    "'''\n",
    "    with open(f'{FOLDER_HOME}/{index}/ESMfold/CPPTraj_aligned_{index}.in','w') as f: f.write(cpptraj) \n",
    "              \n",
    "    if GRID:           extension = \"linuxgccrelease\"\n",
    "    if BLUEPEBBLE:     extension = \"serialization.linuxgccrelease\"\n",
    "    if BACKGROUND_JOB: extension = \"serialization.linuxgccrelease\"\n",
    " \n",
    "    cmd += f\"\"\"\n",
    "    \n",
    "python {FOLDER_HOME}/ESMfold.py {output_file} {sequence_file}\n",
    "\n",
    "sed -i '/PARENT N\\/A/d' {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_output_{index}.pdb\n",
    "cpptraj -i {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Apo_{index}.in           &> \\\n",
    "           {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Apo_{index}.out\n",
    "cpptraj -i {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Lig_{index}.in           &> \\\n",
    "           {FOLDER_HOME}/{index}/ESMfold/CPPTraj_Lig_{index}.out\n",
    "cpptraj -i {FOLDER_HOME}/{index}/ESMfold/CPPTraj_no_hydrogens_{index}.in  &> \\\n",
    "           {FOLDER_HOME}/{index}/ESMfold/CPPTraj_no_hydrogens_{index}.out\n",
    "cpptraj -i {FOLDER_HOME}/{index}/ESMfold/CPPTraj_aligned_{index}.in       &> \\\n",
    "           {FOLDER_HOME}/{index}/ESMfold/CPPTraj_aligned_{index}.out\n",
    "\n",
    "# Assemble the final protein\n",
    "sed -i '/END/d' {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_aligned_{index}.pdb\n",
    "\"\"\"\n",
    "    \n",
    "    input_extension_relax = \"\"\n",
    "    if PreMatchRelax:\n",
    "        extension_relax = \"_APO\"\n",
    "        ## No ligand necessary so just use the aligned pdb from ESMfold\n",
    "        cmd += f\"\"\"\n",
    "cp {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_aligned_{index}.pdb \\\n",
    "   {FOLDER_HOME}/{index}/{WT}_ESMfold_{index}{extension_relax}.pdb\n",
    "\"\"\"  \n",
    "\n",
    "    else:\n",
    "        extension_relax = \"\"\n",
    "        remark = generate_remark_from_all_scores_df(all_scores_df, index)\n",
    "        cmd += f\"\"\"\n",
    "# grep '^REMARK' {PDBFile} > {FOLDER_HOME}/{index}/ESMfold/{WT}_remark.txt\n",
    "echo {remark} > {FOLDER_HOME}/{index}/{WT}_ESMfold_{index}.pdb\n",
    "cat {FOLDER_HOME}/{index}/ESMfold/{WT}_ESMfold_aligned_{index}.pdb \\\n",
    "    {FOLDER_HOME}/{index}/ESMfold/{WT}_CPPTraj_Lig_{index}.pdb >> {FOLDER_HOME}/{index}/{WT}_ESMfold_{index}.pdb\n",
    "sed -i '/TER/d' {FOLDER_HOME}/{index}/{WT}_ESMfold_{index}.pdb\n",
    "\"\"\"\n",
    "        \n",
    "    cmd += f\"\"\"\n",
    "# Run Rosetta Relax\n",
    "{ROSETTA_PATH}/bin/rosetta_scripts.{extension} \\\n",
    "                -s                                        {FOLDER_HOME}/{index}/{WT}_ESMfold_{index}{extension_relax}.pdb \\\n",
    "                -extra_res_fa                             {FOLDER_INPUT}/{LIGAND}.params \\\n",
    "                -parser:protocol                          {FOLDER_HOME}/{index}/scripts/Rosetta_Relax_{index}.xml \\\n",
    "                -out:file:scorefile                       {FOLDER_HOME}/{index}/score_rosetta_relax.sc \\\n",
    "                -nstruct                                  1 \\\n",
    "                -ignore_zero_occupancy                    false \\\n",
    "                -corrections::beta_nov16                  true \\\n",
    "                -run:preserve_header  \\\n",
    "                -overwrite {ex}\n",
    "\n",
    "# Rename the output file\n",
    "mv {WT}_ESMfold_{index}{extension_relax}_0001.pdb {WT}_Rosetta_Relax_{index}{extension_relax}.pdb\n",
    "sed -i '/        H  /d' {WT}_Rosetta_Relax_{index}.pdb\n",
    "\"\"\"\n",
    "    \n",
    "        # Create the Rosetta_Relax.xml file\n",
    "    repeats = \"3\"\n",
    "    if EXPLORE: repeats = \"1\"\n",
    "    Rosetta_Relax_xml = f\"\"\"\n",
    "<ROSETTASCRIPTS>\n",
    "\n",
    "    <SCOREFXNS>\n",
    "    \n",
    "        <ScoreFunction name      = \"score\"                   weights = \"beta_nov16\" >\n",
    "            <Reweight scoretype  = \"atom_pair_constraint\"    weight  = \"4\" />\n",
    "            <Reweight scoretype  = \"dihedral_constraint\"     weight  = \"2\" />\n",
    "            <Reweight scoretype  = \"angle_constraint\"        weight  = \"1\" />\n",
    "        </ScoreFunction> \n",
    "        \n",
    "        <ScoreFunction name      = \"score_final\"             weights = \"beta_nov16\" >\n",
    "            <Reweight scoretype  = \"atom_pair_constraint\"    weight  = \"4\" />\n",
    "            <Reweight scoretype  = \"dihedral_constraint\"     weight  = \"2\" />\n",
    "            <Reweight scoretype  = \"angle_constraint\"        weight  = \"1\" />\n",
    "        </ScoreFunction>\n",
    "        \n",
    "    </SCOREFXNS>\n",
    "       \n",
    "    <MOVERS>\n",
    "                                  \n",
    "        <FastRelax  name=\"mv_relax\" disable_design=\"false\" repeats=\"{repeats}\" /> \n",
    "\"\"\"\n",
    "    if not PreMatchRelax: Rosetta_Relax_xml += f\"\"\"\n",
    "        <AddOrRemoveMatchCsts     name=\"mv_add_cst\" \n",
    "                                  cst_instruction=\"add_new\" \n",
    "                                  cstfile=\"{FOLDER_INPUT}/{LIGAND}_enzdes.cst\" />\n",
    "\n",
    "\"\"\"\n",
    "    Rosetta_Relax_xml += f\"\"\"\n",
    "\n",
    "        <InterfaceScoreCalculator   name                   = \"mv_inter\" \n",
    "                                    chains                 = \"X\" \n",
    "                                    scorefxn               = \"score_final\" />\n",
    "    </MOVERS>\n",
    "    \n",
    "    <PROTOCOLS>  \n",
    "\n",
    "        <Add mover_name=\"mv_relax\" />\n",
    "\"\"\"\n",
    "    if not PreMatchRelax: Rosetta_Relax_xml += f\"\"\"                                  \n",
    "        <Add mover_name=\"mv_add_cst\" />       \n",
    "        <Add mover_name=\"mv_inter\" />\n",
    "\"\"\"\n",
    "    Rosetta_Relax_xml += f\"\"\"\n",
    "    </PROTOCOLS>\n",
    "    \n",
    "</ROSETTASCRIPTS>\n",
    "\"\"\"\n",
    "    # Write the Rosetta_Relax.xml to a file\n",
    "    with open(f'{FOLDER_HOME}/{index}/scripts/Rosetta_Relax_{index}.xml', 'w') as f:\n",
    "        f.writelines(Rosetta_Relax_xml)      \n",
    "        \n",
    "    if OnlyRelax or PreMatchRelax: \n",
    "        with open(f'{FOLDER_HOME}/{index}/scripts/ESMfold_Rosetta_Relax_{index}.sh', 'w') as file:\n",
    "            file.write(cmd)\n",
    "        logging.info(f\"Run ESMfold & Rosetta_Relax for index {index}.\")\n",
    "        submit_job(index=index, job=\"ESMfold_Rosetta_Relax\", bash=bash)\n",
    "        \n",
    "    if ProteinMPNN:\n",
    "        with open(f'{FOLDER_HOME}/{index}/scripts/ProteinMPNN_ESMfold_Rosetta_Relax_{index}.sh', 'w') as file:\n",
    "            file.write(cmd)\n",
    "        logging.info(f\"Run ProteinMPNN for index {index} based on index {ProteinMPNN_parent_index}.\")\n",
    "        submit_job(index=index, job=\"ProteinMPNN_ESMfold_Rosetta_Relax\", bash=bash)\n",
    "\n",
    "    return True\n",
    "        \n",
    "def run_RosettaDesign(parent_index, new_index, all_scores_df, parent_done=True):\n",
    "\n",
    "    # Options for EXPLORE, accelerated script for testing\n",
    "    ex = \"-ex1 -ex2\"\n",
    "    if EXPLORE: ex = \"\"\n",
    "\n",
    "    if GRID:           extension = \"linuxgccrelease\"\n",
    "    if BLUEPEBBLE:     extension = \"serialization.linuxgccrelease\"\n",
    "    if BACKGROUND_JOB: extension = \"serialization.linuxgccrelease\"\n",
    "\n",
    "    if parent_done:\n",
    "        PDB_input  = f'{FOLDER_HOME}/{parent_index}/{WT}_Rosetta_Relax_{parent_index}.pdb'\n",
    "        PDB_output = f'{WT}_Rosetta_Relax_{parent_index}_0001.pdb'\n",
    "    else:\n",
    "        PDB_input  = f'{FOLDER_PARENT}/{parent_index}.pdb'\n",
    "        PDB_output = f'{parent_index}_0001.pdb'\n",
    "        \n",
    "    all_scores_df = save_cat_res_into_all_scores_df(all_scores_df, new_index, PDB_input, from_parent_struct=True)\n",
    "    \n",
    "    cmd = f\"\"\"{ROSETTA_PATH}/bin/rosetta_scripts.{extension}\\\n",
    "    -s                                        {PDB_input} \\\n",
    "    -in:file:native                           {PDB_input} \\\n",
    "    -run:preserve_header                      true \\\n",
    "    -extra_res_fa                             {FOLDER_INPUT}/{LIGAND}.params \\\n",
    "    -parser:protocol                          {FOLDER_HOME}/{new_index}/scripts/Rosetta_Design_{new_index}.xml \\\n",
    "    -out:file:scorefile                       {FOLDER_HOME}/{new_index}/score_rosetta_design.sc \\\n",
    "    -nstruct                                  1  \\\n",
    "    -ignore_zero_occupancy                    false  \\\n",
    "    -corrections::beta_nov16                  true \\\n",
    "    -overwrite {ex}\n",
    "    \n",
    "mv {PDB_output} {WT}_Rosetta_Design_{new_index}.pdb \n",
    "\"\"\"\n",
    "    # Write the shell command to a file\n",
    "    with open(f'{FOLDER_HOME}/{new_index}/scripts/Rosetta_Design_{new_index}.sh','w') as file: file.write(cmd)\n",
    "                \n",
    "    # Create XML script for Rosetta Design  \n",
    "    repeats = \"3\"\n",
    "    if EXPLORE: repeats = \"1\"\n",
    "        \n",
    "    Rosetta_Design_xml = f\"\"\"\n",
    "<ROSETTASCRIPTS>\n",
    "\n",
    "    <SCOREFXNS>\n",
    "\n",
    "        <ScoreFunction            name=\"score\"                           weights=\"beta_nov16\" >        \n",
    "            <Reweight             scoretype=\"atom_pair_constraint\"       weight=\"4\" />\n",
    "            <Reweight             scoretype=\"dihedral_constraint\"        weight=\"2\" />\n",
    "            <Reweight             scoretype=\"angle_constraint\"           weight=\"1\" />      \n",
    "            <Reweight             scoretype=\"res_type_constraint\"        weight=\"1\" />              \n",
    "        </ScoreFunction>\n",
    "       \n",
    "        <ScoreFunction            name=\"score_unconst\"                   weights=\"beta_nov16\" >        \n",
    "            <Reweight             scoretype=\"atom_pair_constraint\"       weight=\"0\" />\n",
    "            <Reweight             scoretype=\"dihedral_constraint\"        weight=\"0\" />\n",
    "            <Reweight             scoretype=\"angle_constraint\"           weight=\"0\" />              \n",
    "        </ScoreFunction>\n",
    "\n",
    "        <ScoreFunction            name=\"score_final\"                     weights=\"beta_nov16\" >    \n",
    "            <Reweight             scoretype=\"atom_pair_constraint\"       weight=\"4\" />\n",
    "            <Reweight             scoretype=\"dihedral_constraint\"        weight=\"2\" />\n",
    "            <Reweight             scoretype=\"angle_constraint\"           weight=\"1\" />                   \n",
    "        </ScoreFunction>\n",
    "   \n",
    "   </SCOREFXNS>\n",
    "   \n",
    "    <RESIDUE_SELECTORS>\n",
    "   \n",
    "        <Index                    name=\"sel_design\"\n",
    "                                  resnums=\"{DESIGN}\" />\n",
    "\n",
    "        <Index                    name=\"sel_repack\"\n",
    "                                  resnums=\"{REPACK}\" />\n",
    "\"\"\"\n",
    "    \n",
    "    # Add residue number constraints from REMARK (via all_scores_df['cat_resi'])\n",
    "    cat_resis = all_scores_df.at[new_index, 'cat_resi']\n",
    "    for idx, cat_res in enumerate(cat_resis): \n",
    "        \n",
    "        Rosetta_Design_xml += f\"\"\"\n",
    "        <Index                    name=\"sel_cat_{idx}\"\n",
    "                                  resnums=\"{int(cat_res)}\" />\n",
    "\"\"\"\n",
    "        \n",
    "    Rosetta_Design_xml += f\"\"\"\n",
    "        <Or                       name=\"sel_desrep\"\n",
    "                                  selectors=\"sel_design,sel_repack\" />\n",
    "\n",
    "        <Not                      name=\"sel_nothing\"\n",
    "                                  selector=\"sel_desrep\" />\n",
    "    </RESIDUE_SELECTORS>\n",
    "   \n",
    "    <TASKOPERATIONS>\n",
    "   \n",
    "        <OperateOnResidueSubset   name=\"tsk_design\"                      selector=\"sel_design\" >\n",
    "                                  <RestrictAbsentCanonicalAASRLT         aas=\"GPAVLIMFYWHKRQNEDST\" />\n",
    "        </OperateOnResidueSubset>\n",
    "\"\"\"\n",
    "    \n",
    "    # Add residue identity constraints from constraint file\n",
    "    with open(f'{FOLDER_HOME}/cst.dat', 'r') as f: cat_resns = f.read()    \n",
    "    cat_resns = cat_resns.split(\";\")\n",
    "    for idx, cat_resn in enumerate(cat_resns): \n",
    "        Rosetta_Design_xml += f\"\"\"\n",
    "        <OperateOnResidueSubset   name=\"tsk_cat_{idx}\"                   selector=\"sel_cat_{idx}\" >\n",
    "                                  <RestrictAbsentCanonicalAASRLT         aas=\"{cat_resn}\" />\n",
    "        </OperateOnResidueSubset>\n",
    "\"\"\"\n",
    "    \n",
    "    tsk_cat = []\n",
    "    for idx, cat_res in enumerate(cat_resns): \n",
    "        tsk_cat += [f\"tsk_cat_{idx}\"]\n",
    "    tsk_cat = \",\".join(tsk_cat)\n",
    "        \n",
    "    Rosetta_Design_xml += f\"\"\"\n",
    "       \n",
    "        <OperateOnResidueSubset   name=\"tsk_repack\"                      selector=\"sel_repack\" >\n",
    "                                  <RestrictToRepackingRLT />\n",
    "        </OperateOnResidueSubset>\n",
    "       \n",
    "        <OperateOnResidueSubset   name=\"tsk_nothing\"                     selector=\"sel_nothing\" >\n",
    "                                  <PreventRepackingRLT />\n",
    "        </OperateOnResidueSubset>\n",
    "       \n",
    "    </TASKOPERATIONS>\n",
    "\n",
    "    <FILTERS>\n",
    "   \n",
    "        <HbondsToResidue          name=\"flt_hbonds\"\n",
    "                                  scorefxn=\"score\"\n",
    "                                  partners=\"1\"\n",
    "                                  residue=\"1X\"\n",
    "                                  backbone=\"true\"\n",
    "                                  sidechain=\"true\"\n",
    "                                  from_other_chains=\"true\"\n",
    "                                  from_same_chain=\"false\"\n",
    "                                  confidence=\"0\" />\n",
    "    </FILTERS>\n",
    "   \n",
    "    <MOVERS>\n",
    "       \n",
    "        <FavorSequenceProfile     name=\"mv_native\"\n",
    "                                  weight=\"{CST_WEIGHT}\"\n",
    "                                  use_native=\"true\"\n",
    "                                  matrix=\"IDENTITY\"\n",
    "                                  scorefxns=\"score\" />  \n",
    "                               \n",
    "        <AddOrRemoveMatchCsts     name=\"mv_add_cst\"\n",
    "                                  cst_instruction=\"add_new\"\n",
    "                                  cstfile=\"{FOLDER_INPUT}/{LIGAND}_enzdes.cst\" />\n",
    "\n",
    "        <FastDesign               name                   = \"mv_design\"\n",
    "                                  disable_design         = \"false\"\n",
    "                                  task_operations        = \"tsk_design,tsk_repack,tsk_nothing,{tsk_cat}\"\n",
    "                                  repeats                = \"{repeats}\"\n",
    "                                  ramp_down_constraints  = \"false\"\n",
    "                                  scorefxn               = \"score\" />\n",
    "                                  \n",
    "        <FastRelax                name                   = \"mv_relax\"\n",
    "                                  disable_design         = \"true\"\n",
    "                                  task_operations        = \"tsk_design,tsk_repack,tsk_nothing,{tsk_cat}\"\n",
    "                                  repeats                = \"1\"\n",
    "                                  ramp_down_constraints  = \"false\"\n",
    "                                  scorefxn               = \"score_unconst\" />  \n",
    "                                  \n",
    "        <InterfaceScoreCalculator name                   = \"mv_inter\"\n",
    "                                  chains                 = \"X\"\n",
    "                                  scorefxn               = \"score_final\" />\n",
    "                                 \n",
    "    </MOVERS>\n",
    "\n",
    "    <PROTOCOLS>\n",
    "        <Add mover_name=\"mv_native\" />\n",
    "        <Add mover_name=\"mv_add_cst\" />\n",
    "        <Add mover_name=\"mv_design\" />\n",
    "        <Add mover_name=\"mv_relax\" />\n",
    "        <Add mover_name=\"mv_inter\" />\n",
    "    </PROTOCOLS>\n",
    "   \n",
    "</ROSETTASCRIPTS>\n",
    "\n",
    "\"\"\"\n",
    "    # Write the XML script to a file\n",
    "    with open(f'{FOLDER_HOME}/{new_index}/scripts/Rosetta_Design_{new_index}.xml', 'w') as f:\n",
    "        f.writelines(Rosetta_Design_xml)               \n",
    "        \n",
    "    # Submit the job using the submit_job function\n",
    "    logging.info(f\"Run RosettaDesign for index {new_index} based on index {parent_index}.\")\n",
    "    submit_job(index=new_index, job=\"Rosetta_Design\")\n",
    "\n",
    "def run_ProteinMPNN(parent_index, new_index, all_scores_df, bash=False):\n",
    "\n",
    "    #Throw error if ProteinMPNN not cloned\n",
    "    if not os.path.exists(f'{FOLDER_HOME}/../ProteinMPNN'):\n",
    "        logging.error(f\"{ProteinMPNN} not installed in {FOLDER_HOME}/../ProteinMPNN.\")\n",
    "        logging.error(f\"Install using: git clone https://github.com/dauparas/ProteinMPNN.git\")\n",
    "        return\n",
    "    \n",
    "    # Make the fasta file for the index variant \n",
    "    PDBFile = f\"{FOLDER_HOME}/{parent_index}/{WT}_Rosetta_Relax_{parent_index}.pdb\"\n",
    "\n",
    "    #Throw error if design not present!\n",
    "    if not os.path.isfile(PDBFile):\n",
    "        logging.error(f\"{PDBFile} not present!\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{new_index}/ProteinMPNN\", exist_ok=True)\n",
    "    os.makedirs(f\"{FOLDER_HOME}/{new_index}/ESMfold\", exist_ok=True)\n",
    "    shutil.copy(PDBFile, f\"{FOLDER_HOME}/{new_index}/ProteinMPNN/{WT}_Rosetta_Relax_{parent_index}.pdb\")\n",
    "    seq = extract_sequence_from_pdb(PDBFile)\n",
    "    with open(f\"{FOLDER_HOME}/{new_index}/ProteinMPNN/Rosetta_Relax_{parent_index}.seq\",\"w\") as f: f.write(seq)\n",
    "          \n",
    "    cmd = f'''\n",
    "# Run ProteinMPNN\n",
    "\n",
    "python {FOLDER_HOME}/../ProteinMPNN/helper_scripts/parse_multiple_chains.py \\\n",
    "    --input_path={FOLDER_HOME}/{new_index}/ProteinMPNN/ \\\n",
    "    --output_path={FOLDER_HOME}/{new_index}/ProteinMPNN/parsed_chains.json1\n",
    "\n",
    "python {FOLDER_HOME}/../ProteinMPNN/helper_scripts/assign_fixed_chains.py \\\n",
    "    --input_path={FOLDER_HOME}/{new_index}/ProteinMPNN/parsed_chains.json1 \\\n",
    "    --output_path={FOLDER_HOME}/{new_index}/ProteinMPNN/assigned_chains.json1 \\\n",
    "    --chain_list 'A'\n",
    "\n",
    "python {FOLDER_HOME}/../ProteinMPNN/helper_scripts/make_fixed_positions_dict.py \\\n",
    "    --input_path={FOLDER_HOME}/{new_index}/ProteinMPNN/parsed_chains.json1 \\\n",
    "    --output_path={FOLDER_HOME}/{new_index}/ProteinMPNN/fixe_positions.json1 \\\n",
    "    --chain_list 'A' \\\n",
    "    --position_list '{\" \".join(DESIGN.split(\",\"))}'\n",
    "\n",
    "python {FOLDER_HOME}/../ProteinMPNN/protein_mpnn_run.py \\\n",
    "    --jsonl_path            {FOLDER_HOME}/{new_index}/ProteinMPNN/parsed_chains.json1 \\\n",
    "    --chain_id_jsonl        {FOLDER_HOME}/{new_index}/ProteinMPNN/assigned_chains.json1\\\n",
    "    --fixed_positions_jsonl {FOLDER_HOME}/{new_index}/ProteinMPNN/fixe_positions.json1 \\\n",
    "    --out_folder            {FOLDER_HOME}/{new_index}/ProteinMPNN/ \\\n",
    "    --num_seq_per_target    100 \\\n",
    "    --sampling_temp         \"{ProteinMPNN_T}\" \\\n",
    "    --seed                  37 \\\n",
    "    --batch_size            1\n",
    "       \n",
    "# Get highest scoreing sequence\n",
    "file_path='{FOLDER_HOME}/{new_index}/ProteinMPNN/seqs/Rosetta_Relax_{parent_index}.fa' \n",
    "parent_seq_file='{FOLDER_HOME}/{new_index}/ProteinMPNN/Rosetta_Relax_{parent_index}.seq'\n",
    "input_sequence='{FOLDER_HOME}/input_sequence_with_X_as_wildecard.seq'\n",
    "highest_score=0\n",
    "highest_scoring_sequence=''\n",
    "read -r parent_sequence < \"$parent_seq_file\"\n",
    "\n",
    "# loop through scores and find greatest score that is not the same as the parent sequence\n",
    "while read -r line; do\n",
    "    if [[ $line == \">\"* ]]; then\n",
    "        score=$(echo $line | grep -oP 'global_score=\\K[\\d.]+')\n",
    "        read -r sequence\n",
    "        \n",
    "        # Check if score is higher than the highest score\n",
    "        if (( $(echo \"$score > $highest_score\" | bc -l) )); then\n",
    "        \n",
    "            # Check if sequence is different from parent_sequence\n",
    "            if [ \"$sequence\" != \"$parent_sequence\" ]; then\n",
    "            \n",
    "                # Check if sequence does not match input_sequence pattern\n",
    "                pattern=$(echo \"$input_sequence\" | sed 's/X/./g')  # Replace 'X' with wildecard '.'\n",
    "                if [[ ! \"$sequence\" =~ $pattern ]]; then\n",
    "                \n",
    "                    highest_score=$score\n",
    "                    highest_scoring_sequence=$sequence\n",
    "                    \n",
    "                fi\n",
    "            fi\n",
    "        fi\n",
    "    fi\n",
    "done < \"$file_path\"\n",
    "\n",
    "# Save highest scoring sequence\n",
    "echo $highest_scoring_sequence > {FOLDER_HOME}/{new_index}/ProteinMPNN/{PARENT}_{new_index}.seq\n",
    "echo $highest_scoring_sequence > {FOLDER_HOME}/{new_index}/ESMfold/{PARENT}_{new_index}.seq\n",
    "''' \n",
    "    run_ESMfold_RosettaRelax(index=new_index, all_scores_df=all_scores_df, RosettaDesign=False, \\\n",
    "                             ProteinMPNN=True, ProteinMPNN_parent_index=parent_index, cmd=cmd, bash=bash, EXPLORE=EXPLORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e6193",
   "metadata": {},
   "source": [
    "# main functions - startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdd671a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startup_controller(UNBLOCK_ALL, RESET, PRINT_VAR=True, PLOT_DATA=True):\n",
    "\n",
    "    # Execute setup if variables file not found\n",
    "    if not os.path.isfile(VARIABLES_JSON): setup_aizymes(RESET) #? why is this called again?\n",
    "    \n",
    "    # Creat all input files, not needed here but does not harm\n",
    "    prepare_input_files()\n",
    "    \n",
    "    if PRINT_VAR:\n",
    "        if os.path.isfile(VARIABLES_JSON):\n",
    "            with open(VARIABLES_JSON, 'r') as f: \n",
    "                globals_dict = json.load(f)\n",
    "            if globals_dict['DESIGN_FOLDER'] == DESIGN_FOLDER:\n",
    "                for k, v in globals_dict.items():\n",
    "                    globals()[k] = v\n",
    "                    print(k.ljust(16), ':', v)\n",
    "            else:\n",
    "                print(\"WRONG DESIGN FOLDER!\")\n",
    "                sys.exit()\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    if PLOT_DATA:\n",
    "        plot_scores()\n",
    "        \n",
    "    # Unblock all (use if all ESMfold_Relax jobs had to be killed.)\n",
    "    #if UNBLOCK_ALL: np.savetxt(BLOCKED_DAT, np.array([], dtype=int), fmt='%d')\n",
    "    \n",
    "    \n",
    "    # Read in current databases of AIzymes\n",
    "    all_scores_df = pd.read_csv(ALL_SCORES_CSV)\n",
    "\n",
    "    if UNBLOCK_ALL: \n",
    "        all_scores_df[\"blocked\"] = False\n",
    "    #blocked_df = np.loadtxt(BLOCKED_DAT)\n",
    "   \n",
    "    return all_scores_df  #, blocked_df\n",
    "\n",
    "def prepare_input_files():\n",
    "                      \n",
    "    # Create the ESMfold.py script\n",
    "    ESMfold_python_script = \"\"\"import sys\n",
    "from transformers import AutoTokenizer, EsmForProteinFolding, EsmConfig\n",
    "import torch\n",
    "from transformers.models.esm.openfold_utils.protein import to_pdb, Protein as OFProtein\n",
    "from transformers.models.esm.openfold_utils.feats import atom14_to_atom37\n",
    "\n",
    "output_file = sys.argv[1]\n",
    "sequence_file = sys.argv[2]\n",
    "\n",
    "with open(sequence_file) as f: sequence=f.read()\n",
    "\n",
    "def convert_outputs_to_pdb(outputs):\n",
    "    final_atom_positions = atom14_to_atom37(outputs[\"positions\"][-1], outputs)\n",
    "    outputs = {k: v.to(\"cpu\").numpy() for k, v in outputs.items()}\n",
    "    final_atom_positions = final_atom_positions.cpu().numpy()\n",
    "    final_atom_mask = outputs[\"atom37_atom_exists\"]\n",
    "    pdbs = []\n",
    "    for i in range(outputs[\"aatype\"].shape[0]):\n",
    "        aa = outputs[\"aatype\"][i]\n",
    "        pred_pos = final_atom_positions[i]\n",
    "        mask = final_atom_mask[i]\n",
    "        resid = outputs[\"residue_index\"][i] + 1\n",
    "        pred = OFProtein(\n",
    "            aatype=aa,\n",
    "            atom_positions=pred_pos,\n",
    "            atom_mask=mask,\n",
    "            residue_index=resid,\n",
    "            b_factors=outputs[\"plddt\"][i],\n",
    "            chain_index=outputs[\"chain_index\"][i] if \"chain_index\" in outputs else None,\n",
    "        )\n",
    "        pdbs.append(to_pdb(pred))\n",
    "    return pdbs\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esmfold_v1\")\n",
    "model = EsmForProteinFolding.from_pretrained(\"facebook/esmfold_v1\", low_cpu_mem_usage=True)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "model.trunk.set_chunk_size(64)\n",
    "tokenized_input = tokenizer([sequence], return_tensors=\"pt\", add_special_tokens=False)['input_ids']\n",
    "with torch.no_grad(): output = model(tokenized_input)\n",
    "pdb = convert_outputs_to_pdb(output)\n",
    "with open(output_file, \"w\") as f: f.write(\"\".join(pdb))\n",
    "\"\"\"\n",
    "\n",
    "    # Write the ESMfold.py to a file\n",
    "    with open(f\"{FOLDER_HOME}/ESMfold.py\", \"w\") as f: \n",
    "        f.write(ESMfold_python_script)\n",
    "\n",
    "    # Save input sequence with X as wildcard\n",
    "    if not os.path.isfile(f\"{FOLDER_INPUT}/{WT}.pdb\"):\n",
    "        print(f\"Error, scaffold protein structure {FOLDER_INPUT}/{WT}.pdb is missing!\")\n",
    "        sys.exit()        \n",
    "    seq = extract_sequence_from_pdb(f\"{FOLDER_INPUT}/{WT}.pdb\")\n",
    "    design_positions = [int(x) for x in DESIGN.split(',')]\n",
    "    # Replace seq with X at design positions. Note: Subtract 1 from each position to convert to Python's 0-based indexing\n",
    "    seq = ''.join('X' if (i+1) in design_positions else amino_acid for i, amino_acid in enumerate(seq))\n",
    "    with open(f'{FOLDER_HOME}/input_sequence_with_X_as_wildecard.seq', 'w') as f:\n",
    "        f.writelines(seq)    \n",
    "    \n",
    "    # Get the Constraint Residues from enzdes constraints file\n",
    "    with open(f'{FOLDER_INPUT}/{LIGAND}_enzdes.cst', 'r') as f:\n",
    "        cst = f.readlines()    \n",
    "    cst = [i.split()[-1] for i in cst if \"TEMPLATE::   ATOM_MAP: 2 res\" in i]\n",
    "    cst = \";\".join(cst)\n",
    "    with open(f'{FOLDER_HOME}/cst.dat', 'w') as f:\n",
    "        f.write(cst)    \n",
    "    \n",
    "def setup_aizymes(RESET=False, EXPLORE=False):\n",
    "    \n",
    "    # Check if setup needs to run\n",
    "    if not os.path.isfile(VARIABLES_JSON):\n",
    "        if not input(f'''Do you want to start AIzymes? [y/n]\n",
    "\n",
    "''') == 'y':\n",
    "            return #stops the start up. Although VARIABLES_JSON is missing, user elected not to set up AIzymes\n",
    "    else:\n",
    "        if RESET:\n",
    "            if not input(f'''Do you really want to restart AIzymes from scratch? \n",
    "This will delete all existing files in {FOLDER_HOME} [y/n]\n",
    "\n",
    "''') == 'y':\n",
    "                return #stops the start up. Although VARIABLES_JSON exists and RESET set, user canceled\n",
    "        else:\n",
    "            return #stop startup. VARIABLES_JSON exists and RESET not set by user\n",
    "\n",
    "    with open(LOG_FILE, 'w'): pass  #resets logfile\n",
    "    logging.info(f\"Running AI.zymes setup.\")\n",
    "    logging.info(f\"Content of {FOLDER_HOME} deleted.\")\n",
    "    logging.info(f\"Happy AI.zymeing! :)\")\n",
    "   \n",
    "    if os.path.exists(FOLDER_HOME):\n",
    "        for item in os.listdir(FOLDER_HOME):\n",
    "            if item == FOLDER_MATCH: continue\n",
    "            item = f'{FOLDER_HOME}/{item}'\n",
    "            if os.path.isfile(item): \n",
    "                os.remove(item)\n",
    "            elif os.path.isdir(item):\n",
    "                shutil.rmtree(item)\n",
    "    os.makedirs(FOLDER_HOME, exist_ok=True)\n",
    "\n",
    "    prepare_input_files()\n",
    "        \n",
    "    #make empyt all_scores_df\n",
    "    all_scores_df = make_empty_all_scores_df()\n",
    "\n",
    "    # create empty blocked.dat\n",
    "    #np.savetxt(BLOCKED_DAT, np.array([], dtype=int), fmt='%d')\n",
    "\n",
    "    # Save global varliables\n",
    "    variables_to_save = [\n",
    "        'DESIGN_FOLDER', 'FOLDER_MATCH', 'MAX_JOBS', 'N_PARENT_JOBS', 'MAX_DESIGNS', 'KBT_BOLTZMANN', 'CST_WEIGHT',\n",
    "        'ProteinMPNN_PROB', 'WT', 'LIGAND', 'ROSETTA_PATH', 'REPACK', 'DESIGN', 'MATCH', 'FOLDER_PARENT',\n",
    "        'ProteinMPNN_T', 'SUBMIT_PREFIX', 'BLUEPEBBLE', 'GRID', 'BACKGROUND_JOB'\n",
    "    ]\n",
    "    globals_to_save = {k: globals()[k] for k in variables_to_save}\n",
    "    globals_to_save['EXPLORE'] = EXPLORE\n",
    "    \n",
    "    with open(VARIABLES_JSON, 'w') as f: json.dump(globals_to_save, f, indent=4)\n",
    "    \n",
    "    \n",
    "def make_empty_all_scores_df():\n",
    "    \n",
    "    all_scores_df = pd.DataFrame(columns=['index', 'sequence', 'parent_index', \\\n",
    "                                          'interface_score', 'total_score', 'catalytic_score', \\\n",
    "                                          'interface_potential', 'total_potential', 'catalytic_potential', \\\n",
    "                                          'generation', 'mutations', 'design_method', 'score_taken_from', 'blocked', 'cat_resi', 'cat_resn'])\n",
    "    \n",
    "    save_all_scores_df(all_scores_df)\n",
    "\n",
    "    return all_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c01cc",
   "metadata": {},
   "source": [
    "# RosettaMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dced448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RosettaMatch(all_scores_df, EXPLORE=False, submit=False, bash=True):\n",
    "    \n",
    "    prepare_input_files()\n",
    "    \n",
    "    os.makedirs(FOLDER_MATCH, exist_ok=True)\n",
    "    if not os.path.isdir(f'{FOLDER_HOME}/{FOLDER_MATCH}/scripts'):\n",
    "        run_ESMfold_RosettaRelax(FOLDER_MATCH, all_scores_df, PreMatchRelax=True, EXPLORE=EXPLORE)  \n",
    "    elif not os.path.isfile(f'{FOLDER_HOME}/{FOLDER_MATCH}/{WT}_Rosetta_Relax_{FOLDER_MATCH}.pdb'):\n",
    "        print(f\"ESMfold and Relax of {FOLDER_MATCH} still running.\")\n",
    "    elif not os.path.isdir(f'{FOLDER_HOME}/{FOLDER_MATCH}/matches'):\n",
    "        run_Matcher()\n",
    "    else:\n",
    "        print(\"Matching is done\")\n",
    "            \n",
    "def run_Matcher():\n",
    "        \n",
    "    cmd = f\"\"\"       \n",
    "  \n",
    "cd {FOLDER_HOME}/{FOLDER_MATCH}\n",
    "\n",
    "echo C9 > {LIGAND}.central\n",
    "echo {\" \".join(MATCH.split(\",\"))} > {LIGAND}.pos\n",
    "\n",
    "grep    {LIGAND} {WT}_ESMfold_{FOLDER_MATCH}.pdb > {WT}_ESMfold_{FOLDER_MATCH}_LIG.pdb\n",
    "grep -v {LIGAND} {WT}_Rosetta_Relax_{FOLDER_MATCH}_APO.pdb > {WT}_Rosetta_Relax_{FOLDER_MATCH}_APO.pdb\n",
    "\n",
    "{ROSETTA_PATH}/bin/gen_lig_grids.linuxgccrelease \\\n",
    "    -s                      {WT}_Rosetta_Relax_{FOLDER_MATCH}_APO.pdb {WT}_ESMfold_{FOLDER_MATCH}_LIG.pdb \\\n",
    "    -extra_res_fa           {FOLDER_INPUT}/{LIGAND}.params \\\n",
    "    -grid_delta             0.5 \\\n",
    "    -grid_lig_cutoff        5.0 \\\n",
    "    -grid_bb_cutoff         2.25 \\\n",
    "    -grid_active_res_cutoff 15.0 \\\n",
    "    -overwrite \n",
    "\n",
    "mv {WT}_Rosetta_Relax_{FOLDER_MATCH}_APO.pdb_0.gridlig {WT}.gridlig\n",
    "rm {WT}_Rosetta_Relax_{FOLDER_MATCH}_APO.pdb_0.pos 2>1\n",
    "\n",
    "rm -r matches\n",
    "mkdir matches\n",
    "cd matches\n",
    "\n",
    "{ROSETTA_PATH}/bin/match.linuxgccrelease \\\n",
    "    -s                                        ../{WT}_Rosetta_Relax_{FOLDER_MATCH}_APO.pdb \\\n",
    "    -match:lig_name                           {LIGAND} \\\n",
    "    -extra_res_fa                             {FOLDER_INPUT}/{LIGAND}.params \\\n",
    "    -match:geometric_constraint_file          {FOLDER_INPUT}/{LIGAND}_enzdes.cst \\\n",
    "    -match::scaffold_active_site_residues     ../{LIGAND}.pos \\\n",
    "    -match:required_active_site_atom_names    ../{LIGAND}.central \\\n",
    "    -match:active_site_definition_by_gridlig  ../{WT}.gridlig  \\\n",
    "    -match:grid_boundary                      ../{WT}.gridlig  \\\n",
    "    -gridligpath                              ../{WT}.gridlig  \\\n",
    "    -overwrite  \\\n",
    "    -output_format PDB  \\\n",
    "    -output_matches_per_group 1  \\\n",
    "    -consolidate_matches true \n",
    "\"\"\" \n",
    "    with open(f'{FOLDER_HOME}/{FOLDER_MATCH}/scripts/RosettaMatch_{FOLDER_MATCH}.sh', 'w') as file: file.write(cmd)\n",
    "    logging.info(f\"Run Rosetta_Match for index {FOLDER_MATCH}.\")\n",
    "    submit_job(FOLDER_MATCH, job=\"RosettaMatch\", bash=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4bf52",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4892c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_job(index, job, bash=False):        \n",
    "      \n",
    "    if GRID:\n",
    "        submission_script = f\"\"\"#!/bin/bash\n",
    "#$ -V\n",
    "#$ -cwd\n",
    "#$ -N {SUBMIT_PREFIX}_{job}_{index}\n",
    "#$ -hard -l mf=16G\n",
    "#$ -o {FOLDER_HOME}/{index}/scripts/AI_{job}_{index}.out\n",
    "#$ -e {FOLDER_HOME}/{index}/scripts/AI_{job}_{index}.err\n",
    "\"\"\"\n",
    "    if BLUEPEBBLE:\n",
    "        submission_script = f\"\"\"#!/bin/bash\n",
    "#SBATCH --account=ptch000721\n",
    "#SBATCH --partition=short\n",
    "#SBATCH --mem=40GB\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --time=2:00:00    \n",
    "#SBATCH --nodes=1          \n",
    "#SBATCH --job-name={SUBMIT_PREFIX}_{job}_{index}\n",
    "#SBATCH --output={FOLDER_HOME}/{index}/scripts/AI_{job}_{index}.out\n",
    "#SBATCH --error={FOLDER_HOME}/{index}/scripts/AI_{job}_{index}.err\n",
    "\"\"\"\n",
    "        \n",
    "    if BACKGROUND_JOB:\n",
    "        if not os.path.isfile(f'{FOLDER_HOME}/n_running_jobs.dat'):\n",
    "            with open(f'{FOLDER_HOME}/n_running_jobs.dat', 'w') as f: f.write('0')\n",
    "        with open(f'{FOLDER_HOME}/n_running_jobs.dat', 'r'): jobs = int(f.read())\n",
    "        with open(f'{FOLDER_HOME}/n_running_jobs.dat', 'w'): f.write(jobs+1)\n",
    "        submission_script = \"\"\n",
    "        \n",
    "    submission_script += f\"\"\"\n",
    "# Output folder\n",
    "cd {FOLDER_HOME}/{index}\n",
    "pwd\n",
    "bash {FOLDER_HOME}/{index}/scripts/{job}_{index}.sh\n",
    "\"\"\" \n",
    "    if BACKGROUND_JOB:\n",
    "        submission_script = f\"\"\"\n",
    "jobs=$(cat {FOLDER_HOME}/n_running_jobs.dat)\n",
    "jobs=$((jobs - 1))\n",
    "echo \"$jobs\" > {FOLDER_HOME}/n_running_jobs.dat\n",
    "\"\"\"\n",
    "\n",
    "    # Create the submission_script\n",
    "    with open(f'{FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh', 'w') as file: file.write(submission_script)\n",
    "    \n",
    "    if bash:\n",
    "        #Bash the submission_script for testing\n",
    "        subprocess.run(f'bash {FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh', shell=True, text=True)\n",
    "    else:\n",
    "        #Submit the submission_script\n",
    "        if GRID:\n",
    "            output = subprocess.check_output(f'qsub -l h=\"!bs-dsvr64&!bs-dsvr58\" -q regular.q \\\n",
    "                                             {FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh', \\\n",
    "                                             shell=True, text=True)\n",
    "            logging.debug(output[:-1]) #remove newline at end of output\n",
    "            \n",
    "        if BLUEPEBBLE:\n",
    "            output = subprocess.check_output(f'sbatch {FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh', \\\n",
    "                                             shell=True, text=True)\n",
    "            logging.debug(output[:-1]) #remove newline at end of output\n",
    "            \n",
    "        if BACKGROUND_JOB:\n",
    "\n",
    "            stdout_log_file_path = f'{FOLDER_HOME}/{index}/scripts/submit_{job}_{index}_stdout.log'\n",
    "            stderr_log_file_path = f'{FOLDER_HOME}/{index}/scripts/submit_{job}_{index}_stderr.log'\n",
    "\n",
    "            with open(stdout_log_file_path, 'w') as stdout_log_file, open(stderr_log_file_path, 'w') as stderr_log_file:\n",
    "                process = subprocess.Popen(f'bash {FOLDER_HOME}/{index}/scripts/submit_{job}_{index}.sh &', \n",
    "                                           shell=True, stdout=stdout_log_file, stderr=stderr_log_file)\n",
    "        \n",
    "def extract_sequence_from_pdb(pdb_path):\n",
    "    with open(pdb_path, \"r\") as pdb_file:\n",
    "        for record in SeqIO.parse(pdb_file, \"pdb-atom\"):\n",
    "            seq = str(record.seq)\n",
    "    return seq\n",
    "    \n",
    "def generate_remark_from_all_scores_df(all_scores_df, index):\n",
    "\n",
    "    remark = ''\n",
    "    cat_resns = all_scores_df.at[index, 'cat_resn']#.split(';')\n",
    "    cat_resis = all_scores_df.at[index, 'cat_resi']#.split(';')\n",
    "    print(cat_resis)\n",
    "    \n",
    "    remarks = []\n",
    "\n",
    "    for cat_resi, cat_resn in zip(cat_resis, cat_resns):\n",
    "        \n",
    "    #remark += f'REMARK 666 MATCH TEMPLATE X {LIGAND}    0 MATCH MOTIF A {cat_resn[idx]}{cat_resi[idx]:>5}  1  1 \\\\n'\n",
    "        remarks.append(f'REMARK 666 MATCH TEMPLATE X {LIGAND}    0 MATCH MOTIF A {cat_resn} {cat_resi}  1  1')\n",
    "    \n",
    "    return \"\\n\".join(remarks)\n",
    "\n",
    "def save_cat_res_into_all_scores_df(all_scores_df, index, PDB_file_path, from_parent_struct=False):\n",
    "    '''Finds the indices and names of the catalytic residue from <PDB_file_path> and saves them to <all_scores_df> in row <index> as lists. Returns the updated all_scores_df'''\n",
    "        \n",
    "    with open(PDB_file_path, 'r') as f: \n",
    "        PDB = f.readlines()\n",
    "    \n",
    "    remarks = [i for i in PDB if i[:10] == 'REMARK 666']\n",
    "\n",
    "    cat_resis = []\n",
    "    cat_resns = []\n",
    "\n",
    "    for remark in remarks:\n",
    "        cat_resis.append(remark[55:59])\n",
    "\n",
    "    for line in PDB[len(remarks)+2:]:\n",
    "        atomtype = line[12:16]\n",
    "        #only want to add to cat_resns once per residue\n",
    "        if atomtype != \" CA \":\n",
    "            continue\n",
    "        resi = line[22:26]\n",
    "        resn = line[17:20]\n",
    "\n",
    "        if resi in cat_resis:\n",
    "            cat_resns.append(resn)\n",
    "    \n",
    "    all_scores_df['cat_resi'] = all_scores_df['cat_resi'].astype(object)\n",
    "    all_scores_df.at[index, 'cat_resi'] = cat_resis\n",
    "\n",
    "    #if not from_parent_struct:\n",
    "    all_scores_df.at[index, 'cat_resn'] = cat_resns\n",
    "    \n",
    "    return all_scores_df \n",
    "\n",
    "def reset_to_after_parent_design():\n",
    "    \n",
    "    folders = []\n",
    "    \n",
    "    for folder_name in os.listdir(FOLDER_HOME):\n",
    "        if os.path.isdir(os.path.join(FOLDER_HOME, folder_name)) and folder_name.isdigit():\n",
    "            folders.append(int(folder_name))\n",
    "    \n",
    "    all_scores_df = make_empty_all_scores_df()\n",
    "        \n",
    "    PARENTS = [i for i in os.listdir(FOLDER_PARENT) if i[-4:] == \".pdb\"]\n",
    "    \n",
    "    for folder in sorted(folders):\n",
    "        \n",
    "        folder_path = os.path.join(FOLDER_HOME, str(folder))\n",
    "        \n",
    "        if folder >= N_PARENT_JOBS * len(PARENTS):\n",
    "            \n",
    "            #Remove non-parent designs\n",
    "            shutil.rmtree(folder_path)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            #Remove Potentials\n",
    "            for item in os.listdir(folder_path):\n",
    "                if 'potential.dat' not in item: continue\n",
    "                item_path = os.path.join(folder_path, item)\n",
    "                os.remove(item_path)\n",
    "                print(item_path)\n",
    "                    \n",
    "            #Update Scorefile\n",
    "            new_index, all_scores_df = create_new_index(parent_index=\"Parent\", all_scores_df=all_scores_df)\n",
    "            all_scores_df['design_method'] = all_scores_df['design_method'].astype('object') \n",
    "            all_scores_df.at[new_index, 'design_method'] = \"RosettaDesign\"\n",
    "            all_scores_df['luca'] = all_scores_df['luca'].astype('object') \n",
    "            score_file_path = f\"{FOLDER_HOME}/{int(index)}/score_rosetta_design.sc\"\n",
    "            with open(score_file_path, 'r') as f: score = f.readlines()[2]\n",
    "            all_scores_df.at[new_index, 'luca'] = score.split()[-1][:-5]\n",
    "    \n",
    "            if new_index % 100 == 0: print(folder, new_index) \n",
    "\n",
    "    save_all_scores_df(all_scores_df)\n",
    "    \n",
    "def save_all_scores_df(all_scores_df):\n",
    "    \n",
    "    temp_fd, temp_path = tempfile.mkstemp(dir=FOLDER_HOME) # Create a temporary file\n",
    "\n",
    "    try:\n",
    "        all_scores_df.to_csv(temp_path, index=False)       # Save DataFrame to the temporary file\n",
    "        os.close(temp_fd)                                  # Close file descriptor\n",
    "        os.rename(temp_path, ALL_SCORES_CSV)               # Rename temporary file to final filename\n",
    "    except Exception as e:\n",
    "        os.close(temp_fd)                                  # Ensure file descriptor is closed in case of error\n",
    "        os.unlink(temp_path)                               # Remove the temporary file if an error occurs\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608bedf",
   "metadata": {},
   "source": [
    "# plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(combined_score_min=0, combined_score_max=1, combined_score_bin=0.01,\n",
    "                interface_score_min=0, interface_score_max=1, interface_score_bin=0.01,\n",
    "                total_score_min=0, total_score_max=1, total_score_bin=0.01,\n",
    "                catalytic_score_min=0, catalytic_score_max=1, catalytic_score_bin=0.01,\n",
    "                mut_min=0,mut_max=len(DESIGN.split(\",\"))+1):\n",
    "        \n",
    "    # Break because file does not exist\n",
    "    if not os.path.isfile(ALL_SCORES_CSV): return\n",
    "    \n",
    "    all_scores_df = pd.read_csv(ALL_SCORES_CSV)\n",
    "    all_scores_df['sequence'] = all_scores_df['sequence'].astype(str)\n",
    "    all_scores_df['design_method'] = all_scores_df['design_method'].astype(str)\n",
    "    all_scores_df['score_taken_from'] = all_scores_df['score_taken_from'].astype(str)\n",
    "            \n",
    "    # Break because not enough data\n",
    "    if len(all_scores_df.dropna(subset=['total_score'])) < 3: return\n",
    "    \n",
    "    ### Calculate Generations and Scores    \n",
    "    G = nx.DiGraph()\n",
    "    ### generations = {} not needed\n",
    "    \n",
    "    for idx, row in all_scores_df.iterrows():\n",
    "        G.add_node(idx)\n",
    "        if row['parent_index'] != \"Parent\":\n",
    "            G.add_edge(int(float(row['parent_index'])), idx)        \n",
    "        \n",
    "    # Plot data\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(15, 6))\n",
    "    \n",
    "    all_scores_df = all_scores_df.dropna(subset=['total_score'])\n",
    "    catalytic_scores, total_scores, interface_scores, combined_scores = normalize_scores(all_scores_df, \n",
    "                                                                                         print_norm=True,\n",
    "                                                                                         norm_all=True)\n",
    "            \n",
    "    plot_combined_score(axs[0,0], combined_scores, \\\n",
    "                        combined_score_min, combined_score_max, combined_score_bin)\n",
    "    plot_interface_score(axs[0,1], interface_scores, \\\n",
    "                         interface_score_min, interface_score_max, interface_score_bin)\n",
    "    plot_total_score(axs[0,2], total_scores, \\\n",
    "                     total_score_min, total_score_max, total_score_bin)\n",
    "    plot_catalytic_score(axs[0,3], catalytic_scores, \\\n",
    "                         catalytic_score_min, catalytic_score_max, catalytic_score_bin)\n",
    "    \n",
    "    plot_boltzmann_histogram(axs[1,0], combined_scores, all_scores_df, \\\n",
    "                             combined_score_min, combined_score_max, combined_score_bin)\n",
    "    plot_combined_score_v_index(axs[1,1], combined_scores, all_scores_df)\n",
    "    plot_combined_score_v_generation(axs[1,2], combined_scores, all_scores_df)\n",
    "    plot_mutations_v_generation(axs[1,3], all_scores_df, mut_min, mut_max)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #fig, ax = plt.subplots(1, 1, figsize=(15, 2.5))\n",
    "    #plot_tree(ax, combined_scores, all_scores_df, G)\n",
    "    #plt.show()\n",
    "\n",
    "def plot_combined_score(ax, combined_scores, score_min, score_max, score_bin):\n",
    "    \n",
    "    ax.hist(combined_scores, bins=np.arange(score_min,score_max+score_bin,score_bin))\n",
    "    ax.axvline(HIGHSCORE, color='b')\n",
    "    ax.axvline(NEG_BEST, color='r')\n",
    "    ax.set_xlim(score_min,score_max)\n",
    "    ax.set_title('Histogram of Score')\n",
    "    ax.set_xlabel('Combined Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "def plot_interface_score(ax, interface_scores, interface_score_min, interface_score_max, interface_score_bin):\n",
    "        \n",
    "    ax.hist(interface_scores, density=True,\n",
    "            bins=np.arange(interface_score_min,interface_score_max+interface_score_bin,interface_score_bin))\n",
    "    ax.set_xlim(interface_score_min,interface_score_max)\n",
    "    ax.set_title('Histogram of Interface Score')\n",
    "    ax.set_xlabel('Interface Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "def plot_total_score(ax, total_scores, total_score_min, total_score_max, total_score_bin):\n",
    "\n",
    "    ax.hist(total_scores, density=True,\n",
    "            bins=np.arange(total_score_min,total_score_max+total_score_bin,total_score_bin))\n",
    "    ax.set_xlim(total_score_min,total_score_max)\n",
    "    ax.set_title('Histogram of Total Score')\n",
    "    ax.set_xlabel('Total Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "def plot_catalytic_score(ax, catalytic_scores, total_score_min, total_score_max, total_score_bin):\n",
    "\n",
    "    ax.hist(catalytic_scores, density=True,\n",
    "            bins=np.arange(total_score_min,total_score_max+total_score_bin,total_score_bin))\n",
    "    ax.set_xlim(total_score_min,total_score_max)\n",
    "    ax.set_title('Histogram of Catalytic Score')\n",
    "    ax.set_xlabel('Catalytic Score')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "\n",
    "def plot_boltzmann_histogram(ax, combined_scores, all_scores_df, score_min, score_max, score_bin):\n",
    "\n",
    "    _, _, _, combined_potentials = normalize_scores(all_scores_df, print_norm=False, norm_all=False, extension=\"potential\")\n",
    "            \n",
    "    if isinstance(KBT_BOLTZMANN, (float, int)):\n",
    "        kbt_boltzmann = KBT_BOLTZMANN\n",
    "    else:\n",
    "        if len(KBT_BOLTZMANN) == 2:\n",
    "            kbt_boltzmann = KBT_BOLTZMANN[0] * 10 ** (- KBT_BOLTZMANN[1] * len(all_scores_df))\n",
    "    \n",
    "    boltzmann_factors = np.exp(combined_potentials / (kbt_boltzmann)) \n",
    "    probabilities     = boltzmann_factors / sum(boltzmann_factors) \n",
    "    \n",
    "    random_scores     = np.random.choice(combined_potentials, size=1000, replace=True)\n",
    "    boltzmann_scores  = np.random.choice(combined_potentials, size=1000, replace=True, p=probabilities)\n",
    "\n",
    "    # Plot the first histogram\n",
    "    ax.hist(random_scores, density=True, alpha=0.7, label='Random Sampling', \\\n",
    "            bins=np.arange(score_min,score_max+score_bin,score_bin))\n",
    "    ax.text(0.05, 0.95, \"normalized only to \\n this dataset\")\n",
    "    ax.set_xlabel('Potential')\n",
    "    ax.set_ylabel('Density (Normal)')\n",
    "    ax.set_title(f'kbT = {kbt_boltzmann:.1e}')\n",
    "    # Create a twin y-axis for the second histogram\n",
    "    ax_dup = ax.twinx()\n",
    "    ax_dup.hist(boltzmann_scores, density=True, alpha=0.7, color='orange', label='Boltzmann Sampling', \\\n",
    "                bins=np.arange(score_min,score_max+score_bin,score_bin))\n",
    "    ax.set_xlim(score_min,score_max)\n",
    "    ax_dup.set_ylabel('Density (Boltzmann)')\n",
    "    ax_dup.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "def plot_interface_score_v_total_score(ax, all_scores_df, \n",
    "                                       total_score_min, total_score_max, interface_score_min, interface_score_max):\n",
    "\n",
    "    ax.scatter(all_scores_df['total_score'], all_scores_df['interface_score'],\n",
    "            c=all_scores_df['index'], cmap='coolwarm_r', s=5)\n",
    "    correlation,_ = pearsonr(all_scores_df['total_score'], all_scores_df['interface_score'])\n",
    "    xmin = all_scores_df['total_score'].min()\n",
    "    xmax = all_scores_df['total_score'].max()\n",
    "    z = np.polyfit(all_scores_df['total_score'], all_scores_df['interface_score'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_trendline = np.linspace(xmin, xmax, 100) \n",
    "    ax.plot(x_trendline, p(x_trendline), \"k\")\n",
    "    ax.set_title(f'Pearson r: {correlation:.2f}')\n",
    "    ax.set_xlim(total_score_min,total_score_max)\n",
    "    ax.set_ylim(interface_score_min,interface_score_max)\n",
    "    ax.set_xlabel('Total Score')\n",
    "    ax.set_ylabel('Interface Score')\n",
    "\n",
    "def plot_combined_score_v_index(ax, combined_scores, all_scores_df):\n",
    "    \n",
    "    combined_scores = pd.Series(combined_scores)\n",
    "    moving_avg = combined_scores.rolling(window=20).mean()\n",
    "    ax.scatter(all_scores_df['index'], combined_scores, c='lightgrey', s=5) \n",
    "    ax.axhline(HIGHSCORE, color='b')\n",
    "    ax.axhline(NEG_BEST, color='r')\n",
    "    PARENTS = [i for i in os.listdir(FOLDER_PARENT) if i[-4:] == \".pdb\"]\n",
    "    ax.axvline(N_PARENT_JOBS*len(PARENTS), color='k')\n",
    "    ax.plot(range(len(moving_avg)),moving_avg,c=\"k\")\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.set_xlim(0,MAX_DESIGNS)\n",
    "    ax.set_title('Score vs Index')\n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Combined Score')    \n",
    "    \n",
    "def plot_combined_score_v_generation(ax, combined_scores, all_scores_df):\n",
    "    \n",
    "    all_scores_df['tmp'] = combined_scores\n",
    "    all_scores_df = all_scores_df.dropna(subset=['tmp'])\n",
    "    \n",
    "    max_gen = int(all_scores_df['generation'].max())\n",
    "    boxplot_data = [all_scores_df[all_scores_df['generation'] == gen]['tmp'] for gen in range(0,max_gen+1,1)]\n",
    "    ax.boxplot(boxplot_data, positions=range(len(boxplot_data)))\n",
    "    ax.axhline(HIGHSCORE, color='b')\n",
    "    ax.axhline(NEG_BEST, color='r')\n",
    "    ax.set_xticks(range(len(boxplot_data)))\n",
    "    ax.set_xticklabels(range(0,len(boxplot_data),1))\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.set_title('Combined Score vs Generations')\n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Combined Score')\n",
    "    ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.7)\n",
    "    \n",
    "def plot_mutations_v_generation(ax, all_scores_df,  mut_min, mut_max):\n",
    "    \n",
    "    all_scores_df = all_scores_df.dropna(subset=['mutations'])\n",
    "    \n",
    "    max_gen = int(all_scores_df['generation'].max())\n",
    "    boxplot_data = [all_scores_df[all_scores_df['generation'] == gen]['mutations'] for gen in range(0,max_gen+1,1)]\n",
    "    ax.boxplot(boxplot_data, positions=range(len(boxplot_data)))\n",
    "    ax.axhline(len(DESIGN.split(\",\")), color='r')\n",
    "    ax.set_xticks(range(len(boxplot_data)))\n",
    "    ax.set_xticklabels(range(0,len(boxplot_data),1))\n",
    "    ax.set_ylim(mut_min,mut_max)\n",
    "    ax.set_title('Mutations vs Generations')\n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Number of Mutations')\n",
    "    ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.7)\n",
    "    \n",
    "def plot_tree(ax, combined_scores, all_scores_df, G):\n",
    "    \n",
    "    all_scores_df = pd.read_csv(ALL_SCORES_CSV)\n",
    "    _, _, _, combined_potentials = normalize_scores(all_scores_df, print_norm=False, norm_all=False, extension=\"potential\")\n",
    "\n",
    "    max_gen = int(all_scores_df['generation'].max())\n",
    "    \n",
    "    def set_node_positions(G, node, pos, x, y, counts):\n",
    "        pos[node] = (x, y)\n",
    "        neighbors = list(G.successors(node))\n",
    "        next_y = y - counts[node] / 2\n",
    "        for neighbor in neighbors:\n",
    "            set_node_positions(G, neighbor, pos, x + 1, next_y + counts[neighbor] / 2, counts)\n",
    "            next_y += counts[neighbor]\n",
    "            \n",
    "    def count_descendants(G, node, counts):\n",
    "        neighbors = list(G.successors(node))\n",
    "        count = 1\n",
    "        for neighbor in neighbors:\n",
    "            count += count_descendants(G, neighbor, counts)\n",
    "        counts[node] = count\n",
    "        return count\n",
    "\n",
    "    counts = {}\n",
    "    count_descendants(G, 0, counts)\n",
    "\n",
    "    pos = {}\n",
    "    set_node_positions(G, 0, pos, 0, 0, counts)\n",
    "    y_values = [y for x, y in pos.values()]\n",
    "    y_span = max(y_values) - min(y_values)  \n",
    "    \n",
    "    colors = combined_potentials\n",
    "    colors[0] = np.nan\n",
    "    normed_colors = [(x - np.nanmin(colors[1:])) / (np.nanmax(colors[1:]) - np.nanmin(colors[1:])) for x in colors]\n",
    "    normed_colors = np.nan_to_num(normed_colors, nan=0)\n",
    "    normed_colors = normed_colors**2\n",
    "\n",
    "    # Draw the graph with the positions set\n",
    "    #nx.draw(G, pos, ax=ax, sld', arrows=False, cmap=plt.cm.coolwarm_r)\n",
    "    for start, end in G.edges():\n",
    "        color = plt.cm.coolwarm_r(normed_colors[end])\n",
    "        if float(normed_colors[end]) == 0.0: color = [0., 0., 0., 1.]\n",
    "        linewidth = 0.1+2*normed_colors[end]\n",
    "        \n",
    "        x0, y0 = pos[start]\n",
    "        x1, y1 = pos[end]\n",
    "        ax.plot([y0, y1], [x0, x1], color=color, linewidth=linewidth)\n",
    "\n",
    "    # Adjust axis labels and ticks for the swapped axes\n",
    "    ax.axis('on')\n",
    "    ax.set_title(\"Colored by Potential\")\n",
    "    ax.set_xlabel(\"Variants\")\n",
    "    ax.set_ylabel(\"Generations\")\n",
    "    ax.set_yticks(range(max_gen+1))\n",
    "    ax.set_ylim(0,max_gen+0.25)\n",
    "    ax.set_yticklabels(range(max_gen+1))\n",
    "\n",
    "    ax.tick_params(axis='y', which='both', bottom=True, top=False, left=True, right=False,\n",
    "                   labelbottom=True, labelleft=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e1fb9",
   "metadata": {},
   "source": [
    "## Functions needed to run AIzyme algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AIzyme Functions loaded!\")\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2a4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
